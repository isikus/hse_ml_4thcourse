{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"assignment_7alt.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"332609d139e94f02b51ef5b57c3a9939":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6d9dd2ab547643179c44b0ebcfde0b3b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d69976efa28f46ac9f2de639a86bd31f","IPY_MODEL_b74c281e1726481d906af433b364d018"]}},"6d9dd2ab547643179c44b0ebcfde0b3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d69976efa28f46ac9f2de639a86bd31f":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8531c6f203614e0ea95c424f18059956","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e883b0eee976425f8aa6804501e033b7"}},"b74c281e1726481d906af433b364d018":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_325f12be80ea4765be9318d629ba0b11","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"235159it [01:07, 3466.25it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_87c7db5c4f3a4349bd7f3c56ad024bb1"}},"8531c6f203614e0ea95c424f18059956":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e883b0eee976425f8aa6804501e033b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"325f12be80ea4765be9318d629ba0b11":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"87c7db5c4f3a4349bd7f3c56ad024bb1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"012d3f509bba4509b5f3ddb26be7697c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f17d60c57122412f85afb851641d7442","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_89ae8fc0ee60410e8640e185331c5ad6","IPY_MODEL_463eda722a5f450ca0cd1dbc92a923ca"]}},"f17d60c57122412f85afb851641d7442":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"89ae8fc0ee60410e8640e185331c5ad6":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2846323e511d4407a67a7f0905dfbba4","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"danger","max":1647,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":44,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3bf79224582a418590fb70213f33c6e4"}},"463eda722a5f450ca0cd1dbc92a923ca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f84ef8687f6e4f14988b9c17398a0826","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"  3% 44/1647 [01:33&lt;56:16,  2.11s/it, loss=7.17]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b5dcf24701e247afb81f2b6fe5410c6b"}},"2846323e511d4407a67a7f0905dfbba4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3bf79224582a418590fb70213f33c6e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f84ef8687f6e4f14988b9c17398a0826":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b5dcf24701e247afb81f2b6fe5410c6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"6wPW5tHp0c4Y","colab_type":"text"},"source":["# Assignment 7\n","\n","Train a Transformer model for Machine Translation from Russian to English.  \n","Dataset: http://data.statmt.org/wmt18/translation-task/training-parallel-nc-v13.tgz   \n","Make all source and target text to lower case.  \n","Use following tokenization for english:  \n","```\n","import sentencepiece as spm\n","\n","...\n","spm.SentencePieceTrainer.Train('--input=data/text.en --model_prefix=bpe_en --vocab_size=32000 --character_coverage=0.98 --model_type=bpe')\n","\n","tok_en = spm.SentencePieceProcessor()\n","tok_en.load('bpe_en.model')\n","\n","TGT = data.Field(\n","    fix_length=50,\n","    init_token='<s>',\n","    eos_token='</s>',\n","    lower=True,\n","    tokenize = lambda x: tok_en.encode_as_pieces(x),\n","    batch_first=True,\n",")\n","\n","...\n","TGT.build_vocab(..., min_freq=5)\n","...\n","\n","```\n","Score: corpus-bleu `nltk.translate.bleu_score.corpus_bleu`  \n","Use last 1000 sentences for model evalutation (test dataset).  \n","Use your target sequence tokenization for BLEU score.  \n","Use max_len=50 for sequence prediction.  \n","\n","\n","Hint: You may consider much smaller model, than shown in the example.  \n","\n","Baselines:  \n","[4 point] BLEU = 0.05  \n","[6 point] BLEU = 0.10  \n","[9 point] BLEU = 0.15  \n","\n","[1 point] Share weights between target embeddings and output dense layer. Notice, they have the same shape.\n","\n","\n","Readings:\n","1. BLUE score how to https://machinelearningmastery.com/calculate-bleu-score-for-text-python/\n","1. Transformer code and comments http://nlp.seas.harvard.edu/2018/04/03/attention.html"]},{"cell_type":"code","metadata":{"id":"UFukRC211Ybd","colab_type":"code","outputId":"02f91476-f944-43cf-ae98-80809ea8a9eb","colab":{"base_uri":"https://localhost:8080/","height":353},"executionInfo":{"status":"ok","timestamp":1583128915946,"user_tz":-180,"elapsed":25369,"user":{"displayName":"Ivan Torubarov","photoUrl":"","userId":"07481003931234110333"}}},"source":["!wget http://data.statmt.org/wmt18/translation-task/training-parallel-nc-v13.tgz\n","!tar -xzvf training-parallel-nc-v13.tgz\n","!mv training-parallel-nc-v13 data"],"execution_count":1,"outputs":[{"output_type":"stream","text":["--2020-03-02 09:01:33--  http://data.statmt.org/wmt18/translation-task/training-parallel-nc-v13.tgz\n","Resolving data.statmt.org (data.statmt.org)... 129.215.197.184\n","Connecting to data.statmt.org (data.statmt.org)|129.215.197.184|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 113157482 (108M) [application/x-gzip]\n","Saving to: ‘training-parallel-nc-v13.tgz’\n","\n","training-parallel-n 100%[===================>] 107.92M  10.9MB/s    in 12s     \n","\n","2020-03-02 09:01:46 (9.13 MB/s) - ‘training-parallel-nc-v13.tgz’ saved [113157482/113157482]\n","\n","training-parallel-nc-v13/\n","training-parallel-nc-v13/news-commentary-v13.ru-en.ru\n","training-parallel-nc-v13/news-commentary-v13.cs-en.en\n","training-parallel-nc-v13/news-commentary-v13.de-en.de\n","training-parallel-nc-v13/news-commentary-v13.ru-en.en\n","training-parallel-nc-v13/news-commentary-v13.zh-en.zh\n","training-parallel-nc-v13/news-commentary-v13.zh-en.en\n","training-parallel-nc-v13/news-commentary-v13.cs-en.cs\n","training-parallel-nc-v13/news-commentary-v13.de-en.en\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9WEE99zj2WZN","colab_type":"code","outputId":"77d1593b-99af-499a-c046-fd5305105cea","colab":{"base_uri":"https://localhost:8080/","height":101},"executionInfo":{"status":"ok","timestamp":1583128921522,"user_tz":-180,"elapsed":30896,"user":{"displayName":"Ivan Torubarov","photoUrl":"","userId":"07481003931234110333"}}},"source":["!pip install sentencepiece"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\r\u001b[K     |▎                               | 10kB 19.0MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 3.4MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 2.2MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 2.6MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |██▌                             | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |██▉                             | 92kB 3.7MB/s eta 0:00:01\r\u001b[K     |███▏                            | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |███▌                            | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |████                            | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▍                           | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▊                           | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 337kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 348kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 358kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 368kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 378kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 389kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 399kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 409kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 419kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 430kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 440kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 450kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 460kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 471kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 481kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 491kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 501kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 512kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 522kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 532kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 542kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 552kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 563kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 573kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 583kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 593kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 604kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 614kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 624kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 634kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 645kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 655kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 665kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 675kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 686kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 696kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 706kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 716kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 727kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 737kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 747kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 757kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 768kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 778kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 788kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 798kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 808kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 819kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 829kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 839kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 849kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 860kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 870kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 880kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 890kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 901kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 911kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 921kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 931kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 942kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 952kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 962kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 972kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 983kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 993kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0MB 2.8MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.85\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vbQFLKn50c4m","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","import numpy as np\n","import pandas as pd\n","import tqdm\n","from torchtext import datasets, data\n","import sentencepiece as spm\n","\n","\n","DEVICE = 'cuda'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lp-0d8AA2uA3","colab_type":"code","outputId":"f8b698bc-c363-4ae6-c22c-f8a34fdc2ead","colab":{"base_uri":"https://localhost:8080/","height":84},"executionInfo":{"status":"ok","timestamp":1583128927528,"user_tz":-180,"elapsed":36842,"user":{"displayName":"Ivan Torubarov","photoUrl":"","userId":"07481003931234110333"}}},"source":["!ls data"],"execution_count":4,"outputs":[{"output_type":"stream","text":["news-commentary-v13.cs-en.cs  news-commentary-v13.ru-en.en\n","news-commentary-v13.cs-en.en  news-commentary-v13.ru-en.ru\n","news-commentary-v13.de-en.de  news-commentary-v13.zh-en.en\n","news-commentary-v13.de-en.en  news-commentary-v13.zh-en.zh\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cbaPmyAN0c4z","colab_type":"code","outputId":"c6880bae-e192-4079-f345-597676757b34","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1583128946425,"user_tz":-180,"elapsed":55704,"user":{"displayName":"Ivan Torubarov","photoUrl":"","userId":"07481003931234110333"}}},"source":["# tokenize english \n","with open('data/news-commentary-v13.ru-en.en') as f:\n","    with open('data/text.en', 'w') as out:\n","            out.write(f.read().lower())\n","        \n","spm.SentencePieceTrainer.Train('--input=data/text.en --model_prefix=bpe_en --vocab_size=32000 --character_coverage=0.98 --model_type=bpe')"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"0Ne6v2EV0c5C","colab_type":"code","outputId":"97a2b3a6-3a95-4c60-cbf6-8dd8cced9273","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1583128987041,"user_tz":-180,"elapsed":96278,"user":{"displayName":"Ivan Torubarov","photoUrl":"","userId":"07481003931234110333"}}},"source":["# tokenize russian\n","\n","with open('data/news-commentary-v13.ru-en.ru') as f:\n","    with open('data/text.ru', 'w') as out:\n","            out.write(f.read().lower())\n","        \n","spm.SentencePieceTrainer.Train('--input=data/text.ru --model_prefix=bpe_ru --vocab_size=32000 --character_coverage=0.98 --model_type=bpe')"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"J-vuMecz0c5K","colab_type":"code","colab":{}},"source":["tok_ru = spm.SentencePieceProcessor()\n","tok_ru.load('bpe_ru.model')\n","\n","tok_en = spm.SentencePieceProcessor()\n","tok_en.load('bpe_en.model')\n","\n","SRC = data.Field(\n","    fix_length=50,\n","    init_token='<s>',\n","    eos_token='</s>',\n","    lower=True,\n","    tokenize = lambda x: tok_ru.encode_as_pieces(x),\n","    batch_first=True,\n",")\n","\n","TGT = data.Field(\n","    fix_length=50,\n","    init_token='<s>',\n","    eos_token='</s>',\n","    lower=True,\n","    tokenize = lambda x: tok_en.encode_as_pieces(x),\n","    batch_first=True,\n",")\n","\n","fields = (('src', SRC), ('tgt', TGT))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xu1vaHvb0c5a","colab_type":"code","outputId":"c5a586d3-dcfb-4328-ab12-0bd4a3a11818","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["332609d139e94f02b51ef5b57c3a9939","6d9dd2ab547643179c44b0ebcfde0b3b","d69976efa28f46ac9f2de639a86bd31f","b74c281e1726481d906af433b364d018","8531c6f203614e0ea95c424f18059956","e883b0eee976425f8aa6804501e033b7","325f12be80ea4765be9318d629ba0b11","87c7db5c4f3a4349bd7f3c56ad024bb1"]},"executionInfo":{"status":"ok","timestamp":1583129055806,"user_tz":-180,"elapsed":164933,"user":{"displayName":"Ivan Torubarov","photoUrl":"","userId":"07481003931234110333"}}},"source":["with open('data/text.ru') as f:\n","    src_snt = list(map(str.strip, f.readlines()))\n","    \n","with open('data/text.en') as f:\n","    tgt_snt = list(map(str.strip, f.readlines()))\n","    \n","examples = [data.Example.fromlist(x, fields) for x in tqdm.tqdm_notebook(zip(src_snt, tgt_snt))]\n","test = data.Dataset(examples[-1000:], fields)\n","train, valid = data.Dataset(examples[:-1000], fields).split(0.9)"],"execution_count":8,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"332609d139e94f02b51ef5b57c3a9939","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jTkVsxOl3zJR","colab_type":"code","outputId":"0489f195-08d6-4aec-8e10-6e8e4cc33aab","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1583129055807,"user_tz":-180,"elapsed":164915,"user":{"displayName":"Ivan Torubarov","photoUrl":"","userId":"07481003931234110333"}}},"source":["print('src: ' + \" \".join(train.examples[100].src))\n","print('tgt: ' + \" \".join(train.examples[100].tgt))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["src: ▁скорее , ▁она ▁по ходит ▁на ▁корей скую ▁маргарет ▁т э тчер ▁ – ▁леди , ▁не ▁склон ную ▁к ▁разво ро там , ▁следуя ▁известной ▁ ф раз е ▁т э тчер , ▁на ▁человека ▁с ▁чет кими , ▁продуман ными ▁политическими ▁принципами , ▁которые ▁ожи вля ют ▁ее ▁поступки .\n","tgt: ▁indeed , ▁she ▁looks ▁more ▁like ▁a ▁korean ▁margaret ▁thatcher ▁ – ▁a ▁lady ▁not ▁for ▁turning , ▁in ▁thatcher ’ s ▁famous ▁phrase , ▁and ▁with ▁clearly ▁thought - through ▁political ▁principles ▁animating ▁her ▁actions .\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"92yQVJco3443","colab_type":"code","outputId":"a23e6cc5-4bca-4863-b037-6e1149d39e4a","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1583129055808,"user_tz":-180,"elapsed":164843,"user":{"displayName":"Ivan Torubarov","photoUrl":"","userId":"07481003931234110333"}}},"source":["len(train), len(valid), len(test)"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(210743, 23416, 1000)"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"3pGoYfog0c6K","colab_type":"code","colab":{}},"source":["TGT.build_vocab(train, min_freq=5)\n","SRC.build_vocab(train, min_freq=5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"A_ncacTe7U4O","colab_type":"code","outputId":"a30e19a1-6bab-410d-c648-e80de3e9dd50","colab":{"base_uri":"https://localhost:8080/","height":202},"executionInfo":{"status":"ok","timestamp":1583129088178,"user_tz":-180,"elapsed":3494,"user":{"displayName":"Ivan Torubarov","photoUrl":"","userId":"07481003931234110333"}}},"source":["!wget https://raw.githubusercontent.com/thedenaas/hse_seminars/master/2019/seminar_10/transformer.py"],"execution_count":14,"outputs":[{"output_type":"stream","text":["--2020-03-02 09:04:45--  https://raw.githubusercontent.com/thedenaas/hse_seminars/master/2019/seminar_10/transformer.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 9478 (9.3K) [text/plain]\n","Saving to: ‘transformer.py.1’\n","\n","\rtransformer.py.1      0%[                    ]       0  --.-KB/s               \rtransformer.py.1    100%[===================>]   9.26K  --.-KB/s    in 0s      \n","\n","2020-03-02 09:04:45 (104 MB/s) - ‘transformer.py.1’ saved [9478/9478]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Su8gACLE0c6a","colab_type":"code","colab":{}},"source":["from transformer import make_model, Batch\n","\n","    \n","class BucketIteratorWrapper(DataLoader):\n","    __initialized = False\n","\n","    def __init__(self, iterator: data.Iterator):\n","#         super(BucketIteratorWrapper,self).__init__()\n","        self.batch_size = iterator.batch_size\n","        self.num_workers = 1\n","        self.collate_fn = None\n","        self.pin_memory = False\n","        self.drop_last = False\n","        self.timeout = 0\n","        self.worker_init_fn = None\n","        self.sampler = iterator\n","        self.batch_sampler = iterator\n","        self.__initialized = True\n","\n","    def __iter__(self):\n","        return map(\n","            lambda batch: Batch(batch.src, batch.tgt, pad=TGT.vocab.stoi['<pad>']),\n","            self.batch_sampler.__iter__()\n","        )\n","\n","    def __len__(self):\n","        return len(self.batch_sampler)\n","    \n","class MyCriterion(nn.Module):\n","    def __init__(self, pad_idx):\n","        super(MyCriterion, self).__init__()\n","        self.pad_idx = pad_idx\n","        self.criterion = nn.CrossEntropyLoss(reduction='sum', ignore_index=pad_idx)\n","        \n","    def forward(self, x, target):\n","        x = x.contiguous().permute(0,2,1)\n","        ntokens = (target != self.pad_idx).data.sum()\n","        \n","        return self.criterion(x, target) / ntokens"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0POt0xgylUFd","colab_type":"code","colab":{}},"source":["class NoamOpt:\n","    \"Optim wrapper that implements rate.\"\n","    def __init__(self, model_size, factor, warmup, optimizer):\n","        self.optimizer = optimizer\n","        self._step = 0\n","        self.warmup = warmup\n","        self.factor = factor\n","        self.model_size = model_size\n","        self._rate = 0\n","        \n","    def step(self):\n","        \"Update parameters and rate\"\n","        self._step += 1\n","        rate = self.rate()\n","        for p in self.optimizer.param_groups:\n","            p['lr'] = rate\n","        self._rate = rate\n","        self.optimizer.step()\n","        \n","    def rate(self, step = None):\n","        \"Implement `lrate` above\"\n","        if step is None:\n","            step = self._step\n","        return self.factor * \\\n","            (self.model_size ** (-0.5) *\n","            min(step ** (-0.5), step * self.warmup ** (-1.5)))\n","        \n","def get_std_opt(model):\n","    return NoamOpt(model.src_embed[0].d_model, 2, 4000,\n","            torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lsEEGDH10c7A","colab_type":"code","colab":{}},"source":["torch.cuda.empty_cache()\n","\n","batch_size = 128\n","num_epochs = 4\n","\n","train_iter, valid_iter, test_iter = data.BucketIterator.splits((train, valid, test), \n","                                              batch_sizes=(batch_size, batch_size, batch_size), \n","                                  sort_key=lambda x: len(x.src),\n","                                  shuffle=True,\n","                                  device=DEVICE,\n","                                  sort_within_batch=False)\n","                                  \n","train_iter = BucketIteratorWrapper(train_iter)\n","valid_iter = BucketIteratorWrapper(valid_iter)\n","test_iter = BucketIteratorWrapper(test_iter)\n","\n","model = make_model(len(SRC.vocab), len(TGT.vocab), N=6)\n","model = model.to(DEVICE)\n","criterion = MyCriterion(TGT.vocab.stoi['<pad>'])\n","#criterion = criterion.to(DEVICE)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n","#scheduler = <TODO>\n","#NoamOpt(model.src_embed[0].d_model, 1, 2000, torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n","\n","# share weights\n","#<TODO>"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Po76zE-y1iLk","colab_type":"text"},"source":["# Train\n"]},{"cell_type":"code","metadata":{"id":"6UD8rrByXQ3u","colab_type":"code","outputId":"8e316810-1945-4f81-c351-7a8b6d1b1279","colab":{"base_uri":"https://localhost:8080/","height":402,"referenced_widgets":["012d3f509bba4509b5f3ddb26be7697c","f17d60c57122412f85afb851641d7442","89ae8fc0ee60410e8640e185331c5ad6","463eda722a5f450ca0cd1dbc92a923ca","2846323e511d4407a67a7f0905dfbba4","3bf79224582a418590fb70213f33c6e4","f84ef8687f6e4f14988b9c17398a0826","b5dcf24701e247afb81f2b6fe5410c6b"]},"executionInfo":{"status":"error","timestamp":1583129296997,"user_tz":-180,"elapsed":97226,"user":{"displayName":"Ivan Torubarov","photoUrl":"","userId":"07481003931234110333"}}},"source":["def train_epoch(data_iter, model, criterion):\n","    total_loss = 0\n","    data_iter = tqdm.tqdm_notebook(data_iter)\n","    counter = 0\n","    for batch in data_iter:\n","        optimizer.zero_grad()\n","        epoch_losses = []\n","        \n","        pred = model.forward(batch)\n","        loss = criterion.forward(pred, batch.tgt_y)\n","        loss.backward()\n","        optimizer.step()\n","        \n","        curr_loss = loss.data.detach().item()\n","        total_loss += curr_loss\n","        epoch_losses.append(curr_loss)\n","        general_loss = np.mean(epoch_losses)\n","        data_iter.set_postfix(loss = general_loss)\n","        counter +=1\n","        \n","    total_loss /= counter\n","    return total_loss\n","\n","def valid_epoch(data_iter, model, criterion):\n","    total_loss = 0\n","    data_iter = tqdm.tqdm_notebook(data_iter)\n","    counter = 0\n","    for batch in data_iter:\n","        epoch_losses = []\n","        \n","        pred = model.forward(batch)\n","        loss = criterion.forward(pred, batch.tgt_y)\n","        \n","        curr_loss = loss.data.detach().item()\n","        total_loss += curr_loss\n","        epoch_losses.append(curr_loss)\n","        general_loss = np.mean(epoch_losses)\n","        data_iter.set_postfix(loss = general_loss)\n","        counter +=1\n","        \n","    total_loss /= counter\n","    return total_loss\n","\n","\n","for epoch in range(num_epochs-1):\n","    model.train()\n","    loss = train_epoch(train_iter, model, criterion)\n","    print('train', loss)\n","    \n","    model.eval()\n","    with torch.no_grad():\n","        loss = valid_epoch(valid_iter, model, criterion)\n","        #scheduler.step(loss)\n","        print('valid', loss)"],"execution_count":20,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"012d3f509bba4509b5f3ddb26be7697c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=1647), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-777a200240d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-20-777a200240d2>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(data_iter, model, criterion)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtgt_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"vWdiPcJC0c7Q","colab_type":"code","outputId":"c23b24d8-b547-4c76-b1ef-6e89cd7d1e75","colab":{"base_uri":"https://localhost:8080/","height":229},"executionInfo":{"status":"error","timestamp":1583129064616,"user_tz":-180,"elapsed":1105,"user":{"displayName":"Ivan Torubarov","photoUrl":"","userId":"07481003931234110333"}}},"source":["def train_epoch(data_iter, model, criterion):\n","    total_loss = 0\n","    data_iter = tqdm.tqdm_notebook(data_iter)\n","    counter = 0\n","    for batch in data_iter:\n","        optimizer.zero_grad()\n","        epoch_losses = []\n","        \n","        pred = model.forward(batch)\n","        loss = criterion.forward(pred, batch.tgt_y)\n","        loss.backward()\n","        optimizer.step()\n","        \n","        curr_loss = loss.data.detach().item()\n","        total_loss += curr_loss\n","        epoch_losses.append(curr_loss)\n","        general_loss = np.mean(epoch_losses)\n","        data_iter.set_postfix(loss = general_loss)\n","        counter +=1\n","        \n","    total_loss /= counter\n","    return total_loss\n","\n","def valid_epoch(data_iter, model, criterion):\n","    total_loss = 0\n","    data_iter = tqdm.tqdm_notebook(data_iter)\n","    counter = 0\n","    for batch in data_iter:\n","        epoch_losses = []\n","        \n","        pred = model.forward(batch)\n","        loss = criterion.forward(pred, batch.tgt_y)\n","        \n","        curr_loss = loss.data.detach().item()\n","        total_loss += curr_loss\n","        epoch_losses.append(curr_loss)\n","        general_loss = np.mean(epoch_losses)\n","        data_iter.set_postfix(loss = general_loss)\n","        counter +=1\n","        \n","    total_loss /= counter\n","    return total_loss\n","\n","\n","for epoch in range(num_epochs-1):\n","    model.train()\n","    loss = train_epoch(train_iter, model, criterion)\n","    print('train', loss)\n","    \n","    model.eval()\n","    with torch.no_grad():\n","        loss = valid_epoch(valid_iter, model, criterion)\n","        #scheduler.step(loss)\n","        print('valid', loss)"],"execution_count":13,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-777a200240d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'num_epochs' is not defined"]}]},{"cell_type":"code","metadata":{"id":"0MWzSOvpXPnF","colab_type":"code","outputId":"813506e7-1a40-4e13-cf07-887c6333339c","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print('valid', loss)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["valid tensor(6.1940, device='cuda:0')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ITtT4F8dgjri","colab_type":"code","colab":{}},"source":["torch.save(model.state_dict(), 'iwslt.pt')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vvhICU3TglLQ","colab_type":"code","outputId":"7980a4a8-1e89-428b-f99d-2dd1ed3abec6","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!ls -lAh iwslt.pt"],"execution_count":0,"outputs":[{"output_type":"stream","text":["-rw-r--r-- 1 root root 363M Feb 29 15:14 iwslt.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JpKDi_EthDn1","colab_type":"code","outputId":"96003e35-f578-4b66-d90b-072cdad8a2a6","colab":{"base_uri":"https://localhost:8080/","height":125}},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9YuLbff6nz6a","colab_type":"code","outputId":"1ff41013-37c4-4333-d6ef-e82e0d87747d","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["2+1"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"ANXQ8I4WhQ-L","colab_type":"code","colab":{}},"source":["!cp iwslt.pt /content/drive/My\\ Drive"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LHcrxZbWI2mQ","colab_type":"code","colab":{}},"source":["!cp /content/drive/My\\ Drive/iwslt.pt ."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7tCQSP-P0c7d","colab_type":"code","colab":{}},"source":["def beam_search(model, src, src_mask, max_len=10, k=5):\n","    <TODO>"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"qj_fekdR0c7j","colab_type":"code","outputId":"a27dd345-9809-41fd-c4c4-e3fa13f27d82","colab":{}},"source":["model.eval()\n","with torch.no_grad():\n","    for i, batch in enumerate(valid_iter):\n","        src = batch.src[:1]\n","        src_key_padding_mask = src != SRC.vocab.stoi[\"<pad>\"]\n","        beam = beam_search(model, src, src_key_padding_mask)\n","        \n","        seq = []\n","        for i in range(1, src.size(1)):\n","            sym = SRC.vocab.itos[src[0, i]]\n","            if sym == \"</s>\": break\n","            seq.append(sym)\n","        seq = tok_ru.decode_pieces(seq)\n","        print(\"\\nSource:\", seq)\n","        \n","        print(\"Translation:\")\n","        for pred, pred_proba in beam:                \n","            seq = []\n","            for i in range(1, pred.size(1)):\n","                sym = TGT.vocab.itos[pred[0, i]]\n","                if sym == \"</s>\": break\n","                seq.append(sym)\n","            seq = tok_en.decode_pieces(seq)\n","            print(f\"pred {pred_proba:.2f}:\", seq)\n","                \n","        seq = []\n","        for i in range(1, batch.tgt.size(1)):\n","            sym = TGT.vocab.itos[batch.tgt[0, i]]\n","            if sym == \"</s>\": break\n","            seq.append(sym)\n","        seq = tok_en.decode_pieces(seq)\n","        print(\"Target:\", seq)\n","        break"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","Source: рост\n","Translation:\n","pred -1.31: growth\n","pred -2.03: growth growth\n","pred -3.63: rising growth\n","pred -3.89: growth in growth\n","pred -4.38: growth growth growth\n","Target: inflation\n"],"name":"stdout"},{"output_type":"stream","text":["/home/denis.litvinov/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:21: UserWarning:\n","\n","Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"KYXKW_En0c7u","colab_type":"code","colab":{}},"source":["from nltk.translate.bleu_score import corpus_bleu"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TnQg75u50c70","colab_type":"code","colab":{}},"source":["hypotheses = []\n","references = []\n","\n","model.eval()\n","with torch.no_grad():\n","    for batch in test_iter:\n","        <TODO>"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k1a6ussA0c8M","colab_type":"code","outputId":"526b7ef0-2d0d-474d-e8ae-8e8404708785","colab":{}},"source":["corpus_bleu(references, hypotheses, \n","            smoothing_function=translate.bleu_score.SmoothingFunction().method3,\n","            auto_reweigh=True\n","           )"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.22829332685417014"]},"metadata":{"tags":[]},"execution_count":97}]},{"cell_type":"markdown","metadata":{"id":"V3liHWTX5BP2","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"vBHeFAD91dre","colab_type":"text"},"source":["# Eval"]},{"cell_type":"code","metadata":{"id":"fj3xYa0RX7mg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"5f2fa41b-63d6-436f-e9a3-517cd031a661","executionInfo":{"status":"ok","timestamp":1583087745052,"user_tz":-180,"elapsed":32692,"user":{"displayName":"Ivan Torubarov","photoUrl":"","userId":"07481003931234110333"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0_Y9SGk8X3ho","colab_type":"code","colab":{}},"source":["!cp /content/drive/My\\ Drive/iwslt.pt ."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dr6iaXosX0A0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"e0f42c7d-0dc7-47c7-d88a-f96e8b702697","executionInfo":{"status":"ok","timestamp":1583089485107,"user_tz":-180,"elapsed":3025,"user":{"displayName":"Ivan Torubarov","photoUrl":"","userId":"07481003931234110333"}}},"source":["model_loaded = make_model(32709, 28276, N=6)\n","model_loaded.load_state_dict(torch.load('iwslt.pt', map_location='cpu'))\n","model_loaded = model_loaded.to(DEVICE)\n","model_loaded.eval()"],"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/plain":["EncoderDecoder(\n","  (encoder): Encoder(\n","    (layers): ModuleList(\n","      (0): EncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (sublayer): ModuleList(\n","          (0): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1): EncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (sublayer): ModuleList(\n","          (0): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (2): EncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (sublayer): ModuleList(\n","          (0): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (3): EncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (sublayer): ModuleList(\n","          (0): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (4): EncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (sublayer): ModuleList(\n","          (0): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (5): EncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (sublayer): ModuleList(\n","          (0): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (norm): LayerNorm()\n","  )\n","  (decoder): Decoder(\n","    (layers): ModuleList(\n","      (0): DecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (src_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (sublayer): ModuleList(\n","          (0): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1): DecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (src_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (sublayer): ModuleList(\n","          (0): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (2): DecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (src_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (sublayer): ModuleList(\n","          (0): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (3): DecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (src_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (sublayer): ModuleList(\n","          (0): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (4): DecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (src_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (sublayer): ModuleList(\n","          (0): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (5): DecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (src_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (sublayer): ModuleList(\n","          (0): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (norm): LayerNorm()\n","  )\n","  (src_embed): Sequential(\n","    (0): Embeddings(\n","      (lut): Embedding(32709, 512)\n","    )\n","    (1): PositionalEncoding(\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","  )\n","  (tgt_embed): Sequential(\n","    (0): Embeddings(\n","      (lut): Embedding(28276, 512)\n","    )\n","    (1): PositionalEncoding(\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","  )\n","  (generator): Linear(in_features=512, out_features=28276, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"code","metadata":{"id":"HqoJC8fiZTSg","colab_type":"code","colab":{}},"source":["model = model_loaded"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xqtwSkrncjlj","colab_type":"code","colab":{}},"source":["model = model.to(DEVICE)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"N_6N2zrPZVpA","colab_type":"code","colab":{}},"source":["hypotheses = []\n","references = []\n","\n","model.eval()\n","with torch.no_grad():\n","    for batch in test_iter:\n","        pred = model.forward(batch)\n","        sents = torch.argmax(torch.softmax(pred, dim=-1), dim=-1)\n","        hypotheses.extend([[TGT.vocab.itos[ix] for ix in sent] for sent in sents])\n","        references.extend([[[TGT.vocab.itos[ix] for ix in sent]] for sent in batch.tgt_y])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CYuHxoG8ZiT6","colab_type":"code","colab":{}},"source":["from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"l3FT7uUwZkQE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"7eb2d1c6-2b13-476b-8a9f-27402a2b87e6","executionInfo":{"status":"ok","timestamp":1583088029363,"user_tz":-180,"elapsed":1393,"user":{"displayName":"Ivan Torubarov","photoUrl":"","userId":"07481003931234110333"}}},"source":["corpus_bleu(\n","    references, hypotheses, smoothing_function=SmoothingFunction().method3,\n","    auto_reweigh=True\n",")"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.0015378640393985269"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"NUwKy8RWacak","colab_type":"code","colab":{}},"source":["def subsequent_mask(size):\n","    \"Mask out subsequent positions.\"\n","    attn_shape = (1, size, size)\n","    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n","    return torch.from_numpy(subsequent_mask) == 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qHw3KIhuZn7a","colab_type":"code","colab":{}},"source":["#from transformer import subsequent_mask\n","\n","def beam_search(model, src, src_mask, max_len=10, k=5):\n","    memory = model.encode(src, src_mask)\n","    start_token = TGT.vocab.stoi[\"<s>\"]\n","    end_token = TGT.vocab.stoi[\"</s>\"]\n","    ys = torch.ones(1, 1).fill_(start_token).type_as(src.data)\n","    beam = [(ys, 0)]\n","    for i in range(max_len):\n","        candidates= []\n","        candidates_proba = []\n","        prev_prob = None\n","        for snt, snt_proba in beam:\n","            if snt[0][-1] == end_token:\n","                candidates.append(snt)\n","                candidates_proba.append(snt_proba)\n","            else:\n","                proba = model.decode(memory, src_mask, snt,\n","                                     subsequent_mask(snt.size(1)).type_as(src.data))\n","                proba = proba[0][i]\n","                best_k = torch.argsort(-proba)[:k].tolist()\n","                proba = proba.tolist()\n","                prev_prob = proba\n","                for tok in best_k:\n","                    candidates.append(torch.cat([snt, torch.ones(1, 1).type_as(src.data).fill_(tok)], dim=1))\n","                    candidates_proba.append(snt_proba + np.log(proba[tok])) \n","         \n","        best_candidates = np.argsort(-np.array(candidates_proba))[:k]\n","        beam = [(candidates[j], candidates_proba[j]) for j in best_candidates]\n","    return beam"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eEQO82hyZpHp","colab_type":"code","colab":{}},"source":["eos = '</s>'\n","pad = \"<pad>\"\n","len_test = len(list(iter(test_iter)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P2ij8vyYbKeV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"0529d539-8c86-4e29-8461-c36223d42612","executionInfo":{"status":"ok","timestamp":1583089173395,"user_tz":-180,"elapsed":1401,"user":{"displayName":"Ivan Torubarov","photoUrl":"","userId":"07481003931234110333"}}},"source":["type(src)"],"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Tensor"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"code","metadata":{"id":"winGZUoqef1w","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"f4e46f96-f9fc-402a-a5d8-b327f6abf691","executionInfo":{"status":"ok","timestamp":1583089322480,"user_tz":-180,"elapsed":1064,"user":{"displayName":"Ivan Torubarov","photoUrl":"","userId":"07481003931234110333"}}},"source":["model"],"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["EncoderDecoder(\n","  (encoder): Encoder(\n","    (layers): ModuleList(\n","      (0): EncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (sublayer): ModuleList(\n","          (0): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1): EncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (sublayer): ModuleList(\n","          (0): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (2): EncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (sublayer): ModuleList(\n","          (0): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (3): EncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (sublayer): ModuleList(\n","          (0): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (4): EncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (sublayer): ModuleList(\n","          (0): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (5): EncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (sublayer): ModuleList(\n","          (0): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (norm): LayerNorm()\n","  )\n","  (decoder): Decoder(\n","    (layers): ModuleList(\n","      (0): DecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (src_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (sublayer): ModuleList(\n","          (0): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1): DecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (src_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (sublayer): ModuleList(\n","          (0): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (2): DecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (src_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (sublayer): ModuleList(\n","          (0): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (3): DecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (src_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (sublayer): ModuleList(\n","          (0): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (4): DecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (src_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (sublayer): ModuleList(\n","          (0): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (5): DecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (src_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (sublayer): ModuleList(\n","          (0): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (norm): LayerNorm()\n","  )\n","  (src_embed): Sequential(\n","    (0): Embeddings(\n","      (lut): Embedding(32709, 512)\n","    )\n","    (1): PositionalEncoding(\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","  )\n","  (tgt_embed): Sequential(\n","    (0): Embeddings(\n","      (lut): Embedding(28276, 512)\n","    )\n","    (1): PositionalEncoding(\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","  )\n","  (generator): Linear(in_features=512, out_features=28276, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"id":"7y0fAs8tZuJq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"95f6a398-929c-4228-b96d-bbb2b7a4d897","executionInfo":{"status":"error","timestamp":1583089734306,"user_tz":-180,"elapsed":1106,"user":{"displayName":"Ivan Torubarov","photoUrl":"","userId":"07481003931234110333"}}},"source":["model.eval()\n","with torch.no_grad():\n","    for i, batch in enumerate(valid_iter):\n","        src = batch.src[:1]\n","        src_key_padding_mask = src != TGT.vocab.stoi['<pad>']\n","        beam = beam_search(model, src, src_key_padding_mask, max_len=8, k=5)\n","        \n","        seq = []\n","        for i in range(1, src.size(1)):\n","            sym = SRC.vocab.itos[src[0, i]]\n","            if sym == eos: break\n","            seq.append(sym)\n","        seq = tok_ru.decode_pieces(seq)\n","        print(\"\\nSource:\", seq)\n","        \n","        print(\"Translation:\")\n","        for pred, pred_proba in beam:                \n","            seq = []\n","            for i in range(1, pred.size(1)):\n","                sym = TGT.vocab.itos[pred[0, i]]\n","                if sym == eos: break\n","                seq.append(sym)\n","            seq = tok_en.decode_pieces(seq)\n","            print(f\"pred {pred_proba:.2f}:\", seq)\n","                \n","        seq = []\n","        for i in range(1, batch.tgt.size(1)):\n","            sym = TGT.vocab.itos[batch.tgt[0, i]]\n","            if sym == eos: break\n","            seq.append(sym)\n","        seq = tok_en.decode_pieces(seq)\n","        print(\"Target:\", seq)\n","        break"],"execution_count":57,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-57-00d76d94dfcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msrc_key_padding_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mTGT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<pad>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mbeam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeam_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-51-78b1e94d32bf>\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(model, src, src_mask, max_len, k)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 proba = model.decode(memory, src_mask, snt,\n\u001b[0;32m---> 18\u001b[0;31m                                      subsequent_mask(snt.size(1)).type_as(src.data))\n\u001b[0m\u001b[1;32m     19\u001b[0m                 \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mbest_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mproba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/transformer.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, tgt, tgt_mask, memory, src_mask)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtgt_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mPositionalEncoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m         return F.embedding(\n\u001b[1;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.cuda.FloatTensor instead (while checking arguments for embedding)"]}]},{"cell_type":"code","metadata":{"id":"L4bnU0j6mTG2","colab_type":"code","colab":{}},"source":["'''\n","model_opt = NoamOpt(model.src_embed[0].d_model, 1, 2000,\n","        torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n","for epoch in range(10):\n","    model_par.train()\n","    run_epoch((rebatch(pad_idx, b) for b in train_iter), \n","              model_par, \n","              MultiGPULossCompute(model.generator, criterion, \n","                                  devices=devices, opt=model_opt))\n","    model_par.eval()\n","    loss = run_epoch((rebatch(pad_idx, b) for b in valid_iter), \n","                      model_par, \n","                      MultiGPULossCompute(model.generator, criterion, \n","                      devices=devices, opt=None))\n","    print(loss)\n","'''"],"execution_count":0,"outputs":[]}]}