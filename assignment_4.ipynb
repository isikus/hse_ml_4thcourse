{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "assignment4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oa0Vr2lrzXU-",
        "colab_type": "code",
        "outputId": "2d8f35bd-70c6-4872-e398-38e9dd911a5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "!wget https://github.com/thedenaas/hse_seminars/raw/master/2019/seminar_6/data.zip"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-02 20:20:23--  https://github.com/thedenaas/hse_seminars/raw/master/2019/seminar_6/data.zip\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/thedenaas/hse_seminars/master/2019/seminar_6/data.zip [following]\n",
            "--2019-12-02 20:20:24--  https://raw.githubusercontent.com/thedenaas/hse_seminars/master/2019/seminar_6/data.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1064698 (1.0M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>]   1.01M  1.82MB/s    in 0.6s    \n",
            "\n",
            "2019-12-02 20:20:26 (1.82 MB/s) - ‘data.zip’ saved [1064698/1064698]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3J076pXzhIq",
        "colab_type": "code",
        "outputId": "84dbb072-bf0e-4e48-bc37-86fb2d144517",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "!unzip data.zip\n",
        "!cp data/ner_short.csv ."
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data.zip\n",
            "   creating: data/\n",
            "  inflating: data/.DS_Store          \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/data/\n",
            "  inflating: __MACOSX/data/._.DS_Store  \n",
            "  inflating: data/ner_short.csv      \n",
            "  inflating: __MACOSX/data/._ner_short.csv  \n",
            "  inflating: __MACOSX/._data         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hom7UZQ3tyRq",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 4: Named entity recognition\n",
        "\n",
        "Create a model for Named Entity Recognition for dataset CoNLL 2002.  \n",
        "Your quality metric = f1_macro\n",
        "\n",
        "In your solution you should use: RandomForest, Gradient Boosting (xgboost, lightgbm, catboost)   \n",
        "Tutorials:  \n",
        "1. https://github.com/Microsoft/LightGBM/tree/master/examples/python-guide\n",
        "1. https://github.com/catboost/tutorials \n",
        "\n",
        "More baselines you beat - better your score\n",
        " \n",
        "baseline 1 [3 points]: 0.0604      random labels  \n",
        "baseline 2 [5 points]: 0.3966      PoS features + logistic regression  \n",
        "baseline 3 [8 points]: 0.8122      word2vec cbow embedding + baseline 2 + svm    \n",
        "\n",
        "[1 point] using feature engineering (creating features not presented in the baselines)\n",
        "\n",
        "! Your results must be reproducible. You should explicitly set all seeds random_states in yout model.  \n",
        "! Remember to use proper training pipeline.  \n",
        "\n",
        "bonus, think about:  \n",
        "1. [1 point] Why did we select f1 score with macro averaging as our classification quality measure? What other metrics are suitable?   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5nqt96btyRt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn import model_selection\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn import metrics\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "SEED=1337"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMVxGhHhtyRw",
        "colab_type": "code",
        "outputId": "c71308c7-eb1e-43af-9441-6d5ceab7b343",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df = pd.read_csv('ner_short.csv', index_col=0)\n",
        "df.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>next-next-pos</th>\n",
              "      <th>next-next-word</th>\n",
              "      <th>next-pos</th>\n",
              "      <th>next-word</th>\n",
              "      <th>pos</th>\n",
              "      <th>prev-pos</th>\n",
              "      <th>prev-prev-pos</th>\n",
              "      <th>prev-prev-word</th>\n",
              "      <th>prev-word</th>\n",
              "      <th>sentence_idx</th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NNS</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>IN</td>\n",
              "      <td>of</td>\n",
              "      <td>NNS</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>VBP</td>\n",
              "      <td>have</td>\n",
              "      <td>NNS</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>IN</td>\n",
              "      <td>NNS</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>1.0</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>VBN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBP</td>\n",
              "      <td>have</td>\n",
              "      <td>NNS</td>\n",
              "      <td>IN</td>\n",
              "      <td>NNS</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>of</td>\n",
              "      <td>1.0</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>IN</td>\n",
              "      <td>through</td>\n",
              "      <td>VBN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBP</td>\n",
              "      <td>NNS</td>\n",
              "      <td>IN</td>\n",
              "      <td>of</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>1.0</td>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NNP</td>\n",
              "      <td>London</td>\n",
              "      <td>IN</td>\n",
              "      <td>through</td>\n",
              "      <td>VBN</td>\n",
              "      <td>VBP</td>\n",
              "      <td>NNS</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>have</td>\n",
              "      <td>1.0</td>\n",
              "      <td>marched</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  next-next-pos next-next-word next-pos  ... sentence_idx           word tag\n",
              "0           NNS  demonstrators       IN  ...          1.0      Thousands   O\n",
              "1           VBP           have      NNS  ...          1.0             of   O\n",
              "2           VBN        marched      VBP  ...          1.0  demonstrators   O\n",
              "3            IN        through      VBN  ...          1.0           have   O\n",
              "4           NNP         London       IN  ...          1.0        marched   O\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11akaVmOB4Qv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e714b867-acf2-4a52-cdf7-7af2a12b621f"
      },
      "source": [
        "null_value_stats = df.isna().sum(axis=0)\n",
        "null_value_stats[null_value_stats != 0]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Series([], dtype: int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjtgMguytyRz",
        "colab_type": "code",
        "outputId": "53d68573-6106-42bd-854d-8d29b6175156",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# number of sentences\n",
        "df.sentence_idx.max()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1500.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr0hC85LtyR1",
        "colab_type": "code",
        "outputId": "8b585198-8a74-490a-b013-8dd5537abf9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "# class distribution\n",
        "df.tag.value_counts(normalize=True)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "O        0.852828\n",
              "B-geo    0.027604\n",
              "B-gpe    0.020935\n",
              "B-org    0.020247\n",
              "I-per    0.017795\n",
              "B-tim    0.016927\n",
              "B-per    0.015312\n",
              "I-org    0.013937\n",
              "I-geo    0.005383\n",
              "I-tim    0.004247\n",
              "B-art    0.001376\n",
              "I-gpe    0.000837\n",
              "I-art    0.000748\n",
              "B-eve    0.000628\n",
              "I-eve    0.000508\n",
              "B-nat    0.000449\n",
              "I-nat    0.000239\n",
              "Name: tag, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRuXy45jtyR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sentence length\n",
        "tdf = df.set_index('sentence_idx')\n",
        "tdf['length'] = df.groupby('sentence_idx').tag.count()\n",
        "df = tdf.reset_index(drop=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAgCaSMs29bZ",
        "colab_type": "text"
      },
      "source": [
        "Firstly, let's take a glance on our targets, so we can hopefully notice some commmon features between them:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqBFJ8IqtySL",
        "colab_type": "code",
        "outputId": "2fabab35-f90a-4f28-8c84-81f18339590c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        }
      },
      "source": [
        "df.loc[df.tag != \"O\"].sample(20)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_idx</th>\n",
              "      <th>next-next-pos</th>\n",
              "      <th>next-next-word</th>\n",
              "      <th>next-pos</th>\n",
              "      <th>next-word</th>\n",
              "      <th>pos</th>\n",
              "      <th>prev-pos</th>\n",
              "      <th>prev-prev-pos</th>\n",
              "      <th>prev-prev-word</th>\n",
              "      <th>prev-word</th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>62087</th>\n",
              "      <td>1288.0</td>\n",
              "      <td>WDT</td>\n",
              "      <td>which</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>NNP</td>\n",
              "      <td>NNP</td>\n",
              "      <td>CD</td>\n",
              "      <td>1998</td>\n",
              "      <td>Noumea</td>\n",
              "      <td>Accord</td>\n",
              "      <td>I-tim</td>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9265</th>\n",
              "      <td>422.0</td>\n",
              "      <td>VBD</td>\n",
              "      <td>said</td>\n",
              "      <td>RB</td>\n",
              "      <td>also</td>\n",
              "      <td>NNP</td>\n",
              "      <td>IN</td>\n",
              "      <td>NN</td>\n",
              "      <td>spokeswoman</td>\n",
              "      <td>in</td>\n",
              "      <td>Islamabad</td>\n",
              "      <td>B-geo</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31531</th>\n",
              "      <td>1414.0</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>NNP</td>\n",
              "      <td>Rhine-Westphalia</td>\n",
              "      <td>NNP</td>\n",
              "      <td>IN</td>\n",
              "      <td>NN</td>\n",
              "      <td>state</td>\n",
              "      <td>of</td>\n",
              "      <td>North</td>\n",
              "      <td>B-geo</td>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59082</th>\n",
              "      <td>1161.0</td>\n",
              "      <td>VBZ</td>\n",
              "      <td>has</td>\n",
              "      <td>NNP</td>\n",
              "      <td>II</td>\n",
              "      <td>NNP</td>\n",
              "      <td>NNP</td>\n",
              "      <td>NNP</td>\n",
              "      <td>Pope</td>\n",
              "      <td>John</td>\n",
              "      <td>Paul</td>\n",
              "      <td>I-per</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36555</th>\n",
              "      <td>140.0</td>\n",
              "      <td>VBN</td>\n",
              "      <td>asked</td>\n",
              "      <td>VBZ</td>\n",
              "      <td>has</td>\n",
              "      <td>NNP</td>\n",
              "      <td>NNP</td>\n",
              "      <td>VBD</td>\n",
              "      <td>said</td>\n",
              "      <td>General</td>\n",
              "      <td>Adam</td>\n",
              "      <td>I-per</td>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1937</th>\n",
              "      <td>84.0</td>\n",
              "      <td>JJ</td>\n",
              "      <td>Sudanese</td>\n",
              "      <td>VBD</td>\n",
              "      <td>accused</td>\n",
              "      <td>NNP</td>\n",
              "      <td>IN</td>\n",
              "      <td>NNS</td>\n",
              "      <td>forces</td>\n",
              "      <td>in</td>\n",
              "      <td>Darfur</td>\n",
              "      <td>B-geo</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45175</th>\n",
              "      <td>536.0</td>\n",
              "      <td>NNP</td>\n",
              "      <td>Saadoun</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>NN</td>\n",
              "      <td>NNP</td>\n",
              "      <td>DT</td>\n",
              "      <td>A</td>\n",
              "      <td>Sunni</td>\n",
              "      <td>Arab</td>\n",
              "      <td>I-gpe</td>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46673</th>\n",
              "      <td>598.0</td>\n",
              "      <td>DT</td>\n",
              "      <td>another</td>\n",
              "      <td>VBD</td>\n",
              "      <td>added</td>\n",
              "      <td>CD</td>\n",
              "      <td>IN</td>\n",
              "      <td>NNP</td>\n",
              "      <td>Trinidad</td>\n",
              "      <td>in</td>\n",
              "      <td>1910</td>\n",
              "      <td>B-tim</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5687</th>\n",
              "      <td>259.0</td>\n",
              "      <td>NNP</td>\n",
              "      <td>Council</td>\n",
              "      <td>NNP</td>\n",
              "      <td>Security</td>\n",
              "      <td>NNP</td>\n",
              "      <td>NNP</td>\n",
              "      <td>DT</td>\n",
              "      <td>the</td>\n",
              "      <td>United</td>\n",
              "      <td>Nations</td>\n",
              "      <td>I-org</td>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65989</th>\n",
              "      <td>1460.0</td>\n",
              "      <td>VBN</td>\n",
              "      <td>met</td>\n",
              "      <td>VBZ</td>\n",
              "      <td>has</td>\n",
              "      <td>NNP</td>\n",
              "      <td>NNP</td>\n",
              "      <td>NNP</td>\n",
              "      <td>Prosecutor</td>\n",
              "      <td>Patrick</td>\n",
              "      <td>Fitzgerald</td>\n",
              "      <td>I-org</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15298</th>\n",
              "      <td>691.0</td>\n",
              "      <td>__END1__</td>\n",
              "      <td>__END1__</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>NNP</td>\n",
              "      <td>NNP</td>\n",
              "      <td>DT</td>\n",
              "      <td>the</td>\n",
              "      <td>Minuteman</td>\n",
              "      <td>Project</td>\n",
              "      <td>I-org</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10443</th>\n",
              "      <td>478.0</td>\n",
              "      <td>NNS</td>\n",
              "      <td>camps</td>\n",
              "      <td>NN</td>\n",
              "      <td>refugee</td>\n",
              "      <td>NNP</td>\n",
              "      <td>DT</td>\n",
              "      <td>IN</td>\n",
              "      <td>through</td>\n",
              "      <td>the</td>\n",
              "      <td>Nablus</td>\n",
              "      <td>B-geo</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20427</th>\n",
              "      <td>922.0</td>\n",
              "      <td>WP</td>\n",
              "      <td>who</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>NNP</td>\n",
              "      <td>NNP</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>Mstislav</td>\n",
              "      <td>Rostropovich</td>\n",
              "      <td>I-per</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8975</th>\n",
              "      <td>409.0</td>\n",
              "      <td>NNP</td>\n",
              "      <td>Malaysia</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>NNP</td>\n",
              "      <td>,</td>\n",
              "      <td>NNP</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>,</td>\n",
              "      <td>Bangladesh</td>\n",
              "      <td>B-geo</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58322</th>\n",
              "      <td>1128.0</td>\n",
              "      <td>VBG</td>\n",
              "      <td>saying</td>\n",
              "      <td>IN</td>\n",
              "      <td>as</td>\n",
              "      <td>NNP</td>\n",
              "      <td>NNP</td>\n",
              "      <td>NN</td>\n",
              "      <td>director</td>\n",
              "      <td>Mohamed</td>\n",
              "      <td>Amiin</td>\n",
              "      <td>I-per</td>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32000</th>\n",
              "      <td>1434.0</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>NNS</td>\n",
              "      <td>families</td>\n",
              "      <td>JJ</td>\n",
              "      <td>CD</td>\n",
              "      <td>IN</td>\n",
              "      <td>between</td>\n",
              "      <td>two</td>\n",
              "      <td>Palestinian</td>\n",
              "      <td>B-gpe</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15287</th>\n",
              "      <td>691.0</td>\n",
              "      <td>NNPS</td>\n",
              "      <td>Rights</td>\n",
              "      <td>NNP</td>\n",
              "      <td>Human</td>\n",
              "      <td>IN</td>\n",
              "      <td>NNP</td>\n",
              "      <td>NNP</td>\n",
              "      <td>National</td>\n",
              "      <td>Alliance</td>\n",
              "      <td>for</td>\n",
              "      <td>I-org</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8246</th>\n",
              "      <td>377.0</td>\n",
              "      <td>VBD</td>\n",
              "      <td>triggered</td>\n",
              "      <td>NNP</td>\n",
              "      <td>Bakri</td>\n",
              "      <td>NNP</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>Mr.</td>\n",
              "      <td>B-per</td>\n",
              "      <td>68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25296</th>\n",
              "      <td>1145.0</td>\n",
              "      <td>__END1__</td>\n",
              "      <td>__END1__</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>NNP</td>\n",
              "      <td>IN</td>\n",
              "      <td>NN</td>\n",
              "      <td>production</td>\n",
              "      <td>in</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>B-geo</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44010</th>\n",
              "      <td>483.0</td>\n",
              "      <td>NN</td>\n",
              "      <td>capital</td>\n",
              "      <td>POS</td>\n",
              "      <td>'s</td>\n",
              "      <td>NNP</td>\n",
              "      <td>IN</td>\n",
              "      <td>IN</td>\n",
              "      <td>out</td>\n",
              "      <td>of</td>\n",
              "      <td>Somalia</td>\n",
              "      <td>B-gpe</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       sentence_idx next-next-pos next-next-word  ...          word    tag length\n",
              "62087        1288.0           WDT          which  ...        Accord  I-tim     78\n",
              "9265          422.0           VBD           said  ...     Islamabad  B-geo     66\n",
              "31531        1414.0             ,              ,  ...         North  B-geo     78\n",
              "59082        1161.0           VBZ            has  ...          Paul  I-per     66\n",
              "36555         140.0           VBN          asked  ...          Adam  I-per     76\n",
              "1937           84.0            JJ       Sudanese  ...        Darfur  B-geo     50\n",
              "45175         536.0           NNP        Saadoun  ...          Arab  I-gpe     58\n",
              "46673         598.0            DT        another  ...          1910  B-tim     26\n",
              "5687          259.0           NNP        Council  ...       Nations  I-org     58\n",
              "65989        1460.0           VBN            met  ...    Fitzgerald  I-org     46\n",
              "15298         691.0      __END1__       __END1__  ...       Project  I-org     40\n",
              "10443         478.0           NNS          camps  ...        Nablus  B-geo     48\n",
              "20427         922.0            WP            who  ...  Rostropovich  I-per     66\n",
              "8975          409.0           NNP       Malaysia  ...    Bangladesh  B-geo     54\n",
              "58322        1128.0           VBG         saying  ...         Amiin  I-per     70\n",
              "32000        1434.0             .              .  ...   Palestinian  B-gpe     48\n",
              "15287         691.0          NNPS         Rights  ...           for  I-org     40\n",
              "8246          377.0           VBD      triggered  ...           Mr.  B-per     68\n",
              "25296        1145.0      __END1__       __END1__  ...   Afghanistan  B-geo     34\n",
              "44010         483.0            NN        capital  ...       Somalia  B-gpe     48\n",
              "\n",
              "[20 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeBzpb3V3SSO",
        "colab_type": "text"
      },
      "source": [
        "Alright, so the target almost unilaterally start either with a capital letter or a numeric. This of course can be true also for sentence starts, but we'll leave to the model to distinguish that. Let's add these two binary features -- data engineering, for hell sake!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uK6F6pLb29ME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def starts_with_capital(word):\n",
        "  if not word:\n",
        "    return 0.0\n",
        "  return int(word[0].upper() == word[0] and word[0].lower() != word[0])\n",
        "\n",
        "def starts_with_number(word):\n",
        "  if not word:\n",
        "    return 0.0\n",
        "  return int(ord(word[0]) in range(ord(\"0\"), ord(\"9\")+1))\n",
        "\n",
        "df['capital_first'] = df.apply(lambda row: starts_with_capital(row.word), axis=1)\n",
        "df['number_first'] = df.apply(lambda row: starts_with_number(row.word), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqRZqADi5Kzk",
        "colab_type": "text"
      },
      "source": [
        "Let's check that:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8NljhDf5J6v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "outputId": "b8290506-8cc9-42bf-db55-b9856ab52250"
      },
      "source": [
        "df.loc[df.capital_first == 1].sample(5)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_idx</th>\n",
              "      <th>next-next-pos</th>\n",
              "      <th>next-next-word</th>\n",
              "      <th>next-pos</th>\n",
              "      <th>next-word</th>\n",
              "      <th>pos</th>\n",
              "      <th>prev-pos</th>\n",
              "      <th>prev-prev-pos</th>\n",
              "      <th>prev-prev-word</th>\n",
              "      <th>prev-word</th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "      <th>length</th>\n",
              "      <th>capital_first</th>\n",
              "      <th>number_first</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7025</th>\n",
              "      <td>320.0</td>\n",
              "      <td>JJ</td>\n",
              "      <td>next</td>\n",
              "      <td>IN</td>\n",
              "      <td>in</td>\n",
              "      <td>NNP</td>\n",
              "      <td>NNP</td>\n",
              "      <td>NNP</td>\n",
              "      <td>President</td>\n",
              "      <td>Yoweri</td>\n",
              "      <td>Museveni</td>\n",
              "      <td>I-per</td>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6557</th>\n",
              "      <td>300.0</td>\n",
              "      <td>NNS</td>\n",
              "      <td>officials</td>\n",
              "      <td>NNP</td>\n",
              "      <td>House</td>\n",
              "      <td>NNP</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>White</td>\n",
              "      <td>B-org</td>\n",
              "      <td>44</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51511</th>\n",
              "      <td>811.0</td>\n",
              "      <td>VBP</td>\n",
              "      <td>have</td>\n",
              "      <td>NNS</td>\n",
              "      <td>migrants</td>\n",
              "      <td>JJ</td>\n",
              "      <td>CD</td>\n",
              "      <td>IN</td>\n",
              "      <td>than</td>\n",
              "      <td>60</td>\n",
              "      <td>African</td>\n",
              "      <td>B-gpe</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5753</th>\n",
              "      <td>262.0</td>\n",
              "      <td>NNPS</td>\n",
              "      <td>Nations</td>\n",
              "      <td>NNP</td>\n",
              "      <td>United</td>\n",
              "      <td>DT</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>The</td>\n",
              "      <td>O</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8086</th>\n",
              "      <td>370.0</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>NNP</td>\n",
              "      <td>Hagino</td>\n",
              "      <td>NNP</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>Yu</td>\n",
              "      <td>B-per</td>\n",
              "      <td>42</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       sentence_idx next-next-pos  ... capital_first number_first\n",
              "7025          320.0            JJ  ...             1            0\n",
              "6557          300.0           NNS  ...             1            0\n",
              "51511         811.0           VBP  ...             1            0\n",
              "5753          262.0          NNPS  ...             1            0\n",
              "8086          370.0             ,  ...             1            0\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHKR8gvE5cZ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "55f6962e-bd07-4fe6-9e9b-f1f720b23a10"
      },
      "source": [
        "df.loc[df.number_first == 1].sample(5)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_idx</th>\n",
              "      <th>next-next-pos</th>\n",
              "      <th>next-next-word</th>\n",
              "      <th>next-pos</th>\n",
              "      <th>next-word</th>\n",
              "      <th>pos</th>\n",
              "      <th>prev-pos</th>\n",
              "      <th>prev-prev-pos</th>\n",
              "      <th>prev-prev-word</th>\n",
              "      <th>prev-word</th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "      <th>length</th>\n",
              "      <th>capital_first</th>\n",
              "      <th>number_first</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>45375</th>\n",
              "      <td>544.0</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>NN</td>\n",
              "      <td>percent</td>\n",
              "      <td>CD</td>\n",
              "      <td>VB</td>\n",
              "      <td>TO</td>\n",
              "      <td>to</td>\n",
              "      <td>hit</td>\n",
              "      <td>7.5</td>\n",
              "      <td>O</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17902</th>\n",
              "      <td>804.0</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>NNS</td>\n",
              "      <td>tsunamis</td>\n",
              "      <td>CD</td>\n",
              "      <td>NNP</td>\n",
              "      <td>DT</td>\n",
              "      <td>the</td>\n",
              "      <td>December</td>\n",
              "      <td>26</td>\n",
              "      <td>I-tim</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57144</th>\n",
              "      <td>1072.0</td>\n",
              "      <td>NNP</td>\n",
              "      <td>Mexico</td>\n",
              "      <td>IN</td>\n",
              "      <td>in</td>\n",
              "      <td>CD</td>\n",
              "      <td>NNP</td>\n",
              "      <td>VBZ</td>\n",
              "      <td>performs</td>\n",
              "      <td>March</td>\n",
              "      <td>17</td>\n",
              "      <td>I-tim</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1638</th>\n",
              "      <td>70.0</td>\n",
              "      <td>WDT</td>\n",
              "      <td>that</td>\n",
              "      <td>NNS</td>\n",
              "      <td>economies</td>\n",
              "      <td>CD</td>\n",
              "      <td>DT</td>\n",
              "      <td>IN</td>\n",
              "      <td>of</td>\n",
              "      <td>the</td>\n",
              "      <td>21</td>\n",
              "      <td>O</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16247</th>\n",
              "      <td>732.0</td>\n",
              "      <td>IN</td>\n",
              "      <td>from</td>\n",
              "      <td>CD</td>\n",
              "      <td>billion</td>\n",
              "      <td>CD</td>\n",
              "      <td>$</td>\n",
              "      <td>VB</td>\n",
              "      <td>raise</td>\n",
              "      <td>$</td>\n",
              "      <td>1.5</td>\n",
              "      <td>O</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       sentence_idx next-next-pos  ... capital_first number_first\n",
              "45375         544.0             .  ...             0            1\n",
              "17902         804.0             ,  ...             0            1\n",
              "57144        1072.0           NNP  ...             0            1\n",
              "1638           70.0           WDT  ...             0            1\n",
              "16247         732.0            IN  ...             0            1\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc_ukrt9bUeP",
        "colab_type": "text"
      },
      "source": [
        "This should give us **[1 point] for using feature engineering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsngOUF52PNa",
        "colab_type": "text"
      },
      "source": [
        "Now, let's look how the data is currently presented in the DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "70efb03f-8bdc-4063-f92e-3711123f5946",
        "id": "U_VvimXvGGTR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "df.loc[0]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentence_idx                  1\n",
              "next-next-pos               NNS\n",
              "next-next-word    demonstrators\n",
              "next-pos                     IN\n",
              "next-word                    of\n",
              "pos                         NNS\n",
              "prev-pos             __START1__\n",
              "prev-prev-pos        __START2__\n",
              "prev-prev-word       __START2__\n",
              "prev-word            __START1__\n",
              "word                  Thousands\n",
              "tag                           O\n",
              "length                       48\n",
              "capital_first                 1\n",
              "number_first                  0\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQAdXCV4tyR8",
        "colab_type": "code",
        "outputId": "42bb5b6b-33ad-4211-c9af-a0834b691675",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_idx</th>\n",
              "      <th>next-next-pos</th>\n",
              "      <th>next-next-word</th>\n",
              "      <th>next-pos</th>\n",
              "      <th>next-word</th>\n",
              "      <th>pos</th>\n",
              "      <th>prev-pos</th>\n",
              "      <th>prev-prev-pos</th>\n",
              "      <th>prev-prev-word</th>\n",
              "      <th>prev-word</th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "      <th>length</th>\n",
              "      <th>capital_first</th>\n",
              "      <th>number_first</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>NNS</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>IN</td>\n",
              "      <td>of</td>\n",
              "      <td>NNS</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>VBP</td>\n",
              "      <td>have</td>\n",
              "      <td>NNS</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>IN</td>\n",
              "      <td>NNS</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>VBN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBP</td>\n",
              "      <td>have</td>\n",
              "      <td>NNS</td>\n",
              "      <td>IN</td>\n",
              "      <td>NNS</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>of</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>IN</td>\n",
              "      <td>through</td>\n",
              "      <td>VBN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBP</td>\n",
              "      <td>NNS</td>\n",
              "      <td>IN</td>\n",
              "      <td>of</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>NNP</td>\n",
              "      <td>London</td>\n",
              "      <td>IN</td>\n",
              "      <td>through</td>\n",
              "      <td>VBN</td>\n",
              "      <td>VBP</td>\n",
              "      <td>NNS</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>have</td>\n",
              "      <td>marched</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentence_idx next-next-pos  ... capital_first number_first\n",
              "0           1.0           NNS  ...             1            0\n",
              "1           1.0           VBP  ...             0            0\n",
              "2           1.0           VBN  ...             0            0\n",
              "3           1.0            IN  ...             0            0\n",
              "4           1.0           NNP  ...             0            0\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umTkHjT7bdUI",
        "colab_type": "text"
      },
      "source": [
        "In order to use LightGBM, let's encode categorial variables (so it will encode them afterwards using its gimmicks):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZIPpkLjV31g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le = LabelEncoder()\n",
        "df['pos'] = le.fit_transform(df['pos'])\n",
        "df['next-pos'] = le.fit_transform(df['next-pos'])\n",
        "df['next-next-pos'] = le.fit_transform(df['next-next-pos'])\n",
        "df['prev-pos'] = le.fit_transform(df['prev-pos'])\n",
        "df['prev-prev-pos'] = le.fit_transform(df['prev-prev-pos'])\n",
        "df['word'] = le.fit_transform(df['word'])\n",
        "df['next-word'] = le.fit_transform(df['next-word'])\n",
        "df['next-next-word'] = le.fit_transform(df['next-next-word'])\n",
        "df['prev-word'] = le.fit_transform(df['prev-word'])\n",
        "df['prev-prev-word'] = le.fit_transform(df['prev-prev-word'])\n",
        "df['tag'] = le.fit_transform(df['tag'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWzEUnuHboyg",
        "colab_type": "text"
      },
      "source": [
        "Train-test splitting:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5HAGN-7tyR-",
        "colab_type": "code",
        "outputId": "8842b230-ad9a-4078-9ed9-7ac02a70ea6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "y = df.tag\n",
        "Ndf = df.drop(columns=['tag'])\n",
        "\n",
        "df_train, df_test, y_train, y_test = model_selection.train_test_split(Ndf, y, stratify=y, \n",
        "                                                                      test_size=0.25, random_state=SEED, shuffle=True)\n",
        "print('train', df_train.shape[0])\n",
        "print('test', df_test.shape[0])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train 50155\n",
            "test 16719\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWPBB8cZbtGe",
        "colab_type": "text"
      },
      "source": [
        "Finally, let's define and train the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZ_D1vz6UT1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = df_train\n",
        "X_test = df_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GF013xqpA9Ij",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9d0789f3-5df4-4637-ee0d-5abb95b3fcbe"
      },
      "source": [
        "num_train, num_feature = X_train.shape\n",
        "\n",
        "# create dataset for lightgbm\n",
        "# if you want to re-use data, remember to set free_raw_data=False\n",
        "lgb_train = lgb.Dataset(X_train, y_train, free_raw_data=False)\n",
        "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train, free_raw_data=False)\n",
        "\n",
        "# specify your configurations as a dict\n",
        "params = {\n",
        "    'boosting_type': 'gbdt',\n",
        "    'objective': 'multiclass',\n",
        "    'num_class': 17,\n",
        "    'metric': 'multi_logloss',\n",
        "    'num_leaves': 31,\n",
        "    'learning_rate': 0.05,\n",
        "    'feature_fraction': 0.9,\n",
        "    'bagging_fraction': 0.8,\n",
        "    'bagging_freq': 5,\n",
        "    'verbose': 0\n",
        "}\n",
        "\n",
        "feature_name = [\"sentence_idx\", \"next-next-pos\", \"next-next-word\", \"next-pos\",\n",
        "                \"next-word\", \"pos\", \"prev-pos\", \"prev-prev-pos\",\n",
        "                \"prev-prev-word\", \"prev-word\", \"word\", \"length\",\n",
        "                \"capital_first\", \"number_first\"]\n",
        "\n",
        "categorical_feature = [\"next-next-pos\", \"next-next-word\", \"next-pos\",\n",
        "                \"next-word\", \"pos\", \"prev-pos\", \"prev-prev-pos\",\n",
        "                \"prev-prev-word\", \"prev-word\", \"word\",\n",
        "                \"capital_first\", \"number_first\"]\n",
        "\n",
        "print('Starting training...')\n",
        "# feature_name and categorical_feature\n",
        "gbm = lgb.train(params,\n",
        "                lgb_train,\n",
        "                num_boost_round=5000,\n",
        "                early_stopping_rounds=10,\n",
        "                valid_sets=lgb_train,  # eval training data\n",
        "                feature_name=feature_name,\n",
        "                categorical_feature=categorical_feature)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting training...\n",
            "[1]\ttraining's multi_logloss: 0.623104\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\ttraining's multi_logloss: 0.561878\n",
            "[3]\ttraining's multi_logloss: 0.51764\n",
            "[4]\ttraining's multi_logloss: 0.481741\n",
            "[5]\ttraining's multi_logloss: 0.452418\n",
            "[6]\ttraining's multi_logloss: 0.426806\n",
            "[7]\ttraining's multi_logloss: 0.403427\n",
            "[8]\ttraining's multi_logloss: 0.383223\n",
            "[9]\ttraining's multi_logloss: 0.365496\n",
            "[10]\ttraining's multi_logloss: 0.348794\n",
            "[11]\ttraining's multi_logloss: 0.333315\n",
            "[12]\ttraining's multi_logloss: 0.318778\n",
            "[13]\ttraining's multi_logloss: 0.305576\n",
            "[14]\ttraining's multi_logloss: 0.293313\n",
            "[15]\ttraining's multi_logloss: 0.281972\n",
            "[16]\ttraining's multi_logloss: 0.271188\n",
            "[17]\ttraining's multi_logloss: 0.261288\n",
            "[18]\ttraining's multi_logloss: 0.25185\n",
            "[19]\ttraining's multi_logloss: 0.243074\n",
            "[20]\ttraining's multi_logloss: 0.23489\n",
            "[21]\ttraining's multi_logloss: 0.226983\n",
            "[22]\ttraining's multi_logloss: 0.219659\n",
            "[23]\ttraining's multi_logloss: 0.212581\n",
            "[24]\ttraining's multi_logloss: 0.20593\n",
            "[25]\ttraining's multi_logloss: 0.19963\n",
            "[26]\ttraining's multi_logloss: 0.193424\n",
            "[27]\ttraining's multi_logloss: 0.187715\n",
            "[28]\ttraining's multi_logloss: 0.182233\n",
            "[29]\ttraining's multi_logloss: 0.177019\n",
            "[30]\ttraining's multi_logloss: 0.172055\n",
            "[31]\ttraining's multi_logloss: 0.167249\n",
            "[32]\ttraining's multi_logloss: 0.162651\n",
            "[33]\ttraining's multi_logloss: 0.158154\n",
            "[34]\ttraining's multi_logloss: 0.153916\n",
            "[35]\ttraining's multi_logloss: 0.14993\n",
            "[36]\ttraining's multi_logloss: 0.146148\n",
            "[37]\ttraining's multi_logloss: 0.142486\n",
            "[38]\ttraining's multi_logloss: 0.138952\n",
            "[39]\ttraining's multi_logloss: 0.135578\n",
            "[40]\ttraining's multi_logloss: 0.132385\n",
            "[41]\ttraining's multi_logloss: 0.129163\n",
            "[42]\ttraining's multi_logloss: 0.126096\n",
            "[43]\ttraining's multi_logloss: 0.123146\n",
            "[44]\ttraining's multi_logloss: 0.120236\n",
            "[45]\ttraining's multi_logloss: 0.11757\n",
            "[46]\ttraining's multi_logloss: 0.114969\n",
            "[47]\ttraining's multi_logloss: 0.112401\n",
            "[48]\ttraining's multi_logloss: 0.109935\n",
            "[49]\ttraining's multi_logloss: 0.107567\n",
            "[50]\ttraining's multi_logloss: 0.105289\n",
            "[51]\ttraining's multi_logloss: 0.103059\n",
            "[52]\ttraining's multi_logloss: 0.100985\n",
            "[53]\ttraining's multi_logloss: 0.0989393\n",
            "[54]\ttraining's multi_logloss: 0.0969631\n",
            "[55]\ttraining's multi_logloss: 0.0950646\n",
            "[56]\ttraining's multi_logloss: 0.0931643\n",
            "[57]\ttraining's multi_logloss: 0.0912591\n",
            "[58]\ttraining's multi_logloss: 0.0894296\n",
            "[59]\ttraining's multi_logloss: 0.0876615\n",
            "[60]\ttraining's multi_logloss: 0.0859972\n",
            "[61]\ttraining's multi_logloss: 0.0843393\n",
            "[62]\ttraining's multi_logloss: 0.0827641\n",
            "[63]\ttraining's multi_logloss: 0.0811183\n",
            "[64]\ttraining's multi_logloss: 0.0795728\n",
            "[65]\ttraining's multi_logloss: 0.0780555\n",
            "[66]\ttraining's multi_logloss: 0.0765813\n",
            "[67]\ttraining's multi_logloss: 0.0751525\n",
            "[68]\ttraining's multi_logloss: 0.0738177\n",
            "[69]\ttraining's multi_logloss: 0.0724933\n",
            "[70]\ttraining's multi_logloss: 0.0712365\n",
            "[71]\ttraining's multi_logloss: 0.0700223\n",
            "[72]\ttraining's multi_logloss: 0.0687634\n",
            "[73]\ttraining's multi_logloss: 0.0676157\n",
            "[74]\ttraining's multi_logloss: 0.0664705\n",
            "[75]\ttraining's multi_logloss: 0.0653773\n",
            "[76]\ttraining's multi_logloss: 0.0642029\n",
            "[77]\ttraining's multi_logloss: 0.0630674\n",
            "[78]\ttraining's multi_logloss: 0.0620541\n",
            "[79]\ttraining's multi_logloss: 0.0609741\n",
            "[80]\ttraining's multi_logloss: 0.0599114\n",
            "[81]\ttraining's multi_logloss: 0.0589401\n",
            "[82]\ttraining's multi_logloss: 0.05799\n",
            "[83]\ttraining's multi_logloss: 0.0570436\n",
            "[84]\ttraining's multi_logloss: 0.0560887\n",
            "[85]\ttraining's multi_logloss: 0.0552077\n",
            "[86]\ttraining's multi_logloss: 0.0543481\n",
            "[87]\ttraining's multi_logloss: 0.053456\n",
            "[88]\ttraining's multi_logloss: 0.0526067\n",
            "[89]\ttraining's multi_logloss: 0.0517868\n",
            "[90]\ttraining's multi_logloss: 0.0510161\n",
            "[91]\ttraining's multi_logloss: 0.050185\n",
            "[92]\ttraining's multi_logloss: 0.049372\n",
            "[93]\ttraining's multi_logloss: 0.0486051\n",
            "[94]\ttraining's multi_logloss: 0.0478575\n",
            "[95]\ttraining's multi_logloss: 0.0471025\n",
            "[96]\ttraining's multi_logloss: 0.0463979\n",
            "[97]\ttraining's multi_logloss: 0.0457268\n",
            "[98]\ttraining's multi_logloss: 0.0450322\n",
            "[99]\ttraining's multi_logloss: 0.0443793\n",
            "[100]\ttraining's multi_logloss: 0.0437565\n",
            "[101]\ttraining's multi_logloss: 0.0431144\n",
            "[102]\ttraining's multi_logloss: 0.0424954\n",
            "[103]\ttraining's multi_logloss: 0.0418728\n",
            "[104]\ttraining's multi_logloss: 0.041247\n",
            "[105]\ttraining's multi_logloss: 0.0406887\n",
            "[106]\ttraining's multi_logloss: 0.0400977\n",
            "[107]\ttraining's multi_logloss: 0.0395176\n",
            "[108]\ttraining's multi_logloss: 0.038965\n",
            "[109]\ttraining's multi_logloss: 0.0384452\n",
            "[110]\ttraining's multi_logloss: 0.0378979\n",
            "[111]\ttraining's multi_logloss: 0.0373518\n",
            "[112]\ttraining's multi_logloss: 0.0368472\n",
            "[113]\ttraining's multi_logloss: 0.0363377\n",
            "[114]\ttraining's multi_logloss: 0.0358453\n",
            "[115]\ttraining's multi_logloss: 0.0353351\n",
            "[116]\ttraining's multi_logloss: 0.0348383\n",
            "[117]\ttraining's multi_logloss: 0.0343476\n",
            "[118]\ttraining's multi_logloss: 0.0338527\n",
            "[119]\ttraining's multi_logloss: 0.0333723\n",
            "[120]\ttraining's multi_logloss: 0.0329072\n",
            "[121]\ttraining's multi_logloss: 0.0324628\n",
            "[122]\ttraining's multi_logloss: 0.0320645\n",
            "[123]\ttraining's multi_logloss: 0.0316526\n",
            "[124]\ttraining's multi_logloss: 0.031236\n",
            "[125]\ttraining's multi_logloss: 0.0308167\n",
            "[126]\ttraining's multi_logloss: 0.0304241\n",
            "[127]\ttraining's multi_logloss: 0.0300108\n",
            "[128]\ttraining's multi_logloss: 0.0296262\n",
            "[129]\ttraining's multi_logloss: 0.0292234\n",
            "[130]\ttraining's multi_logloss: 0.0288541\n",
            "[131]\ttraining's multi_logloss: 0.0284734\n",
            "[132]\ttraining's multi_logloss: 0.0281169\n",
            "[133]\ttraining's multi_logloss: 0.02776\n",
            "[134]\ttraining's multi_logloss: 0.027424\n",
            "[135]\ttraining's multi_logloss: 0.0270844\n",
            "[136]\ttraining's multi_logloss: 0.0267539\n",
            "[137]\ttraining's multi_logloss: 0.0264257\n",
            "[138]\ttraining's multi_logloss: 0.0261152\n",
            "[139]\ttraining's multi_logloss: 0.0257945\n",
            "[140]\ttraining's multi_logloss: 0.0254984\n",
            "[141]\ttraining's multi_logloss: 0.0251859\n",
            "[142]\ttraining's multi_logloss: 0.024885\n",
            "[143]\ttraining's multi_logloss: 0.0245858\n",
            "[144]\ttraining's multi_logloss: 0.0242878\n",
            "[145]\ttraining's multi_logloss: 0.0240011\n",
            "[146]\ttraining's multi_logloss: 0.023703\n",
            "[147]\ttraining's multi_logloss: 0.0234249\n",
            "[148]\ttraining's multi_logloss: 0.0231398\n",
            "[149]\ttraining's multi_logloss: 0.0228672\n",
            "[150]\ttraining's multi_logloss: 0.022599\n",
            "[151]\ttraining's multi_logloss: 0.0223219\n",
            "[152]\ttraining's multi_logloss: 0.0220572\n",
            "[153]\ttraining's multi_logloss: 0.0218015\n",
            "[154]\ttraining's multi_logloss: 0.0215413\n",
            "[155]\ttraining's multi_logloss: 0.021298\n",
            "[156]\ttraining's multi_logloss: 0.0210396\n",
            "[157]\ttraining's multi_logloss: 0.0208037\n",
            "[158]\ttraining's multi_logloss: 0.0205528\n",
            "[159]\ttraining's multi_logloss: 0.020314\n",
            "[160]\ttraining's multi_logloss: 0.0200852\n",
            "[161]\ttraining's multi_logloss: 0.0198462\n",
            "[162]\ttraining's multi_logloss: 0.0196042\n",
            "[163]\ttraining's multi_logloss: 0.0193825\n",
            "[164]\ttraining's multi_logloss: 0.0191595\n",
            "[165]\ttraining's multi_logloss: 0.0189455\n",
            "[166]\ttraining's multi_logloss: 0.0187365\n",
            "[167]\ttraining's multi_logloss: 0.0185189\n",
            "[168]\ttraining's multi_logloss: 0.0183124\n",
            "[169]\ttraining's multi_logloss: 0.0181059\n",
            "[170]\ttraining's multi_logloss: 0.0179007\n",
            "[171]\ttraining's multi_logloss: 0.0177093\n",
            "[172]\ttraining's multi_logloss: 0.0175204\n",
            "[173]\ttraining's multi_logloss: 0.0173283\n",
            "[174]\ttraining's multi_logloss: 0.0171489\n",
            "[175]\ttraining's multi_logloss: 0.0169735\n",
            "[176]\ttraining's multi_logloss: 0.0167824\n",
            "[177]\ttraining's multi_logloss: 0.0165895\n",
            "[178]\ttraining's multi_logloss: 0.0164083\n",
            "[179]\ttraining's multi_logloss: 0.016222\n",
            "[180]\ttraining's multi_logloss: 0.016038\n",
            "[181]\ttraining's multi_logloss: 0.0158598\n",
            "[182]\ttraining's multi_logloss: 0.0156883\n",
            "[183]\ttraining's multi_logloss: 0.0155295\n",
            "[184]\ttraining's multi_logloss: 0.0153711\n",
            "[185]\ttraining's multi_logloss: 0.0152139\n",
            "[186]\ttraining's multi_logloss: 0.015058\n",
            "[187]\ttraining's multi_logloss: 0.0148998\n",
            "[188]\ttraining's multi_logloss: 0.0147416\n",
            "[189]\ttraining's multi_logloss: 0.0145849\n",
            "[190]\ttraining's multi_logloss: 0.0144391\n",
            "[191]\ttraining's multi_logloss: 0.0142853\n",
            "[192]\ttraining's multi_logloss: 0.0141419\n",
            "[193]\ttraining's multi_logloss: 0.0139951\n",
            "[194]\ttraining's multi_logloss: 0.0138541\n",
            "[195]\ttraining's multi_logloss: 0.0137091\n",
            "[196]\ttraining's multi_logloss: 0.0135572\n",
            "[197]\ttraining's multi_logloss: 0.0134182\n",
            "[198]\ttraining's multi_logloss: 0.0132859\n",
            "[199]\ttraining's multi_logloss: 0.0131459\n",
            "[200]\ttraining's multi_logloss: 0.0130112\n",
            "[201]\ttraining's multi_logloss: 0.0128789\n",
            "[202]\ttraining's multi_logloss: 0.0127453\n",
            "[203]\ttraining's multi_logloss: 0.012619\n",
            "[204]\ttraining's multi_logloss: 0.0124945\n",
            "[205]\ttraining's multi_logloss: 0.0123612\n",
            "[206]\ttraining's multi_logloss: 0.0122317\n",
            "[207]\ttraining's multi_logloss: 0.0121091\n",
            "[208]\ttraining's multi_logloss: 0.0119865\n",
            "[209]\ttraining's multi_logloss: 0.0118704\n",
            "[210]\ttraining's multi_logloss: 0.0117513\n",
            "[211]\ttraining's multi_logloss: 0.0116322\n",
            "[212]\ttraining's multi_logloss: 0.0115222\n",
            "[213]\ttraining's multi_logloss: 0.0114113\n",
            "[214]\ttraining's multi_logloss: 0.0113018\n",
            "[215]\ttraining's multi_logloss: 0.0111967\n",
            "[216]\ttraining's multi_logloss: 0.0110889\n",
            "[217]\ttraining's multi_logloss: 0.0109782\n",
            "[218]\ttraining's multi_logloss: 0.0108725\n",
            "[219]\ttraining's multi_logloss: 0.010773\n",
            "[220]\ttraining's multi_logloss: 0.0106713\n",
            "[221]\ttraining's multi_logloss: 0.0105651\n",
            "[222]\ttraining's multi_logloss: 0.0104698\n",
            "[223]\ttraining's multi_logloss: 0.0103747\n",
            "[224]\ttraining's multi_logloss: 0.0102716\n",
            "[225]\ttraining's multi_logloss: 0.0101738\n",
            "[226]\ttraining's multi_logloss: 0.0100869\n",
            "[227]\ttraining's multi_logloss: 0.00998708\n",
            "[228]\ttraining's multi_logloss: 0.00988975\n",
            "[229]\ttraining's multi_logloss: 0.00980206\n",
            "[230]\ttraining's multi_logloss: 0.00971307\n",
            "[231]\ttraining's multi_logloss: 0.00962236\n",
            "[232]\ttraining's multi_logloss: 0.00952599\n",
            "[233]\ttraining's multi_logloss: 0.00942687\n",
            "[234]\ttraining's multi_logloss: 0.00934354\n",
            "[235]\ttraining's multi_logloss: 0.00925343\n",
            "[236]\ttraining's multi_logloss: 0.00916836\n",
            "[237]\ttraining's multi_logloss: 0.00908083\n",
            "[238]\ttraining's multi_logloss: 0.00900253\n",
            "[239]\ttraining's multi_logloss: 0.00891432\n",
            "[240]\ttraining's multi_logloss: 0.00883391\n",
            "[241]\ttraining's multi_logloss: 0.00874952\n",
            "[242]\ttraining's multi_logloss: 0.0086799\n",
            "[243]\ttraining's multi_logloss: 0.00859919\n",
            "[244]\ttraining's multi_logloss: 0.00852303\n",
            "[245]\ttraining's multi_logloss: 0.00844269\n",
            "[246]\ttraining's multi_logloss: 0.00836525\n",
            "[247]\ttraining's multi_logloss: 0.00828637\n",
            "[248]\ttraining's multi_logloss: 0.00821364\n",
            "[249]\ttraining's multi_logloss: 0.00814445\n",
            "[250]\ttraining's multi_logloss: 0.00807363\n",
            "[251]\ttraining's multi_logloss: 0.00800052\n",
            "[252]\ttraining's multi_logloss: 0.00792285\n",
            "[253]\ttraining's multi_logloss: 0.00784992\n",
            "[254]\ttraining's multi_logloss: 0.00777692\n",
            "[255]\ttraining's multi_logloss: 0.00771141\n",
            "[256]\ttraining's multi_logloss: 0.00763976\n",
            "[257]\ttraining's multi_logloss: 0.00757088\n",
            "[258]\ttraining's multi_logloss: 0.00750205\n",
            "[259]\ttraining's multi_logloss: 0.00743246\n",
            "[260]\ttraining's multi_logloss: 0.00736464\n",
            "[261]\ttraining's multi_logloss: 0.00730075\n",
            "[262]\ttraining's multi_logloss: 0.00723933\n",
            "[263]\ttraining's multi_logloss: 0.00717716\n",
            "[264]\ttraining's multi_logloss: 0.00711266\n",
            "[265]\ttraining's multi_logloss: 0.00705401\n",
            "[266]\ttraining's multi_logloss: 0.00699276\n",
            "[267]\ttraining's multi_logloss: 0.00693148\n",
            "[268]\ttraining's multi_logloss: 0.00687188\n",
            "[269]\ttraining's multi_logloss: 0.00681649\n",
            "[270]\ttraining's multi_logloss: 0.00675511\n",
            "[271]\ttraining's multi_logloss: 0.00669438\n",
            "[272]\ttraining's multi_logloss: 0.00663669\n",
            "[273]\ttraining's multi_logloss: 0.00657961\n",
            "[274]\ttraining's multi_logloss: 0.00652351\n",
            "[275]\ttraining's multi_logloss: 0.00646715\n",
            "[276]\ttraining's multi_logloss: 0.00640623\n",
            "[277]\ttraining's multi_logloss: 0.00635007\n",
            "[278]\ttraining's multi_logloss: 0.00629444\n",
            "[279]\ttraining's multi_logloss: 0.00624197\n",
            "[280]\ttraining's multi_logloss: 0.00618692\n",
            "[281]\ttraining's multi_logloss: 0.00613123\n",
            "[282]\ttraining's multi_logloss: 0.00607402\n",
            "[283]\ttraining's multi_logloss: 0.00602347\n",
            "[284]\ttraining's multi_logloss: 0.00597477\n",
            "[285]\ttraining's multi_logloss: 0.00592595\n",
            "[286]\ttraining's multi_logloss: 0.00587591\n",
            "[287]\ttraining's multi_logloss: 0.00582839\n",
            "[288]\ttraining's multi_logloss: 0.00578397\n",
            "[289]\ttraining's multi_logloss: 0.0057375\n",
            "[290]\ttraining's multi_logloss: 0.00569208\n",
            "[291]\ttraining's multi_logloss: 0.00564435\n",
            "[292]\ttraining's multi_logloss: 0.00559553\n",
            "[293]\ttraining's multi_logloss: 0.00554715\n",
            "[294]\ttraining's multi_logloss: 0.00549765\n",
            "[295]\ttraining's multi_logloss: 0.00545001\n",
            "[296]\ttraining's multi_logloss: 0.00540421\n",
            "[297]\ttraining's multi_logloss: 0.00536381\n",
            "[298]\ttraining's multi_logloss: 0.00532154\n",
            "[299]\ttraining's multi_logloss: 0.00527953\n",
            "[300]\ttraining's multi_logloss: 0.00523999\n",
            "[301]\ttraining's multi_logloss: 0.0051979\n",
            "[302]\ttraining's multi_logloss: 0.00515479\n",
            "[303]\ttraining's multi_logloss: 0.00511348\n",
            "[304]\ttraining's multi_logloss: 0.00507217\n",
            "[305]\ttraining's multi_logloss: 0.00503028\n",
            "[306]\ttraining's multi_logloss: 0.00498793\n",
            "[307]\ttraining's multi_logloss: 0.00494522\n",
            "[308]\ttraining's multi_logloss: 0.0049035\n",
            "[309]\ttraining's multi_logloss: 0.00486223\n",
            "[310]\ttraining's multi_logloss: 0.00481916\n",
            "[311]\ttraining's multi_logloss: 0.00478103\n",
            "[312]\ttraining's multi_logloss: 0.00474247\n",
            "[313]\ttraining's multi_logloss: 0.00470068\n",
            "[314]\ttraining's multi_logloss: 0.00466478\n",
            "[315]\ttraining's multi_logloss: 0.00462903\n",
            "[316]\ttraining's multi_logloss: 0.00459039\n",
            "[317]\ttraining's multi_logloss: 0.00455578\n",
            "[318]\ttraining's multi_logloss: 0.00452093\n",
            "[319]\ttraining's multi_logloss: 0.00448464\n",
            "[320]\ttraining's multi_logloss: 0.00444786\n",
            "[321]\ttraining's multi_logloss: 0.00441373\n",
            "[322]\ttraining's multi_logloss: 0.00437874\n",
            "[323]\ttraining's multi_logloss: 0.00434327\n",
            "[324]\ttraining's multi_logloss: 0.00431294\n",
            "[325]\ttraining's multi_logloss: 0.00427898\n",
            "[326]\ttraining's multi_logloss: 0.00424373\n",
            "[327]\ttraining's multi_logloss: 0.00420966\n",
            "[328]\ttraining's multi_logloss: 0.00417698\n",
            "[329]\ttraining's multi_logloss: 0.00414772\n",
            "[330]\ttraining's multi_logloss: 0.00411705\n",
            "[331]\ttraining's multi_logloss: 0.00408569\n",
            "[332]\ttraining's multi_logloss: 0.00405472\n",
            "[333]\ttraining's multi_logloss: 0.00402319\n",
            "[334]\ttraining's multi_logloss: 0.00399184\n",
            "[335]\ttraining's multi_logloss: 0.00395953\n",
            "[336]\ttraining's multi_logloss: 0.00392724\n",
            "[337]\ttraining's multi_logloss: 0.00389745\n",
            "[338]\ttraining's multi_logloss: 0.00386832\n",
            "[339]\ttraining's multi_logloss: 0.00383762\n",
            "[340]\ttraining's multi_logloss: 0.0038085\n",
            "[341]\ttraining's multi_logloss: 0.0037799\n",
            "[342]\ttraining's multi_logloss: 0.00375135\n",
            "[343]\ttraining's multi_logloss: 0.0037224\n",
            "[344]\ttraining's multi_logloss: 0.00369565\n",
            "[345]\ttraining's multi_logloss: 0.00366805\n",
            "[346]\ttraining's multi_logloss: 0.0036428\n",
            "[347]\ttraining's multi_logloss: 0.00361554\n",
            "[348]\ttraining's multi_logloss: 0.00359205\n",
            "[349]\ttraining's multi_logloss: 0.00356589\n",
            "[350]\ttraining's multi_logloss: 0.00354015\n",
            "[351]\ttraining's multi_logloss: 0.00351068\n",
            "[352]\ttraining's multi_logloss: 0.00348362\n",
            "[353]\ttraining's multi_logloss: 0.0034557\n",
            "[354]\ttraining's multi_logloss: 0.00342714\n",
            "[355]\ttraining's multi_logloss: 0.00339998\n",
            "[356]\ttraining's multi_logloss: 0.00337344\n",
            "[357]\ttraining's multi_logloss: 0.00334895\n",
            "[358]\ttraining's multi_logloss: 0.00332617\n",
            "[359]\ttraining's multi_logloss: 0.00330212\n",
            "[360]\ttraining's multi_logloss: 0.00327756\n",
            "[361]\ttraining's multi_logloss: 0.00324271\n",
            "[362]\ttraining's multi_logloss: 0.00321982\n",
            "[363]\ttraining's multi_logloss: 0.00319296\n",
            "[364]\ttraining's multi_logloss: 0.00316423\n",
            "[365]\ttraining's multi_logloss: 0.00314005\n",
            "[366]\ttraining's multi_logloss: 0.00311225\n",
            "[367]\ttraining's multi_logloss: 0.0030865\n",
            "[368]\ttraining's multi_logloss: 0.00306098\n",
            "[369]\ttraining's multi_logloss: 0.00303756\n",
            "[370]\ttraining's multi_logloss: 0.00301401\n",
            "[371]\ttraining's multi_logloss: 0.00299014\n",
            "[372]\ttraining's multi_logloss: 0.00296551\n",
            "[373]\ttraining's multi_logloss: 0.00294346\n",
            "[374]\ttraining's multi_logloss: 0.00292252\n",
            "[375]\ttraining's multi_logloss: 0.00290097\n",
            "[376]\ttraining's multi_logloss: 0.00287754\n",
            "[377]\ttraining's multi_logloss: 0.00285565\n",
            "[378]\ttraining's multi_logloss: 0.00283369\n",
            "[379]\ttraining's multi_logloss: 0.0028134\n",
            "[380]\ttraining's multi_logloss: 0.00279377\n",
            "[381]\ttraining's multi_logloss: 0.00277355\n",
            "[382]\ttraining's multi_logloss: 0.00275223\n",
            "[383]\ttraining's multi_logloss: 0.00273071\n",
            "[384]\ttraining's multi_logloss: 0.0027108\n",
            "[385]\ttraining's multi_logloss: 0.00268947\n",
            "[386]\ttraining's multi_logloss: 0.00266838\n",
            "[387]\ttraining's multi_logloss: 0.00264871\n",
            "[388]\ttraining's multi_logloss: 0.00262957\n",
            "[389]\ttraining's multi_logloss: 0.00260959\n",
            "[390]\ttraining's multi_logloss: 0.00259221\n",
            "[391]\ttraining's multi_logloss: 0.00257414\n",
            "[392]\ttraining's multi_logloss: 0.00255481\n",
            "[393]\ttraining's multi_logloss: 0.00253658\n",
            "[394]\ttraining's multi_logloss: 0.00251855\n",
            "[395]\ttraining's multi_logloss: 0.00250156\n",
            "[396]\ttraining's multi_logloss: 0.00248468\n",
            "[397]\ttraining's multi_logloss: 0.0024666\n",
            "[398]\ttraining's multi_logloss: 0.00245059\n",
            "[399]\ttraining's multi_logloss: 0.00243418\n",
            "[400]\ttraining's multi_logloss: 0.00241843\n",
            "[401]\ttraining's multi_logloss: 0.0024017\n",
            "[402]\ttraining's multi_logloss: 0.00238586\n",
            "[403]\ttraining's multi_logloss: 0.00236899\n",
            "[404]\ttraining's multi_logloss: 0.00235394\n",
            "[405]\ttraining's multi_logloss: 0.0023376\n",
            "[406]\ttraining's multi_logloss: 0.00232034\n",
            "[407]\ttraining's multi_logloss: 0.00230313\n",
            "[408]\ttraining's multi_logloss: 0.00229069\n",
            "[409]\ttraining's multi_logloss: 0.00227522\n",
            "[410]\ttraining's multi_logloss: 0.00226096\n",
            "[411]\ttraining's multi_logloss: 0.00224501\n",
            "[412]\ttraining's multi_logloss: 0.00223038\n",
            "[413]\ttraining's multi_logloss: 0.00221445\n",
            "[414]\ttraining's multi_logloss: 0.00219941\n",
            "[415]\ttraining's multi_logloss: 0.00218594\n",
            "[416]\ttraining's multi_logloss: 0.00216943\n",
            "[417]\ttraining's multi_logloss: 0.00215359\n",
            "[418]\ttraining's multi_logloss: 0.00213807\n",
            "[419]\ttraining's multi_logloss: 0.00212286\n",
            "[420]\ttraining's multi_logloss: 0.00210841\n",
            "[421]\ttraining's multi_logloss: 0.0020935\n",
            "[422]\ttraining's multi_logloss: 0.00207975\n",
            "[423]\ttraining's multi_logloss: 0.00206597\n",
            "[424]\ttraining's multi_logloss: 0.00205297\n",
            "[425]\ttraining's multi_logloss: 0.00203966\n",
            "[426]\ttraining's multi_logloss: 0.00202664\n",
            "[427]\ttraining's multi_logloss: 0.00201334\n",
            "[428]\ttraining's multi_logloss: 0.0019991\n",
            "[429]\ttraining's multi_logloss: 0.00198696\n",
            "[430]\ttraining's multi_logloss: 0.00197408\n",
            "[431]\ttraining's multi_logloss: 0.00196176\n",
            "[432]\ttraining's multi_logloss: 0.00194929\n",
            "[433]\ttraining's multi_logloss: 0.00193692\n",
            "[434]\ttraining's multi_logloss: 0.0019247\n",
            "[435]\ttraining's multi_logloss: 0.0019115\n",
            "[436]\ttraining's multi_logloss: 0.0018987\n",
            "[437]\ttraining's multi_logloss: 0.00188597\n",
            "[438]\ttraining's multi_logloss: 0.00187356\n",
            "[439]\ttraining's multi_logloss: 0.00186112\n",
            "[440]\ttraining's multi_logloss: 0.00184814\n",
            "[441]\ttraining's multi_logloss: 0.00183572\n",
            "[442]\ttraining's multi_logloss: 0.00182396\n",
            "[443]\ttraining's multi_logloss: 0.00181271\n",
            "[444]\ttraining's multi_logloss: 0.00180073\n",
            "[445]\ttraining's multi_logloss: 0.00178875\n",
            "[446]\ttraining's multi_logloss: 0.00177651\n",
            "[447]\ttraining's multi_logloss: 0.00176421\n",
            "[448]\ttraining's multi_logloss: 0.00175219\n",
            "[449]\ttraining's multi_logloss: 0.00173913\n",
            "[450]\ttraining's multi_logloss: 0.00172708\n",
            "[451]\ttraining's multi_logloss: 0.00171463\n",
            "[452]\ttraining's multi_logloss: 0.00170428\n",
            "[453]\ttraining's multi_logloss: 0.00169375\n",
            "[454]\ttraining's multi_logloss: 0.00168258\n",
            "[455]\ttraining's multi_logloss: 0.00167114\n",
            "[456]\ttraining's multi_logloss: 0.00166021\n",
            "[457]\ttraining's multi_logloss: 0.00165031\n",
            "[458]\ttraining's multi_logloss: 0.00163997\n",
            "[459]\ttraining's multi_logloss: 0.00162992\n",
            "[460]\ttraining's multi_logloss: 0.00162007\n",
            "[461]\ttraining's multi_logloss: 0.00160967\n",
            "[462]\ttraining's multi_logloss: 0.00159977\n",
            "[463]\ttraining's multi_logloss: 0.00159016\n",
            "[464]\ttraining's multi_logloss: 0.00158003\n",
            "[465]\ttraining's multi_logloss: 0.00156891\n",
            "[466]\ttraining's multi_logloss: 0.00155893\n",
            "[467]\ttraining's multi_logloss: 0.00155028\n",
            "[468]\ttraining's multi_logloss: 0.00153997\n",
            "[469]\ttraining's multi_logloss: 0.00153016\n",
            "[470]\ttraining's multi_logloss: 0.00151982\n",
            "[471]\ttraining's multi_logloss: 0.00150986\n",
            "[472]\ttraining's multi_logloss: 0.0014989\n",
            "[473]\ttraining's multi_logloss: 0.00149049\n",
            "[474]\ttraining's multi_logloss: 0.00148021\n",
            "[475]\ttraining's multi_logloss: 0.00147077\n",
            "[476]\ttraining's multi_logloss: 0.00146122\n",
            "[477]\ttraining's multi_logloss: 0.00145093\n",
            "[478]\ttraining's multi_logloss: 0.00144171\n",
            "[479]\ttraining's multi_logloss: 0.00143249\n",
            "[480]\ttraining's multi_logloss: 0.00142431\n",
            "[481]\ttraining's multi_logloss: 0.00141413\n",
            "[482]\ttraining's multi_logloss: 0.00140419\n",
            "[483]\ttraining's multi_logloss: 0.0013947\n",
            "[484]\ttraining's multi_logloss: 0.00138541\n",
            "[485]\ttraining's multi_logloss: 0.00137638\n",
            "[486]\ttraining's multi_logloss: 0.00136743\n",
            "[487]\ttraining's multi_logloss: 0.00135848\n",
            "[488]\ttraining's multi_logloss: 0.00134966\n",
            "[489]\ttraining's multi_logloss: 0.00134145\n",
            "[490]\ttraining's multi_logloss: 0.0013334\n",
            "[491]\ttraining's multi_logloss: 0.00132561\n",
            "[492]\ttraining's multi_logloss: 0.00131729\n",
            "[493]\ttraining's multi_logloss: 0.0013094\n",
            "[494]\ttraining's multi_logloss: 0.00130118\n",
            "[495]\ttraining's multi_logloss: 0.0012933\n",
            "[496]\ttraining's multi_logloss: 0.0012857\n",
            "[497]\ttraining's multi_logloss: 0.00127758\n",
            "[498]\ttraining's multi_logloss: 0.00127109\n",
            "[499]\ttraining's multi_logloss: 0.00126386\n",
            "[500]\ttraining's multi_logloss: 0.00125695\n",
            "[501]\ttraining's multi_logloss: 0.00124935\n",
            "[502]\ttraining's multi_logloss: 0.00124219\n",
            "[503]\ttraining's multi_logloss: 0.00123489\n",
            "[504]\ttraining's multi_logloss: 0.0012271\n",
            "[505]\ttraining's multi_logloss: 0.00121975\n",
            "[506]\ttraining's multi_logloss: 0.00121225\n",
            "[507]\ttraining's multi_logloss: 0.00120442\n",
            "[508]\ttraining's multi_logloss: 0.00119751\n",
            "[509]\ttraining's multi_logloss: 0.00119104\n",
            "[510]\ttraining's multi_logloss: 0.00118428\n",
            "[511]\ttraining's multi_logloss: 0.00117755\n",
            "[512]\ttraining's multi_logloss: 0.00117126\n",
            "[513]\ttraining's multi_logloss: 0.00116392\n",
            "[514]\ttraining's multi_logloss: 0.00115693\n",
            "[515]\ttraining's multi_logloss: 0.00115039\n",
            "[516]\ttraining's multi_logloss: 0.00114403\n",
            "[517]\ttraining's multi_logloss: 0.00113718\n",
            "[518]\ttraining's multi_logloss: 0.0011306\n",
            "[519]\ttraining's multi_logloss: 0.00112441\n",
            "[520]\ttraining's multi_logloss: 0.00111777\n",
            "[521]\ttraining's multi_logloss: 0.00111083\n",
            "[522]\ttraining's multi_logloss: 0.00110434\n",
            "[523]\ttraining's multi_logloss: 0.00109724\n",
            "[524]\ttraining's multi_logloss: 0.00109089\n",
            "[525]\ttraining's multi_logloss: 0.00108454\n",
            "[526]\ttraining's multi_logloss: 0.00107816\n",
            "[527]\ttraining's multi_logloss: 0.00107181\n",
            "[528]\ttraining's multi_logloss: 0.00106565\n",
            "[529]\ttraining's multi_logloss: 0.0010595\n",
            "[530]\ttraining's multi_logloss: 0.0010537\n",
            "[531]\ttraining's multi_logloss: 0.00104798\n",
            "[532]\ttraining's multi_logloss: 0.00104175\n",
            "[533]\ttraining's multi_logloss: 0.00103603\n",
            "[534]\ttraining's multi_logloss: 0.00103008\n",
            "[535]\ttraining's multi_logloss: 0.00102463\n",
            "[536]\ttraining's multi_logloss: 0.00101916\n",
            "[537]\ttraining's multi_logloss: 0.00101367\n",
            "[538]\ttraining's multi_logloss: 0.00100835\n",
            "[539]\ttraining's multi_logloss: 0.00100272\n",
            "[540]\ttraining's multi_logloss: 0.00099739\n",
            "[541]\ttraining's multi_logloss: 0.000991889\n",
            "[542]\ttraining's multi_logloss: 0.000986281\n",
            "[543]\ttraining's multi_logloss: 0.00098128\n",
            "[544]\ttraining's multi_logloss: 0.000975619\n",
            "[545]\ttraining's multi_logloss: 0.000970373\n",
            "[546]\ttraining's multi_logloss: 0.00096366\n",
            "[547]\ttraining's multi_logloss: 0.000958185\n",
            "[548]\ttraining's multi_logloss: 0.000952524\n",
            "[549]\ttraining's multi_logloss: 0.000946964\n",
            "[550]\ttraining's multi_logloss: 0.000941668\n",
            "[551]\ttraining's multi_logloss: 0.000935809\n",
            "[552]\ttraining's multi_logloss: 0.000931237\n",
            "[553]\ttraining's multi_logloss: 0.000926119\n",
            "[554]\ttraining's multi_logloss: 0.000921067\n",
            "[555]\ttraining's multi_logloss: 0.000916146\n",
            "[556]\ttraining's multi_logloss: 0.000910991\n",
            "[557]\ttraining's multi_logloss: 0.000906575\n",
            "[558]\ttraining's multi_logloss: 0.000902108\n",
            "[559]\ttraining's multi_logloss: 0.00089708\n",
            "[560]\ttraining's multi_logloss: 0.000892175\n",
            "[561]\ttraining's multi_logloss: 0.000886815\n",
            "[562]\ttraining's multi_logloss: 0.000881652\n",
            "[563]\ttraining's multi_logloss: 0.000876713\n",
            "[564]\ttraining's multi_logloss: 0.000871421\n",
            "[565]\ttraining's multi_logloss: 0.000866482\n",
            "[566]\ttraining's multi_logloss: 0.000860953\n",
            "[567]\ttraining's multi_logloss: 0.000855718\n",
            "[568]\ttraining's multi_logloss: 0.000850582\n",
            "[569]\ttraining's multi_logloss: 0.000845657\n",
            "[570]\ttraining's multi_logloss: 0.000840873\n",
            "[571]\ttraining's multi_logloss: 0.000835936\n",
            "[572]\ttraining's multi_logloss: 0.000831463\n",
            "[573]\ttraining's multi_logloss: 0.000826735\n",
            "[574]\ttraining's multi_logloss: 0.000822393\n",
            "[575]\ttraining's multi_logloss: 0.000817524\n",
            "[576]\ttraining's multi_logloss: 0.000812874\n",
            "[577]\ttraining's multi_logloss: 0.000808324\n",
            "[578]\ttraining's multi_logloss: 0.000803811\n",
            "[579]\ttraining's multi_logloss: 0.000799639\n",
            "[580]\ttraining's multi_logloss: 0.000795095\n",
            "[581]\ttraining's multi_logloss: 0.000790797\n",
            "[582]\ttraining's multi_logloss: 0.000786354\n",
            "[583]\ttraining's multi_logloss: 0.000782176\n",
            "[584]\ttraining's multi_logloss: 0.000778201\n",
            "[585]\ttraining's multi_logloss: 0.000773734\n",
            "[586]\ttraining's multi_logloss: 0.000768909\n",
            "[587]\ttraining's multi_logloss: 0.000764393\n",
            "[588]\ttraining's multi_logloss: 0.000759994\n",
            "[589]\ttraining's multi_logloss: 0.000755705\n",
            "[590]\ttraining's multi_logloss: 0.000751602\n",
            "[591]\ttraining's multi_logloss: 0.0007474\n",
            "[592]\ttraining's multi_logloss: 0.000743378\n",
            "[593]\ttraining's multi_logloss: 0.000739968\n",
            "[594]\ttraining's multi_logloss: 0.000736391\n",
            "[595]\ttraining's multi_logloss: 0.000732698\n",
            "[596]\ttraining's multi_logloss: 0.000729258\n",
            "[597]\ttraining's multi_logloss: 0.000725287\n",
            "[598]\ttraining's multi_logloss: 0.000721268\n",
            "[599]\ttraining's multi_logloss: 0.000717808\n",
            "[600]\ttraining's multi_logloss: 0.000714323\n",
            "[601]\ttraining's multi_logloss: 0.000710402\n",
            "[602]\ttraining's multi_logloss: 0.00070689\n",
            "[603]\ttraining's multi_logloss: 0.000703427\n",
            "[604]\ttraining's multi_logloss: 0.000699989\n",
            "[605]\ttraining's multi_logloss: 0.000696332\n",
            "[606]\ttraining's multi_logloss: 0.000692804\n",
            "[607]\ttraining's multi_logloss: 0.000689527\n",
            "[608]\ttraining's multi_logloss: 0.00068601\n",
            "[609]\ttraining's multi_logloss: 0.000682547\n",
            "[610]\ttraining's multi_logloss: 0.000679078\n",
            "[611]\ttraining's multi_logloss: 0.000675614\n",
            "[612]\ttraining's multi_logloss: 0.000672587\n",
            "[613]\ttraining's multi_logloss: 0.000669559\n",
            "[614]\ttraining's multi_logloss: 0.000665932\n",
            "[615]\ttraining's multi_logloss: 0.000662868\n",
            "[616]\ttraining's multi_logloss: 0.000659513\n",
            "[617]\ttraining's multi_logloss: 0.000656407\n",
            "[618]\ttraining's multi_logloss: 0.000652893\n",
            "[619]\ttraining's multi_logloss: 0.000649595\n",
            "[620]\ttraining's multi_logloss: 0.000646612\n",
            "[621]\ttraining's multi_logloss: 0.000643373\n",
            "[622]\ttraining's multi_logloss: 0.000640174\n",
            "[623]\ttraining's multi_logloss: 0.000637201\n",
            "[624]\ttraining's multi_logloss: 0.000634037\n",
            "[625]\ttraining's multi_logloss: 0.00063106\n",
            "[626]\ttraining's multi_logloss: 0.000627708\n",
            "[627]\ttraining's multi_logloss: 0.000624509\n",
            "[628]\ttraining's multi_logloss: 0.000621289\n",
            "[629]\ttraining's multi_logloss: 0.000618172\n",
            "[630]\ttraining's multi_logloss: 0.000615064\n",
            "[631]\ttraining's multi_logloss: 0.00061212\n",
            "[632]\ttraining's multi_logloss: 0.000609185\n",
            "[633]\ttraining's multi_logloss: 0.000606102\n",
            "[634]\ttraining's multi_logloss: 0.000603078\n",
            "[635]\ttraining's multi_logloss: 0.000600052\n",
            "[636]\ttraining's multi_logloss: 0.000596943\n",
            "[637]\ttraining's multi_logloss: 0.000593649\n",
            "[638]\ttraining's multi_logloss: 0.000590302\n",
            "[639]\ttraining's multi_logloss: 0.000587095\n",
            "[640]\ttraining's multi_logloss: 0.000584377\n",
            "[641]\ttraining's multi_logloss: 0.000581509\n",
            "[642]\ttraining's multi_logloss: 0.000578825\n",
            "[643]\ttraining's multi_logloss: 0.000576139\n",
            "[644]\ttraining's multi_logloss: 0.000573433\n",
            "[645]\ttraining's multi_logloss: 0.000570576\n",
            "[646]\ttraining's multi_logloss: 0.000568056\n",
            "[647]\ttraining's multi_logloss: 0.000565802\n",
            "[648]\ttraining's multi_logloss: 0.000562977\n",
            "[649]\ttraining's multi_logloss: 0.000560307\n",
            "[650]\ttraining's multi_logloss: 0.000557887\n",
            "[651]\ttraining's multi_logloss: 0.000555262\n",
            "[652]\ttraining's multi_logloss: 0.000552732\n",
            "[653]\ttraining's multi_logloss: 0.000550024\n",
            "[654]\ttraining's multi_logloss: 0.000547658\n",
            "[655]\ttraining's multi_logloss: 0.000545115\n",
            "[656]\ttraining's multi_logloss: 0.000542682\n",
            "[657]\ttraining's multi_logloss: 0.000540133\n",
            "[658]\ttraining's multi_logloss: 0.000537794\n",
            "[659]\ttraining's multi_logloss: 0.000535007\n",
            "[660]\ttraining's multi_logloss: 0.000532334\n",
            "[661]\ttraining's multi_logloss: 0.000529873\n",
            "[662]\ttraining's multi_logloss: 0.000527508\n",
            "[663]\ttraining's multi_logloss: 0.000525013\n",
            "[664]\ttraining's multi_logloss: 0.000522403\n",
            "[665]\ttraining's multi_logloss: 0.000520063\n",
            "[666]\ttraining's multi_logloss: 0.000517735\n",
            "[667]\ttraining's multi_logloss: 0.00051535\n",
            "[668]\ttraining's multi_logloss: 0.000513182\n",
            "[669]\ttraining's multi_logloss: 0.000511071\n",
            "[670]\ttraining's multi_logloss: 0.00050892\n",
            "[671]\ttraining's multi_logloss: 0.000506505\n",
            "[672]\ttraining's multi_logloss: 0.000504218\n",
            "[673]\ttraining's multi_logloss: 0.000502327\n",
            "[674]\ttraining's multi_logloss: 0.000500139\n",
            "[675]\ttraining's multi_logloss: 0.000497679\n",
            "[676]\ttraining's multi_logloss: 0.000495744\n",
            "[677]\ttraining's multi_logloss: 0.00049358\n",
            "[678]\ttraining's multi_logloss: 0.000491209\n",
            "[679]\ttraining's multi_logloss: 0.000489023\n",
            "[680]\ttraining's multi_logloss: 0.000486836\n",
            "[681]\ttraining's multi_logloss: 0.000484881\n",
            "[682]\ttraining's multi_logloss: 0.00048257\n",
            "[683]\ttraining's multi_logloss: 0.000480657\n",
            "[684]\ttraining's multi_logloss: 0.000478678\n",
            "[685]\ttraining's multi_logloss: 0.000476865\n",
            "[686]\ttraining's multi_logloss: 0.000474525\n",
            "[687]\ttraining's multi_logloss: 0.00047227\n",
            "[688]\ttraining's multi_logloss: 0.000470243\n",
            "[689]\ttraining's multi_logloss: 0.000467848\n",
            "[690]\ttraining's multi_logloss: 0.000465777\n",
            "[691]\ttraining's multi_logloss: 0.000463571\n",
            "[692]\ttraining's multi_logloss: 0.000461513\n",
            "[693]\ttraining's multi_logloss: 0.000459542\n",
            "[694]\ttraining's multi_logloss: 0.000457106\n",
            "[695]\ttraining's multi_logloss: 0.000455206\n",
            "[696]\ttraining's multi_logloss: 0.000453067\n",
            "[697]\ttraining's multi_logloss: 0.000450879\n",
            "[698]\ttraining's multi_logloss: 0.000448834\n",
            "[699]\ttraining's multi_logloss: 0.000446883\n",
            "[700]\ttraining's multi_logloss: 0.000444946\n",
            "[701]\ttraining's multi_logloss: 0.000442954\n",
            "[702]\ttraining's multi_logloss: 0.000441051\n",
            "[703]\ttraining's multi_logloss: 0.000439027\n",
            "[704]\ttraining's multi_logloss: 0.000437149\n",
            "[705]\ttraining's multi_logloss: 0.000435331\n",
            "[706]\ttraining's multi_logloss: 0.000433504\n",
            "[707]\ttraining's multi_logloss: 0.000431534\n",
            "[708]\ttraining's multi_logloss: 0.000429553\n",
            "[709]\ttraining's multi_logloss: 0.000427764\n",
            "[710]\ttraining's multi_logloss: 0.000426164\n",
            "[711]\ttraining's multi_logloss: 0.000424293\n",
            "[712]\ttraining's multi_logloss: 0.000422488\n",
            "[713]\ttraining's multi_logloss: 0.000420759\n",
            "[714]\ttraining's multi_logloss: 0.000419016\n",
            "[715]\ttraining's multi_logloss: 0.000417183\n",
            "[716]\ttraining's multi_logloss: 0.000415247\n",
            "[717]\ttraining's multi_logloss: 0.000413427\n",
            "[718]\ttraining's multi_logloss: 0.000411702\n",
            "[719]\ttraining's multi_logloss: 0.000409737\n",
            "[720]\ttraining's multi_logloss: 0.000407775\n",
            "[721]\ttraining's multi_logloss: 0.000406009\n",
            "[722]\ttraining's multi_logloss: 0.000404116\n",
            "[723]\ttraining's multi_logloss: 0.00040229\n",
            "[724]\ttraining's multi_logloss: 0.000400887\n",
            "[725]\ttraining's multi_logloss: 0.000399172\n",
            "[726]\ttraining's multi_logloss: 0.000397431\n",
            "[727]\ttraining's multi_logloss: 0.000395591\n",
            "[728]\ttraining's multi_logloss: 0.000394134\n",
            "[729]\ttraining's multi_logloss: 0.00039234\n",
            "[730]\ttraining's multi_logloss: 0.000390905\n",
            "[731]\ttraining's multi_logloss: 0.000388983\n",
            "[732]\ttraining's multi_logloss: 0.000387196\n",
            "[733]\ttraining's multi_logloss: 0.000385445\n",
            "[734]\ttraining's multi_logloss: 0.000383733\n",
            "[735]\ttraining's multi_logloss: 0.000382198\n",
            "[736]\ttraining's multi_logloss: 0.000380778\n",
            "[737]\ttraining's multi_logloss: 0.00037916\n",
            "[738]\ttraining's multi_logloss: 0.000377614\n",
            "[739]\ttraining's multi_logloss: 0.000376322\n",
            "[740]\ttraining's multi_logloss: 0.0003749\n",
            "[741]\ttraining's multi_logloss: 0.00037313\n",
            "[742]\ttraining's multi_logloss: 0.000371459\n",
            "[743]\ttraining's multi_logloss: 0.000369825\n",
            "[744]\ttraining's multi_logloss: 0.000368285\n",
            "[745]\ttraining's multi_logloss: 0.000366672\n",
            "[746]\ttraining's multi_logloss: 0.000365014\n",
            "[747]\ttraining's multi_logloss: 0.000363477\n",
            "[748]\ttraining's multi_logloss: 0.000362013\n",
            "[749]\ttraining's multi_logloss: 0.000360689\n",
            "[750]\ttraining's multi_logloss: 0.000359132\n",
            "[751]\ttraining's multi_logloss: 0.000357721\n",
            "[752]\ttraining's multi_logloss: 0.000355971\n",
            "[753]\ttraining's multi_logloss: 0.000354308\n",
            "[754]\ttraining's multi_logloss: 0.000352741\n",
            "[755]\ttraining's multi_logloss: 0.000351095\n",
            "[756]\ttraining's multi_logloss: 0.000349756\n",
            "[757]\ttraining's multi_logloss: 0.000348305\n",
            "[758]\ttraining's multi_logloss: 0.000346889\n",
            "[759]\ttraining's multi_logloss: 0.000345468\n",
            "[760]\ttraining's multi_logloss: 0.00034419\n",
            "[761]\ttraining's multi_logloss: 0.000342735\n",
            "[762]\ttraining's multi_logloss: 0.000341386\n",
            "[763]\ttraining's multi_logloss: 0.000339814\n",
            "[764]\ttraining's multi_logloss: 0.000338603\n",
            "[765]\ttraining's multi_logloss: 0.00033737\n",
            "[766]\ttraining's multi_logloss: 0.000335619\n",
            "[767]\ttraining's multi_logloss: 0.000334001\n",
            "[768]\ttraining's multi_logloss: 0.00033267\n",
            "[769]\ttraining's multi_logloss: 0.000331349\n",
            "[770]\ttraining's multi_logloss: 0.000329995\n",
            "[771]\ttraining's multi_logloss: 0.000328825\n",
            "[772]\ttraining's multi_logloss: 0.000327506\n",
            "[773]\ttraining's multi_logloss: 0.000326471\n",
            "[774]\ttraining's multi_logloss: 0.000325054\n",
            "[775]\ttraining's multi_logloss: 0.000323809\n",
            "[776]\ttraining's multi_logloss: 0.000322784\n",
            "[777]\ttraining's multi_logloss: 0.000321482\n",
            "[778]\ttraining's multi_logloss: 0.000320214\n",
            "[779]\ttraining's multi_logloss: 0.000319088\n",
            "[780]\ttraining's multi_logloss: 0.000318123\n",
            "[781]\ttraining's multi_logloss: 0.000316812\n",
            "[782]\ttraining's multi_logloss: 0.000315389\n",
            "[783]\ttraining's multi_logloss: 0.000314008\n",
            "[784]\ttraining's multi_logloss: 0.000312736\n",
            "[785]\ttraining's multi_logloss: 0.000311505\n",
            "[786]\ttraining's multi_logloss: 0.000310332\n",
            "[787]\ttraining's multi_logloss: 0.000309217\n",
            "[788]\ttraining's multi_logloss: 0.000308084\n",
            "[789]\ttraining's multi_logloss: 0.000306875\n",
            "[790]\ttraining's multi_logloss: 0.000305665\n",
            "[791]\ttraining's multi_logloss: 0.000304407\n",
            "[792]\ttraining's multi_logloss: 0.000303297\n",
            "[793]\ttraining's multi_logloss: 0.000301982\n",
            "[794]\ttraining's multi_logloss: 0.000300716\n",
            "[795]\ttraining's multi_logloss: 0.000299692\n",
            "[796]\ttraining's multi_logloss: 0.000298425\n",
            "[797]\ttraining's multi_logloss: 0.000297213\n",
            "[798]\ttraining's multi_logloss: 0.000296116\n",
            "[799]\ttraining's multi_logloss: 0.000294837\n",
            "[800]\ttraining's multi_logloss: 0.000293734\n",
            "[801]\ttraining's multi_logloss: 0.000292593\n",
            "[802]\ttraining's multi_logloss: 0.000291512\n",
            "[803]\ttraining's multi_logloss: 0.000290601\n",
            "[804]\ttraining's multi_logloss: 0.00028962\n",
            "[805]\ttraining's multi_logloss: 0.000288557\n",
            "[806]\ttraining's multi_logloss: 0.000287395\n",
            "[807]\ttraining's multi_logloss: 0.00028629\n",
            "[808]\ttraining's multi_logloss: 0.000285253\n",
            "[809]\ttraining's multi_logloss: 0.000284157\n",
            "[810]\ttraining's multi_logloss: 0.000283002\n",
            "[811]\ttraining's multi_logloss: 0.000281767\n",
            "[812]\ttraining's multi_logloss: 0.000280611\n",
            "[813]\ttraining's multi_logloss: 0.000279477\n",
            "[814]\ttraining's multi_logloss: 0.000278491\n",
            "[815]\ttraining's multi_logloss: 0.000277414\n",
            "[816]\ttraining's multi_logloss: 0.000276321\n",
            "[817]\ttraining's multi_logloss: 0.000275206\n",
            "[818]\ttraining's multi_logloss: 0.0002742\n",
            "[819]\ttraining's multi_logloss: 0.000273153\n",
            "[820]\ttraining's multi_logloss: 0.000272248\n",
            "[821]\ttraining's multi_logloss: 0.000271133\n",
            "[822]\ttraining's multi_logloss: 0.000269982\n",
            "[823]\ttraining's multi_logloss: 0.000268836\n",
            "[824]\ttraining's multi_logloss: 0.000267901\n",
            "[825]\ttraining's multi_logloss: 0.000266831\n",
            "[826]\ttraining's multi_logloss: 0.00026585\n",
            "[827]\ttraining's multi_logloss: 0.000264888\n",
            "[828]\ttraining's multi_logloss: 0.000263925\n",
            "[829]\ttraining's multi_logloss: 0.000263101\n",
            "[830]\ttraining's multi_logloss: 0.000262115\n",
            "[831]\ttraining's multi_logloss: 0.000261267\n",
            "[832]\ttraining's multi_logloss: 0.0002603\n",
            "[833]\ttraining's multi_logloss: 0.000259454\n",
            "[834]\ttraining's multi_logloss: 0.000258606\n",
            "[835]\ttraining's multi_logloss: 0.000257873\n",
            "[836]\ttraining's multi_logloss: 0.000256745\n",
            "[837]\ttraining's multi_logloss: 0.000255689\n",
            "[838]\ttraining's multi_logloss: 0.000254728\n",
            "[839]\ttraining's multi_logloss: 0.000253614\n",
            "[840]\ttraining's multi_logloss: 0.000252657\n",
            "[841]\ttraining's multi_logloss: 0.000251711\n",
            "[842]\ttraining's multi_logloss: 0.00025087\n",
            "[843]\ttraining's multi_logloss: 0.000249963\n",
            "[844]\ttraining's multi_logloss: 0.000249138\n",
            "[845]\ttraining's multi_logloss: 0.000248286\n",
            "[846]\ttraining's multi_logloss: 0.000247207\n",
            "[847]\ttraining's multi_logloss: 0.000246356\n",
            "[848]\ttraining's multi_logloss: 0.000245372\n",
            "[849]\ttraining's multi_logloss: 0.000244426\n",
            "[850]\ttraining's multi_logloss: 0.000243503\n",
            "[851]\ttraining's multi_logloss: 0.000242654\n",
            "[852]\ttraining's multi_logloss: 0.000241778\n",
            "[853]\ttraining's multi_logloss: 0.000240937\n",
            "[854]\ttraining's multi_logloss: 0.000240064\n",
            "[855]\ttraining's multi_logloss: 0.000239253\n",
            "[856]\ttraining's multi_logloss: 0.000238498\n",
            "[857]\ttraining's multi_logloss: 0.000237806\n",
            "[858]\ttraining's multi_logloss: 0.000236941\n",
            "[859]\ttraining's multi_logloss: 0.000236171\n",
            "[860]\ttraining's multi_logloss: 0.000235317\n",
            "[861]\ttraining's multi_logloss: 0.000234604\n",
            "[862]\ttraining's multi_logloss: 0.000233724\n",
            "[863]\ttraining's multi_logloss: 0.000232907\n",
            "[864]\ttraining's multi_logloss: 0.000232094\n",
            "[865]\ttraining's multi_logloss: 0.000231243\n",
            "[866]\ttraining's multi_logloss: 0.000230374\n",
            "[867]\ttraining's multi_logloss: 0.000229678\n",
            "[868]\ttraining's multi_logloss: 0.000228946\n",
            "[869]\ttraining's multi_logloss: 0.000228211\n",
            "[870]\ttraining's multi_logloss: 0.000227468\n",
            "[871]\ttraining's multi_logloss: 0.000226663\n",
            "[872]\ttraining's multi_logloss: 0.0002258\n",
            "[873]\ttraining's multi_logloss: 0.0002249\n",
            "[874]\ttraining's multi_logloss: 0.000224013\n",
            "[875]\ttraining's multi_logloss: 0.000223258\n",
            "[876]\ttraining's multi_logloss: 0.000222508\n",
            "[877]\ttraining's multi_logloss: 0.000221652\n",
            "[878]\ttraining's multi_logloss: 0.000220892\n",
            "[879]\ttraining's multi_logloss: 0.00022018\n",
            "[880]\ttraining's multi_logloss: 0.000219429\n",
            "[881]\ttraining's multi_logloss: 0.000218742\n",
            "[882]\ttraining's multi_logloss: 0.000217785\n",
            "[883]\ttraining's multi_logloss: 0.000216874\n",
            "[884]\ttraining's multi_logloss: 0.000216042\n",
            "[885]\ttraining's multi_logloss: 0.000215255\n",
            "[886]\ttraining's multi_logloss: 0.000214539\n",
            "[887]\ttraining's multi_logloss: 0.000213832\n",
            "[888]\ttraining's multi_logloss: 0.00021303\n",
            "[889]\ttraining's multi_logloss: 0.000212298\n",
            "[890]\ttraining's multi_logloss: 0.000211617\n",
            "[891]\ttraining's multi_logloss: 0.000210831\n",
            "[892]\ttraining's multi_logloss: 0.000210018\n",
            "[893]\ttraining's multi_logloss: 0.000209337\n",
            "[894]\ttraining's multi_logloss: 0.000208595\n",
            "[895]\ttraining's multi_logloss: 0.000207954\n",
            "[896]\ttraining's multi_logloss: 0.000207209\n",
            "[897]\ttraining's multi_logloss: 0.000206393\n",
            "[898]\ttraining's multi_logloss: 0.000205613\n",
            "[899]\ttraining's multi_logloss: 0.000204872\n",
            "[900]\ttraining's multi_logloss: 0.000204103\n",
            "[901]\ttraining's multi_logloss: 0.000203439\n",
            "[902]\ttraining's multi_logloss: 0.000202824\n",
            "[903]\ttraining's multi_logloss: 0.000202168\n",
            "[904]\ttraining's multi_logloss: 0.000201594\n",
            "[905]\ttraining's multi_logloss: 0.000201012\n",
            "[906]\ttraining's multi_logloss: 0.000200373\n",
            "[907]\ttraining's multi_logloss: 0.000199599\n",
            "[908]\ttraining's multi_logloss: 0.000198948\n",
            "[909]\ttraining's multi_logloss: 0.000198218\n",
            "[910]\ttraining's multi_logloss: 0.000197603\n",
            "[911]\ttraining's multi_logloss: 0.000196862\n",
            "[912]\ttraining's multi_logloss: 0.000196154\n",
            "[913]\ttraining's multi_logloss: 0.000195407\n",
            "[914]\ttraining's multi_logloss: 0.000194587\n",
            "[915]\ttraining's multi_logloss: 0.000193664\n",
            "[916]\ttraining's multi_logloss: 0.000192897\n",
            "[917]\ttraining's multi_logloss: 0.000192281\n",
            "[918]\ttraining's multi_logloss: 0.000191547\n",
            "[919]\ttraining's multi_logloss: 0.00019089\n",
            "[920]\ttraining's multi_logloss: 0.000190385\n",
            "[921]\ttraining's multi_logloss: 0.000189789\n",
            "[922]\ttraining's multi_logloss: 0.000189101\n",
            "[923]\ttraining's multi_logloss: 0.000188442\n",
            "[924]\ttraining's multi_logloss: 0.000187671\n",
            "[925]\ttraining's multi_logloss: 0.000187004\n",
            "[926]\ttraining's multi_logloss: 0.000186334\n",
            "[927]\ttraining's multi_logloss: 0.000185735\n",
            "[928]\ttraining's multi_logloss: 0.000185175\n",
            "[929]\ttraining's multi_logloss: 0.00018458\n",
            "[930]\ttraining's multi_logloss: 0.00018396\n",
            "[931]\ttraining's multi_logloss: 0.00018337\n",
            "[932]\ttraining's multi_logloss: 0.00018273\n",
            "[933]\ttraining's multi_logloss: 0.000182201\n",
            "[934]\ttraining's multi_logloss: 0.000181642\n",
            "[935]\ttraining's multi_logloss: 0.000181083\n",
            "[936]\ttraining's multi_logloss: 0.000180445\n",
            "[937]\ttraining's multi_logloss: 0.000179884\n",
            "[938]\ttraining's multi_logloss: 0.000179263\n",
            "[939]\ttraining's multi_logloss: 0.000178657\n",
            "[940]\ttraining's multi_logloss: 0.000178026\n",
            "[941]\ttraining's multi_logloss: 0.000177403\n",
            "[942]\ttraining's multi_logloss: 0.000176738\n",
            "[943]\ttraining's multi_logloss: 0.000176101\n",
            "[944]\ttraining's multi_logloss: 0.000175478\n",
            "[945]\ttraining's multi_logloss: 0.000174807\n",
            "[946]\ttraining's multi_logloss: 0.000174214\n",
            "[947]\ttraining's multi_logloss: 0.000173697\n",
            "[948]\ttraining's multi_logloss: 0.000173164\n",
            "[949]\ttraining's multi_logloss: 0.000172693\n",
            "[950]\ttraining's multi_logloss: 0.000172196\n",
            "[951]\ttraining's multi_logloss: 0.000171518\n",
            "[952]\ttraining's multi_logloss: 0.000170992\n",
            "[953]\ttraining's multi_logloss: 0.000170393\n",
            "[954]\ttraining's multi_logloss: 0.000169791\n",
            "[955]\ttraining's multi_logloss: 0.000169189\n",
            "[956]\ttraining's multi_logloss: 0.000168652\n",
            "[957]\ttraining's multi_logloss: 0.000168198\n",
            "[958]\ttraining's multi_logloss: 0.000167582\n",
            "[959]\ttraining's multi_logloss: 0.000167121\n",
            "[960]\ttraining's multi_logloss: 0.000166644\n",
            "[961]\ttraining's multi_logloss: 0.000165987\n",
            "[962]\ttraining's multi_logloss: 0.000165428\n",
            "[963]\ttraining's multi_logloss: 0.000164744\n",
            "[964]\ttraining's multi_logloss: 0.000164131\n",
            "[965]\ttraining's multi_logloss: 0.000163475\n",
            "[966]\ttraining's multi_logloss: 0.000162979\n",
            "[967]\ttraining's multi_logloss: 0.000162491\n",
            "[968]\ttraining's multi_logloss: 0.000162047\n",
            "[969]\ttraining's multi_logloss: 0.00016162\n",
            "[970]\ttraining's multi_logloss: 0.000161138\n",
            "[971]\ttraining's multi_logloss: 0.000160586\n",
            "[972]\ttraining's multi_logloss: 0.000160095\n",
            "[973]\ttraining's multi_logloss: 0.000159597\n",
            "[974]\ttraining's multi_logloss: 0.000159121\n",
            "[975]\ttraining's multi_logloss: 0.00015863\n",
            "[976]\ttraining's multi_logloss: 0.000158142\n",
            "[977]\ttraining's multi_logloss: 0.000157621\n",
            "[978]\ttraining's multi_logloss: 0.000157124\n",
            "[979]\ttraining's multi_logloss: 0.000156659\n",
            "[980]\ttraining's multi_logloss: 0.000156223\n",
            "[981]\ttraining's multi_logloss: 0.000155679\n",
            "[982]\ttraining's multi_logloss: 0.000155174\n",
            "[983]\ttraining's multi_logloss: 0.00015469\n",
            "[984]\ttraining's multi_logloss: 0.00015422\n",
            "[985]\ttraining's multi_logloss: 0.000153783\n",
            "[986]\ttraining's multi_logloss: 0.000153242\n",
            "[987]\ttraining's multi_logloss: 0.000152755\n",
            "[988]\ttraining's multi_logloss: 0.000152267\n",
            "[989]\ttraining's multi_logloss: 0.000151767\n",
            "[990]\ttraining's multi_logloss: 0.000151293\n",
            "[991]\ttraining's multi_logloss: 0.000150797\n",
            "[992]\ttraining's multi_logloss: 0.000150339\n",
            "[993]\ttraining's multi_logloss: 0.00014995\n",
            "[994]\ttraining's multi_logloss: 0.000149562\n",
            "[995]\ttraining's multi_logloss: 0.000149174\n",
            "[996]\ttraining's multi_logloss: 0.000148761\n",
            "[997]\ttraining's multi_logloss: 0.00014837\n",
            "[998]\ttraining's multi_logloss: 0.00014793\n",
            "[999]\ttraining's multi_logloss: 0.000147529\n",
            "[1000]\ttraining's multi_logloss: 0.000147094\n",
            "[1001]\ttraining's multi_logloss: 0.000146598\n",
            "[1002]\ttraining's multi_logloss: 0.000146158\n",
            "[1003]\ttraining's multi_logloss: 0.00014568\n",
            "[1004]\ttraining's multi_logloss: 0.00014519\n",
            "[1005]\ttraining's multi_logloss: 0.000144745\n",
            "[1006]\ttraining's multi_logloss: 0.000144273\n",
            "[1007]\ttraining's multi_logloss: 0.000143813\n",
            "[1008]\ttraining's multi_logloss: 0.00014335\n",
            "[1009]\ttraining's multi_logloss: 0.000142885\n",
            "[1010]\ttraining's multi_logloss: 0.000142402\n",
            "[1011]\ttraining's multi_logloss: 0.000142003\n",
            "[1012]\ttraining's multi_logloss: 0.000141604\n",
            "[1013]\ttraining's multi_logloss: 0.000141298\n",
            "[1014]\ttraining's multi_logloss: 0.00014087\n",
            "[1015]\ttraining's multi_logloss: 0.000140454\n",
            "[1016]\ttraining's multi_logloss: 0.000140109\n",
            "[1017]\ttraining's multi_logloss: 0.000139778\n",
            "[1018]\ttraining's multi_logloss: 0.000139512\n",
            "[1019]\ttraining's multi_logloss: 0.00013923\n",
            "[1020]\ttraining's multi_logloss: 0.000138797\n",
            "[1021]\ttraining's multi_logloss: 0.000138422\n",
            "[1022]\ttraining's multi_logloss: 0.000138077\n",
            "[1023]\ttraining's multi_logloss: 0.000137602\n",
            "[1024]\ttraining's multi_logloss: 0.000137221\n",
            "[1025]\ttraining's multi_logloss: 0.000136827\n",
            "[1026]\ttraining's multi_logloss: 0.000136351\n",
            "[1027]\ttraining's multi_logloss: 0.00013591\n",
            "[1028]\ttraining's multi_logloss: 0.000135491\n",
            "[1029]\ttraining's multi_logloss: 0.000135127\n",
            "[1030]\ttraining's multi_logloss: 0.000134739\n",
            "[1031]\ttraining's multi_logloss: 0.000134336\n",
            "[1032]\ttraining's multi_logloss: 0.000133951\n",
            "[1033]\ttraining's multi_logloss: 0.000133543\n",
            "[1034]\ttraining's multi_logloss: 0.000133152\n",
            "[1035]\ttraining's multi_logloss: 0.000132724\n",
            "[1036]\ttraining's multi_logloss: 0.000132385\n",
            "[1037]\ttraining's multi_logloss: 0.000132037\n",
            "[1038]\ttraining's multi_logloss: 0.000131714\n",
            "[1039]\ttraining's multi_logloss: 0.000131431\n",
            "[1040]\ttraining's multi_logloss: 0.000131114\n",
            "[1041]\ttraining's multi_logloss: 0.000130687\n",
            "[1042]\ttraining's multi_logloss: 0.000130273\n",
            "[1043]\ttraining's multi_logloss: 0.000129939\n",
            "[1044]\ttraining's multi_logloss: 0.000129559\n",
            "[1045]\ttraining's multi_logloss: 0.000129138\n",
            "[1046]\ttraining's multi_logloss: 0.000128758\n",
            "[1047]\ttraining's multi_logloss: 0.000128347\n",
            "[1048]\ttraining's multi_logloss: 0.000127951\n",
            "[1049]\ttraining's multi_logloss: 0.000127548\n",
            "[1050]\ttraining's multi_logloss: 0.00012719\n",
            "[1051]\ttraining's multi_logloss: 0.000126881\n",
            "[1052]\ttraining's multi_logloss: 0.000126512\n",
            "[1053]\ttraining's multi_logloss: 0.000126148\n",
            "[1054]\ttraining's multi_logloss: 0.000125779\n",
            "[1055]\ttraining's multi_logloss: 0.000125408\n",
            "[1056]\ttraining's multi_logloss: 0.00012502\n",
            "[1057]\ttraining's multi_logloss: 0.000124733\n",
            "[1058]\ttraining's multi_logloss: 0.000124435\n",
            "[1059]\ttraining's multi_logloss: 0.000124125\n",
            "[1060]\ttraining's multi_logloss: 0.000123854\n",
            "[1061]\ttraining's multi_logloss: 0.000123405\n",
            "[1062]\ttraining's multi_logloss: 0.000122986\n",
            "[1063]\ttraining's multi_logloss: 0.000122564\n",
            "[1064]\ttraining's multi_logloss: 0.000122241\n",
            "[1065]\ttraining's multi_logloss: 0.000121822\n",
            "[1066]\ttraining's multi_logloss: 0.000121512\n",
            "[1067]\ttraining's multi_logloss: 0.000121198\n",
            "[1068]\ttraining's multi_logloss: 0.000120806\n",
            "[1069]\ttraining's multi_logloss: 0.000120526\n",
            "[1070]\ttraining's multi_logloss: 0.000120257\n",
            "[1071]\ttraining's multi_logloss: 0.000119909\n",
            "[1072]\ttraining's multi_logloss: 0.000119552\n",
            "[1073]\ttraining's multi_logloss: 0.0001192\n",
            "[1074]\ttraining's multi_logloss: 0.000118839\n",
            "[1075]\ttraining's multi_logloss: 0.000118497\n",
            "[1076]\ttraining's multi_logloss: 0.000118089\n",
            "[1077]\ttraining's multi_logloss: 0.000117742\n",
            "[1078]\ttraining's multi_logloss: 0.000117385\n",
            "[1079]\ttraining's multi_logloss: 0.00011705\n",
            "[1080]\ttraining's multi_logloss: 0.000116691\n",
            "[1081]\ttraining's multi_logloss: 0.000116352\n",
            "[1082]\ttraining's multi_logloss: 0.000116043\n",
            "[1083]\ttraining's multi_logloss: 0.000115705\n",
            "[1084]\ttraining's multi_logloss: 0.00011543\n",
            "[1085]\ttraining's multi_logloss: 0.000115115\n",
            "[1086]\ttraining's multi_logloss: 0.000114785\n",
            "[1087]\ttraining's multi_logloss: 0.000114506\n",
            "[1088]\ttraining's multi_logloss: 0.000114159\n",
            "[1089]\ttraining's multi_logloss: 0.000113839\n",
            "[1090]\ttraining's multi_logloss: 0.000113547\n",
            "[1091]\ttraining's multi_logloss: 0.000113229\n",
            "[1092]\ttraining's multi_logloss: 0.000112973\n",
            "[1093]\ttraining's multi_logloss: 0.000112703\n",
            "[1094]\ttraining's multi_logloss: 0.000112361\n",
            "[1095]\ttraining's multi_logloss: 0.000112038\n",
            "[1096]\ttraining's multi_logloss: 0.000111714\n",
            "[1097]\ttraining's multi_logloss: 0.000111425\n",
            "[1098]\ttraining's multi_logloss: 0.000111014\n",
            "[1099]\ttraining's multi_logloss: 0.00011077\n",
            "[1100]\ttraining's multi_logloss: 0.00011049\n",
            "[1101]\ttraining's multi_logloss: 0.000110193\n",
            "[1102]\ttraining's multi_logloss: 0.000109881\n",
            "[1103]\ttraining's multi_logloss: 0.00010959\n",
            "[1104]\ttraining's multi_logloss: 0.000109343\n",
            "[1105]\ttraining's multi_logloss: 0.000109051\n",
            "[1106]\ttraining's multi_logloss: 0.000108766\n",
            "[1107]\ttraining's multi_logloss: 0.000108445\n",
            "[1108]\ttraining's multi_logloss: 0.000108148\n",
            "[1109]\ttraining's multi_logloss: 0.000107925\n",
            "[1110]\ttraining's multi_logloss: 0.000107671\n",
            "[1111]\ttraining's multi_logloss: 0.000107336\n",
            "[1112]\ttraining's multi_logloss: 0.00010706\n",
            "[1113]\ttraining's multi_logloss: 0.000106833\n",
            "[1114]\ttraining's multi_logloss: 0.000106504\n",
            "[1115]\ttraining's multi_logloss: 0.000106237\n",
            "[1116]\ttraining's multi_logloss: 0.00010591\n",
            "[1117]\ttraining's multi_logloss: 0.000105576\n",
            "[1118]\ttraining's multi_logloss: 0.000105314\n",
            "[1119]\ttraining's multi_logloss: 0.000105024\n",
            "[1120]\ttraining's multi_logloss: 0.00010478\n",
            "[1121]\ttraining's multi_logloss: 0.000104486\n",
            "[1122]\ttraining's multi_logloss: 0.000104197\n",
            "[1123]\ttraining's multi_logloss: 0.000103868\n",
            "[1124]\ttraining's multi_logloss: 0.000103604\n",
            "[1125]\ttraining's multi_logloss: 0.000103244\n",
            "[1126]\ttraining's multi_logloss: 0.000102973\n",
            "[1127]\ttraining's multi_logloss: 0.000102705\n",
            "[1128]\ttraining's multi_logloss: 0.000102475\n",
            "[1129]\ttraining's multi_logloss: 0.000102148\n",
            "[1130]\ttraining's multi_logloss: 0.00010189\n",
            "[1131]\ttraining's multi_logloss: 0.000101581\n",
            "[1132]\ttraining's multi_logloss: 0.000101279\n",
            "[1133]\ttraining's multi_logloss: 0.000101\n",
            "[1134]\ttraining's multi_logloss: 0.000100708\n",
            "[1135]\ttraining's multi_logloss: 0.000100462\n",
            "[1136]\ttraining's multi_logloss: 0.00010021\n",
            "[1137]\ttraining's multi_logloss: 0.000100013\n",
            "[1138]\ttraining's multi_logloss: 9.97779e-05\n",
            "[1139]\ttraining's multi_logloss: 9.95238e-05\n",
            "[1140]\ttraining's multi_logloss: 9.92724e-05\n",
            "[1141]\ttraining's multi_logloss: 9.89737e-05\n",
            "[1142]\ttraining's multi_logloss: 9.86887e-05\n",
            "[1143]\ttraining's multi_logloss: 9.84529e-05\n",
            "[1144]\ttraining's multi_logloss: 9.82542e-05\n",
            "[1145]\ttraining's multi_logloss: 9.79984e-05\n",
            "[1146]\ttraining's multi_logloss: 9.77636e-05\n",
            "[1147]\ttraining's multi_logloss: 9.75354e-05\n",
            "[1148]\ttraining's multi_logloss: 9.73345e-05\n",
            "[1149]\ttraining's multi_logloss: 9.70871e-05\n",
            "[1150]\ttraining's multi_logloss: 9.68644e-05\n",
            "[1151]\ttraining's multi_logloss: 9.66429e-05\n",
            "[1152]\ttraining's multi_logloss: 9.64256e-05\n",
            "[1153]\ttraining's multi_logloss: 9.6187e-05\n",
            "[1154]\ttraining's multi_logloss: 9.60011e-05\n",
            "[1155]\ttraining's multi_logloss: 9.57747e-05\n",
            "[1156]\ttraining's multi_logloss: 9.54845e-05\n",
            "[1157]\ttraining's multi_logloss: 9.52218e-05\n",
            "[1158]\ttraining's multi_logloss: 9.49799e-05\n",
            "[1159]\ttraining's multi_logloss: 9.47358e-05\n",
            "[1160]\ttraining's multi_logloss: 9.44783e-05\n",
            "[1161]\ttraining's multi_logloss: 9.42701e-05\n",
            "[1162]\ttraining's multi_logloss: 9.40403e-05\n",
            "[1163]\ttraining's multi_logloss: 9.38221e-05\n",
            "[1164]\ttraining's multi_logloss: 9.36081e-05\n",
            "[1165]\ttraining's multi_logloss: 9.34071e-05\n",
            "[1166]\ttraining's multi_logloss: 9.31437e-05\n",
            "[1167]\ttraining's multi_logloss: 9.29058e-05\n",
            "[1168]\ttraining's multi_logloss: 9.2683e-05\n",
            "[1169]\ttraining's multi_logloss: 9.2435e-05\n",
            "[1170]\ttraining's multi_logloss: 9.22481e-05\n",
            "[1171]\ttraining's multi_logloss: 9.20253e-05\n",
            "[1172]\ttraining's multi_logloss: 9.18275e-05\n",
            "[1173]\ttraining's multi_logloss: 9.168e-05\n",
            "[1174]\ttraining's multi_logloss: 9.15177e-05\n",
            "[1175]\ttraining's multi_logloss: 9.12979e-05\n",
            "[1176]\ttraining's multi_logloss: 9.10954e-05\n",
            "[1177]\ttraining's multi_logloss: 9.0847e-05\n",
            "[1178]\ttraining's multi_logloss: 9.06104e-05\n",
            "[1179]\ttraining's multi_logloss: 9.03505e-05\n",
            "[1180]\ttraining's multi_logloss: 9.01541e-05\n",
            "[1181]\ttraining's multi_logloss: 8.9915e-05\n",
            "[1182]\ttraining's multi_logloss: 8.9717e-05\n",
            "[1183]\ttraining's multi_logloss: 8.95029e-05\n",
            "[1184]\ttraining's multi_logloss: 8.93201e-05\n",
            "[1185]\ttraining's multi_logloss: 8.91514e-05\n",
            "[1186]\ttraining's multi_logloss: 8.89361e-05\n",
            "[1187]\ttraining's multi_logloss: 8.87115e-05\n",
            "[1188]\ttraining's multi_logloss: 8.85325e-05\n",
            "[1189]\ttraining's multi_logloss: 8.82944e-05\n",
            "[1190]\ttraining's multi_logloss: 8.81296e-05\n",
            "[1191]\ttraining's multi_logloss: 8.79479e-05\n",
            "[1192]\ttraining's multi_logloss: 8.77561e-05\n",
            "[1193]\ttraining's multi_logloss: 8.75427e-05\n",
            "[1194]\ttraining's multi_logloss: 8.7345e-05\n",
            "[1195]\ttraining's multi_logloss: 8.71654e-05\n",
            "[1196]\ttraining's multi_logloss: 8.69595e-05\n",
            "[1197]\ttraining's multi_logloss: 8.67703e-05\n",
            "[1198]\ttraining's multi_logloss: 8.65711e-05\n",
            "[1199]\ttraining's multi_logloss: 8.63473e-05\n",
            "[1200]\ttraining's multi_logloss: 8.61856e-05\n",
            "[1201]\ttraining's multi_logloss: 8.60043e-05\n",
            "[1202]\ttraining's multi_logloss: 8.5805e-05\n",
            "[1203]\ttraining's multi_logloss: 8.56066e-05\n",
            "[1204]\ttraining's multi_logloss: 8.5453e-05\n",
            "[1205]\ttraining's multi_logloss: 8.52916e-05\n",
            "[1206]\ttraining's multi_logloss: 8.50678e-05\n",
            "[1207]\ttraining's multi_logloss: 8.48701e-05\n",
            "[1208]\ttraining's multi_logloss: 8.4664e-05\n",
            "[1209]\ttraining's multi_logloss: 8.44092e-05\n",
            "[1210]\ttraining's multi_logloss: 8.41966e-05\n",
            "[1211]\ttraining's multi_logloss: 8.40365e-05\n",
            "[1212]\ttraining's multi_logloss: 8.38478e-05\n",
            "[1213]\ttraining's multi_logloss: 8.37055e-05\n",
            "[1214]\ttraining's multi_logloss: 8.35211e-05\n",
            "[1215]\ttraining's multi_logloss: 8.33249e-05\n",
            "[1216]\ttraining's multi_logloss: 8.3157e-05\n",
            "[1217]\ttraining's multi_logloss: 8.29843e-05\n",
            "[1218]\ttraining's multi_logloss: 8.27596e-05\n",
            "[1219]\ttraining's multi_logloss: 8.2519e-05\n",
            "[1220]\ttraining's multi_logloss: 8.23248e-05\n",
            "[1221]\ttraining's multi_logloss: 8.21466e-05\n",
            "[1222]\ttraining's multi_logloss: 8.20184e-05\n",
            "[1223]\ttraining's multi_logloss: 8.18613e-05\n",
            "[1224]\ttraining's multi_logloss: 8.16667e-05\n",
            "[1225]\ttraining's multi_logloss: 8.15017e-05\n",
            "[1226]\ttraining's multi_logloss: 8.12936e-05\n",
            "[1227]\ttraining's multi_logloss: 8.11299e-05\n",
            "[1228]\ttraining's multi_logloss: 8.09326e-05\n",
            "[1229]\ttraining's multi_logloss: 8.07356e-05\n",
            "[1230]\ttraining's multi_logloss: 8.05571e-05\n",
            "[1231]\ttraining's multi_logloss: 8.03411e-05\n",
            "[1232]\ttraining's multi_logloss: 8.01517e-05\n",
            "[1233]\ttraining's multi_logloss: 7.99727e-05\n",
            "[1234]\ttraining's multi_logloss: 7.97366e-05\n",
            "[1235]\ttraining's multi_logloss: 7.95649e-05\n",
            "[1236]\ttraining's multi_logloss: 7.93815e-05\n",
            "[1237]\ttraining's multi_logloss: 7.9246e-05\n",
            "[1238]\ttraining's multi_logloss: 7.90418e-05\n",
            "[1239]\ttraining's multi_logloss: 7.88842e-05\n",
            "[1240]\ttraining's multi_logloss: 7.87178e-05\n",
            "[1241]\ttraining's multi_logloss: 7.8533e-05\n",
            "[1242]\ttraining's multi_logloss: 7.837e-05\n",
            "[1243]\ttraining's multi_logloss: 7.81956e-05\n",
            "[1244]\ttraining's multi_logloss: 7.80509e-05\n",
            "[1245]\ttraining's multi_logloss: 7.78533e-05\n",
            "[1246]\ttraining's multi_logloss: 7.76607e-05\n",
            "[1247]\ttraining's multi_logloss: 7.74771e-05\n",
            "[1248]\ttraining's multi_logloss: 7.72849e-05\n",
            "[1249]\ttraining's multi_logloss: 7.71094e-05\n",
            "[1250]\ttraining's multi_logloss: 7.69539e-05\n",
            "[1251]\ttraining's multi_logloss: 7.67272e-05\n",
            "[1252]\ttraining's multi_logloss: 7.65332e-05\n",
            "[1253]\ttraining's multi_logloss: 7.63705e-05\n",
            "[1254]\ttraining's multi_logloss: 7.61763e-05\n",
            "[1255]\ttraining's multi_logloss: 7.59919e-05\n",
            "[1256]\ttraining's multi_logloss: 7.58012e-05\n",
            "[1257]\ttraining's multi_logloss: 7.56433e-05\n",
            "[1258]\ttraining's multi_logloss: 7.54955e-05\n",
            "[1259]\ttraining's multi_logloss: 7.53733e-05\n",
            "[1260]\ttraining's multi_logloss: 7.52302e-05\n",
            "[1261]\ttraining's multi_logloss: 7.51067e-05\n",
            "[1262]\ttraining's multi_logloss: 7.49838e-05\n",
            "[1263]\ttraining's multi_logloss: 7.48856e-05\n",
            "[1264]\ttraining's multi_logloss: 7.47805e-05\n",
            "[1265]\ttraining's multi_logloss: 7.46646e-05\n",
            "[1266]\ttraining's multi_logloss: 7.44908e-05\n",
            "[1267]\ttraining's multi_logloss: 7.43191e-05\n",
            "[1268]\ttraining's multi_logloss: 7.41527e-05\n",
            "[1269]\ttraining's multi_logloss: 7.39865e-05\n",
            "[1270]\ttraining's multi_logloss: 7.38073e-05\n",
            "[1271]\ttraining's multi_logloss: 7.36731e-05\n",
            "[1272]\ttraining's multi_logloss: 7.35344e-05\n",
            "[1273]\ttraining's multi_logloss: 7.34041e-05\n",
            "[1274]\ttraining's multi_logloss: 7.32694e-05\n",
            "[1275]\ttraining's multi_logloss: 7.31401e-05\n",
            "[1276]\ttraining's multi_logloss: 7.29859e-05\n",
            "[1277]\ttraining's multi_logloss: 7.28225e-05\n",
            "[1278]\ttraining's multi_logloss: 7.26193e-05\n",
            "[1279]\ttraining's multi_logloss: 7.24603e-05\n",
            "[1280]\ttraining's multi_logloss: 7.23026e-05\n",
            "[1281]\ttraining's multi_logloss: 7.21183e-05\n",
            "[1282]\ttraining's multi_logloss: 7.19788e-05\n",
            "[1283]\ttraining's multi_logloss: 7.18115e-05\n",
            "[1284]\ttraining's multi_logloss: 7.16143e-05\n",
            "[1285]\ttraining's multi_logloss: 7.14533e-05\n",
            "[1286]\ttraining's multi_logloss: 7.1308e-05\n",
            "[1287]\ttraining's multi_logloss: 7.11315e-05\n",
            "[1288]\ttraining's multi_logloss: 7.09576e-05\n",
            "[1289]\ttraining's multi_logloss: 7.08118e-05\n",
            "[1290]\ttraining's multi_logloss: 7.07147e-05\n",
            "[1291]\ttraining's multi_logloss: 7.05892e-05\n",
            "[1292]\ttraining's multi_logloss: 7.04638e-05\n",
            "[1293]\ttraining's multi_logloss: 7.03348e-05\n",
            "[1294]\ttraining's multi_logloss: 7.02303e-05\n",
            "[1295]\ttraining's multi_logloss: 7.01228e-05\n",
            "[1296]\ttraining's multi_logloss: 7.00099e-05\n",
            "[1297]\ttraining's multi_logloss: 6.99128e-05\n",
            "[1298]\ttraining's multi_logloss: 6.98131e-05\n",
            "[1299]\ttraining's multi_logloss: 6.96888e-05\n",
            "[1300]\ttraining's multi_logloss: 6.95851e-05\n",
            "[1301]\ttraining's multi_logloss: 6.94406e-05\n",
            "[1302]\ttraining's multi_logloss: 6.9298e-05\n",
            "[1303]\ttraining's multi_logloss: 6.91465e-05\n",
            "[1304]\ttraining's multi_logloss: 6.89851e-05\n",
            "[1305]\ttraining's multi_logloss: 6.88795e-05\n",
            "[1306]\ttraining's multi_logloss: 6.87446e-05\n",
            "[1307]\ttraining's multi_logloss: 6.86189e-05\n",
            "[1308]\ttraining's multi_logloss: 6.84807e-05\n",
            "[1309]\ttraining's multi_logloss: 6.83646e-05\n",
            "[1310]\ttraining's multi_logloss: 6.82142e-05\n",
            "[1311]\ttraining's multi_logloss: 6.80185e-05\n",
            "[1312]\ttraining's multi_logloss: 6.78655e-05\n",
            "[1313]\ttraining's multi_logloss: 6.7717e-05\n",
            "[1314]\ttraining's multi_logloss: 6.7542e-05\n",
            "[1315]\ttraining's multi_logloss: 6.73933e-05\n",
            "[1316]\ttraining's multi_logloss: 6.72396e-05\n",
            "[1317]\ttraining's multi_logloss: 6.70996e-05\n",
            "[1318]\ttraining's multi_logloss: 6.69519e-05\n",
            "[1319]\ttraining's multi_logloss: 6.67999e-05\n",
            "[1320]\ttraining's multi_logloss: 6.66855e-05\n",
            "[1321]\ttraining's multi_logloss: 6.65119e-05\n",
            "[1322]\ttraining's multi_logloss: 6.63477e-05\n",
            "[1323]\ttraining's multi_logloss: 6.61919e-05\n",
            "[1324]\ttraining's multi_logloss: 6.60189e-05\n",
            "[1325]\ttraining's multi_logloss: 6.58893e-05\n",
            "[1326]\ttraining's multi_logloss: 6.57589e-05\n",
            "[1327]\ttraining's multi_logloss: 6.56242e-05\n",
            "[1328]\ttraining's multi_logloss: 6.5502e-05\n",
            "[1329]\ttraining's multi_logloss: 6.53969e-05\n",
            "[1330]\ttraining's multi_logloss: 6.5306e-05\n",
            "[1331]\ttraining's multi_logloss: 6.51817e-05\n",
            "[1332]\ttraining's multi_logloss: 6.50684e-05\n",
            "[1333]\ttraining's multi_logloss: 6.49376e-05\n",
            "[1334]\ttraining's multi_logloss: 6.48408e-05\n",
            "[1335]\ttraining's multi_logloss: 6.47347e-05\n",
            "[1336]\ttraining's multi_logloss: 6.46485e-05\n",
            "[1337]\ttraining's multi_logloss: 6.4552e-05\n",
            "[1338]\ttraining's multi_logloss: 6.44585e-05\n",
            "[1339]\ttraining's multi_logloss: 6.4384e-05\n",
            "[1340]\ttraining's multi_logloss: 6.42871e-05\n",
            "[1341]\ttraining's multi_logloss: 6.41228e-05\n",
            "[1342]\ttraining's multi_logloss: 6.39541e-05\n",
            "[1343]\ttraining's multi_logloss: 6.38032e-05\n",
            "[1344]\ttraining's multi_logloss: 6.36473e-05\n",
            "[1345]\ttraining's multi_logloss: 6.35162e-05\n",
            "[1346]\ttraining's multi_logloss: 6.33756e-05\n",
            "[1347]\ttraining's multi_logloss: 6.32325e-05\n",
            "[1348]\ttraining's multi_logloss: 6.31107e-05\n",
            "[1349]\ttraining's multi_logloss: 6.29927e-05\n",
            "[1350]\ttraining's multi_logloss: 6.289e-05\n",
            "[1351]\ttraining's multi_logloss: 6.27942e-05\n",
            "[1352]\ttraining's multi_logloss: 6.26866e-05\n",
            "[1353]\ttraining's multi_logloss: 6.2567e-05\n",
            "[1354]\ttraining's multi_logloss: 6.24682e-05\n",
            "[1355]\ttraining's multi_logloss: 6.23789e-05\n",
            "[1356]\ttraining's multi_logloss: 6.22571e-05\n",
            "[1357]\ttraining's multi_logloss: 6.21605e-05\n",
            "[1358]\ttraining's multi_logloss: 6.20697e-05\n",
            "[1359]\ttraining's multi_logloss: 6.19709e-05\n",
            "[1360]\ttraining's multi_logloss: 6.18388e-05\n",
            "[1361]\ttraining's multi_logloss: 6.17456e-05\n",
            "[1362]\ttraining's multi_logloss: 6.16511e-05\n",
            "[1363]\ttraining's multi_logloss: 6.15546e-05\n",
            "[1364]\ttraining's multi_logloss: 6.14544e-05\n",
            "[1365]\ttraining's multi_logloss: 6.13377e-05\n",
            "[1366]\ttraining's multi_logloss: 6.12501e-05\n",
            "[1367]\ttraining's multi_logloss: 6.11281e-05\n",
            "[1368]\ttraining's multi_logloss: 6.10188e-05\n",
            "[1369]\ttraining's multi_logloss: 6.09204e-05\n",
            "[1370]\ttraining's multi_logloss: 6.0823e-05\n",
            "[1371]\ttraining's multi_logloss: 6.07551e-05\n",
            "[1372]\ttraining's multi_logloss: 6.06839e-05\n",
            "[1373]\ttraining's multi_logloss: 6.06162e-05\n",
            "[1374]\ttraining's multi_logloss: 6.05315e-05\n",
            "[1375]\ttraining's multi_logloss: 6.04373e-05\n",
            "[1376]\ttraining's multi_logloss: 6.03191e-05\n",
            "[1377]\ttraining's multi_logloss: 6.02462e-05\n",
            "[1378]\ttraining's multi_logloss: 6.0108e-05\n",
            "[1379]\ttraining's multi_logloss: 5.99973e-05\n",
            "[1380]\ttraining's multi_logloss: 5.98866e-05\n",
            "[1381]\ttraining's multi_logloss: 5.97961e-05\n",
            "[1382]\ttraining's multi_logloss: 5.97e-05\n",
            "[1383]\ttraining's multi_logloss: 5.95854e-05\n",
            "[1384]\ttraining's multi_logloss: 5.95021e-05\n",
            "[1385]\ttraining's multi_logloss: 5.94203e-05\n",
            "[1386]\ttraining's multi_logloss: 5.93204e-05\n",
            "[1387]\ttraining's multi_logloss: 5.92214e-05\n",
            "[1388]\ttraining's multi_logloss: 5.912e-05\n",
            "[1389]\ttraining's multi_logloss: 5.90326e-05\n",
            "[1390]\ttraining's multi_logloss: 5.89487e-05\n",
            "[1391]\ttraining's multi_logloss: 5.88501e-05\n",
            "[1392]\ttraining's multi_logloss: 5.87517e-05\n",
            "[1393]\ttraining's multi_logloss: 5.86561e-05\n",
            "[1394]\ttraining's multi_logloss: 5.85832e-05\n",
            "[1395]\ttraining's multi_logloss: 5.84478e-05\n",
            "[1396]\ttraining's multi_logloss: 5.83499e-05\n",
            "[1397]\ttraining's multi_logloss: 5.82485e-05\n",
            "[1398]\ttraining's multi_logloss: 5.81401e-05\n",
            "[1399]\ttraining's multi_logloss: 5.80208e-05\n",
            "[1400]\ttraining's multi_logloss: 5.78921e-05\n",
            "[1401]\ttraining's multi_logloss: 5.77808e-05\n",
            "[1402]\ttraining's multi_logloss: 5.76635e-05\n",
            "[1403]\ttraining's multi_logloss: 5.75431e-05\n",
            "[1404]\ttraining's multi_logloss: 5.74053e-05\n",
            "[1405]\ttraining's multi_logloss: 5.72851e-05\n",
            "[1406]\ttraining's multi_logloss: 5.71715e-05\n",
            "[1407]\ttraining's multi_logloss: 5.70601e-05\n",
            "[1408]\ttraining's multi_logloss: 5.69713e-05\n",
            "[1409]\ttraining's multi_logloss: 5.6855e-05\n",
            "[1410]\ttraining's multi_logloss: 5.67346e-05\n",
            "[1411]\ttraining's multi_logloss: 5.66309e-05\n",
            "[1412]\ttraining's multi_logloss: 5.65128e-05\n",
            "[1413]\ttraining's multi_logloss: 5.63504e-05\n",
            "[1414]\ttraining's multi_logloss: 5.62034e-05\n",
            "[1415]\ttraining's multi_logloss: 5.60611e-05\n",
            "[1416]\ttraining's multi_logloss: 5.59627e-05\n",
            "[1417]\ttraining's multi_logloss: 5.58898e-05\n",
            "[1418]\ttraining's multi_logloss: 5.5792e-05\n",
            "[1419]\ttraining's multi_logloss: 5.57021e-05\n",
            "[1420]\ttraining's multi_logloss: 5.56166e-05\n",
            "[1421]\ttraining's multi_logloss: 5.55084e-05\n",
            "[1422]\ttraining's multi_logloss: 5.53778e-05\n",
            "[1423]\ttraining's multi_logloss: 5.52582e-05\n",
            "[1424]\ttraining's multi_logloss: 5.51416e-05\n",
            "[1425]\ttraining's multi_logloss: 5.50445e-05\n",
            "[1426]\ttraining's multi_logloss: 5.49715e-05\n",
            "[1427]\ttraining's multi_logloss: 5.49065e-05\n",
            "[1428]\ttraining's multi_logloss: 5.48514e-05\n",
            "[1429]\ttraining's multi_logloss: 5.47979e-05\n",
            "[1430]\ttraining's multi_logloss: 5.47304e-05\n",
            "[1431]\ttraining's multi_logloss: 5.46374e-05\n",
            "[1432]\ttraining's multi_logloss: 5.45295e-05\n",
            "[1433]\ttraining's multi_logloss: 5.44159e-05\n",
            "[1434]\ttraining's multi_logloss: 5.4317e-05\n",
            "[1435]\ttraining's multi_logloss: 5.42098e-05\n",
            "[1436]\ttraining's multi_logloss: 5.41197e-05\n",
            "[1437]\ttraining's multi_logloss: 5.40001e-05\n",
            "[1438]\ttraining's multi_logloss: 5.38993e-05\n",
            "[1439]\ttraining's multi_logloss: 5.38001e-05\n",
            "[1440]\ttraining's multi_logloss: 5.36962e-05\n",
            "[1441]\ttraining's multi_logloss: 5.35953e-05\n",
            "[1442]\ttraining's multi_logloss: 5.35035e-05\n",
            "[1443]\ttraining's multi_logloss: 5.34042e-05\n",
            "[1444]\ttraining's multi_logloss: 5.32841e-05\n",
            "[1445]\ttraining's multi_logloss: 5.31979e-05\n",
            "[1446]\ttraining's multi_logloss: 5.3117e-05\n",
            "[1447]\ttraining's multi_logloss: 5.30293e-05\n",
            "[1448]\ttraining's multi_logloss: 5.29263e-05\n",
            "[1449]\ttraining's multi_logloss: 5.28485e-05\n",
            "[1450]\ttraining's multi_logloss: 5.27652e-05\n",
            "[1451]\ttraining's multi_logloss: 5.26979e-05\n",
            "[1452]\ttraining's multi_logloss: 5.26408e-05\n",
            "[1453]\ttraining's multi_logloss: 5.25899e-05\n",
            "[1454]\ttraining's multi_logloss: 5.25082e-05\n",
            "[1455]\ttraining's multi_logloss: 5.24309e-05\n",
            "[1456]\ttraining's multi_logloss: 5.23123e-05\n",
            "[1457]\ttraining's multi_logloss: 5.22273e-05\n",
            "[1458]\ttraining's multi_logloss: 5.21332e-05\n",
            "[1459]\ttraining's multi_logloss: 5.20452e-05\n",
            "[1460]\ttraining's multi_logloss: 5.1978e-05\n",
            "[1461]\ttraining's multi_logloss: 5.19084e-05\n",
            "[1462]\ttraining's multi_logloss: 5.18234e-05\n",
            "[1463]\ttraining's multi_logloss: 5.17684e-05\n",
            "[1464]\ttraining's multi_logloss: 5.16931e-05\n",
            "[1465]\ttraining's multi_logloss: 5.16095e-05\n",
            "[1466]\ttraining's multi_logloss: 5.14892e-05\n",
            "[1467]\ttraining's multi_logloss: 5.13888e-05\n",
            "[1468]\ttraining's multi_logloss: 5.13206e-05\n",
            "[1469]\ttraining's multi_logloss: 5.12431e-05\n",
            "[1470]\ttraining's multi_logloss: 5.11508e-05\n",
            "[1471]\ttraining's multi_logloss: 5.10581e-05\n",
            "[1472]\ttraining's multi_logloss: 5.09573e-05\n",
            "[1473]\ttraining's multi_logloss: 5.08443e-05\n",
            "[1474]\ttraining's multi_logloss: 5.0763e-05\n",
            "[1475]\ttraining's multi_logloss: 5.06822e-05\n",
            "[1476]\ttraining's multi_logloss: 5.05872e-05\n",
            "[1477]\ttraining's multi_logloss: 5.04841e-05\n",
            "[1478]\ttraining's multi_logloss: 5.03776e-05\n",
            "[1479]\ttraining's multi_logloss: 5.02706e-05\n",
            "[1480]\ttraining's multi_logloss: 5.01718e-05\n",
            "[1481]\ttraining's multi_logloss: 5.01124e-05\n",
            "[1482]\ttraining's multi_logloss: 5.00402e-05\n",
            "[1483]\ttraining's multi_logloss: 4.99897e-05\n",
            "[1484]\ttraining's multi_logloss: 4.99269e-05\n",
            "[1485]\ttraining's multi_logloss: 4.98576e-05\n",
            "[1486]\ttraining's multi_logloss: 4.97948e-05\n",
            "[1487]\ttraining's multi_logloss: 4.9723e-05\n",
            "[1488]\ttraining's multi_logloss: 4.96363e-05\n",
            "[1489]\ttraining's multi_logloss: 4.95569e-05\n",
            "[1490]\ttraining's multi_logloss: 4.94925e-05\n",
            "[1491]\ttraining's multi_logloss: 4.94271e-05\n",
            "[1492]\ttraining's multi_logloss: 4.93487e-05\n",
            "[1493]\ttraining's multi_logloss: 4.92863e-05\n",
            "[1494]\ttraining's multi_logloss: 4.92128e-05\n",
            "[1495]\ttraining's multi_logloss: 4.91448e-05\n",
            "[1496]\ttraining's multi_logloss: 4.90587e-05\n",
            "[1497]\ttraining's multi_logloss: 4.89951e-05\n",
            "[1498]\ttraining's multi_logloss: 4.89227e-05\n",
            "[1499]\ttraining's multi_logloss: 4.8872e-05\n",
            "[1500]\ttraining's multi_logloss: 4.88169e-05\n",
            "[1501]\ttraining's multi_logloss: 4.87667e-05\n",
            "[1502]\ttraining's multi_logloss: 4.87067e-05\n",
            "[1503]\ttraining's multi_logloss: 4.86687e-05\n",
            "[1504]\ttraining's multi_logloss: 4.86029e-05\n",
            "[1505]\ttraining's multi_logloss: 4.8548e-05\n",
            "[1506]\ttraining's multi_logloss: 4.85073e-05\n",
            "[1507]\ttraining's multi_logloss: 4.84588e-05\n",
            "[1508]\ttraining's multi_logloss: 4.84256e-05\n",
            "[1509]\ttraining's multi_logloss: 4.83784e-05\n",
            "[1510]\ttraining's multi_logloss: 4.83251e-05\n",
            "[1511]\ttraining's multi_logloss: 4.8214e-05\n",
            "[1512]\ttraining's multi_logloss: 4.81217e-05\n",
            "[1513]\ttraining's multi_logloss: 4.80214e-05\n",
            "[1514]\ttraining's multi_logloss: 4.79227e-05\n",
            "[1515]\ttraining's multi_logloss: 4.78057e-05\n",
            "[1516]\ttraining's multi_logloss: 4.77402e-05\n",
            "[1517]\ttraining's multi_logloss: 4.77021e-05\n",
            "[1518]\ttraining's multi_logloss: 4.76683e-05\n",
            "[1519]\ttraining's multi_logloss: 4.7613e-05\n",
            "[1520]\ttraining's multi_logloss: 4.75744e-05\n",
            "[1521]\ttraining's multi_logloss: 4.7519e-05\n",
            "[1522]\ttraining's multi_logloss: 4.74655e-05\n",
            "[1523]\ttraining's multi_logloss: 4.74063e-05\n",
            "[1524]\ttraining's multi_logloss: 4.73522e-05\n",
            "[1525]\ttraining's multi_logloss: 4.73005e-05\n",
            "[1526]\ttraining's multi_logloss: 4.72177e-05\n",
            "[1527]\ttraining's multi_logloss: 4.71368e-05\n",
            "[1528]\ttraining's multi_logloss: 4.70644e-05\n",
            "[1529]\ttraining's multi_logloss: 4.70079e-05\n",
            "[1530]\ttraining's multi_logloss: 4.69432e-05\n",
            "[1531]\ttraining's multi_logloss: 4.68923e-05\n",
            "[1532]\ttraining's multi_logloss: 4.68392e-05\n",
            "[1533]\ttraining's multi_logloss: 4.67937e-05\n",
            "[1534]\ttraining's multi_logloss: 4.67504e-05\n",
            "[1535]\ttraining's multi_logloss: 4.66847e-05\n",
            "[1536]\ttraining's multi_logloss: 4.66415e-05\n",
            "[1537]\ttraining's multi_logloss: 4.65983e-05\n",
            "[1538]\ttraining's multi_logloss: 4.65117e-05\n",
            "[1539]\ttraining's multi_logloss: 4.64298e-05\n",
            "[1540]\ttraining's multi_logloss: 4.63379e-05\n",
            "[1541]\ttraining's multi_logloss: 4.62414e-05\n",
            "[1542]\ttraining's multi_logloss: 4.61697e-05\n",
            "[1543]\ttraining's multi_logloss: 4.60791e-05\n",
            "[1544]\ttraining's multi_logloss: 4.6019e-05\n",
            "[1545]\ttraining's multi_logloss: 4.59299e-05\n",
            "[1546]\ttraining's multi_logloss: 4.58806e-05\n",
            "[1547]\ttraining's multi_logloss: 4.58251e-05\n",
            "[1548]\ttraining's multi_logloss: 4.57902e-05\n",
            "[1549]\ttraining's multi_logloss: 4.5755e-05\n",
            "[1550]\ttraining's multi_logloss: 4.57274e-05\n",
            "[1551]\ttraining's multi_logloss: 4.56563e-05\n",
            "[1552]\ttraining's multi_logloss: 4.55918e-05\n",
            "[1553]\ttraining's multi_logloss: 4.55259e-05\n",
            "[1554]\ttraining's multi_logloss: 4.54474e-05\n",
            "[1555]\ttraining's multi_logloss: 4.5416e-05\n",
            "[1556]\ttraining's multi_logloss: 4.53465e-05\n",
            "[1557]\ttraining's multi_logloss: 4.52845e-05\n",
            "[1558]\ttraining's multi_logloss: 4.52161e-05\n",
            "[1559]\ttraining's multi_logloss: 4.51656e-05\n",
            "[1560]\ttraining's multi_logloss: 4.51308e-05\n",
            "[1561]\ttraining's multi_logloss: 4.50676e-05\n",
            "[1562]\ttraining's multi_logloss: 4.50129e-05\n",
            "[1563]\ttraining's multi_logloss: 4.49502e-05\n",
            "[1564]\ttraining's multi_logloss: 4.49069e-05\n",
            "[1565]\ttraining's multi_logloss: 4.48495e-05\n",
            "[1566]\ttraining's multi_logloss: 4.47406e-05\n",
            "[1567]\ttraining's multi_logloss: 4.46721e-05\n",
            "[1568]\ttraining's multi_logloss: 4.45953e-05\n",
            "[1569]\ttraining's multi_logloss: 4.44983e-05\n",
            "[1570]\ttraining's multi_logloss: 4.44186e-05\n",
            "[1571]\ttraining's multi_logloss: 4.43582e-05\n",
            "[1572]\ttraining's multi_logloss: 4.43036e-05\n",
            "[1573]\ttraining's multi_logloss: 4.42587e-05\n",
            "[1574]\ttraining's multi_logloss: 4.42098e-05\n",
            "[1575]\ttraining's multi_logloss: 4.41603e-05\n",
            "[1576]\ttraining's multi_logloss: 4.41194e-05\n",
            "[1577]\ttraining's multi_logloss: 4.40638e-05\n",
            "[1578]\ttraining's multi_logloss: 4.40224e-05\n",
            "[1579]\ttraining's multi_logloss: 4.39938e-05\n",
            "[1580]\ttraining's multi_logloss: 4.39699e-05\n",
            "[1581]\ttraining's multi_logloss: 4.39137e-05\n",
            "[1582]\ttraining's multi_logloss: 4.38636e-05\n",
            "[1583]\ttraining's multi_logloss: 4.38004e-05\n",
            "[1584]\ttraining's multi_logloss: 4.3745e-05\n",
            "[1585]\ttraining's multi_logloss: 4.37077e-05\n",
            "[1586]\ttraining's multi_logloss: 4.36802e-05\n",
            "[1587]\ttraining's multi_logloss: 4.36535e-05\n",
            "[1588]\ttraining's multi_logloss: 4.36178e-05\n",
            "[1589]\ttraining's multi_logloss: 4.35746e-05\n",
            "[1590]\ttraining's multi_logloss: 4.35429e-05\n",
            "[1591]\ttraining's multi_logloss: 4.34727e-05\n",
            "[1592]\ttraining's multi_logloss: 4.34211e-05\n",
            "[1593]\ttraining's multi_logloss: 4.33554e-05\n",
            "[1594]\ttraining's multi_logloss: 4.32973e-05\n",
            "[1595]\ttraining's multi_logloss: 4.32273e-05\n",
            "[1596]\ttraining's multi_logloss: 4.31579e-05\n",
            "[1597]\ttraining's multi_logloss: 4.30778e-05\n",
            "[1598]\ttraining's multi_logloss: 4.30158e-05\n",
            "[1599]\ttraining's multi_logloss: 4.29409e-05\n",
            "[1600]\ttraining's multi_logloss: 4.28606e-05\n",
            "[1601]\ttraining's multi_logloss: 4.28242e-05\n",
            "[1602]\ttraining's multi_logloss: 4.27544e-05\n",
            "[1603]\ttraining's multi_logloss: 4.27254e-05\n",
            "[1604]\ttraining's multi_logloss: 4.26911e-05\n",
            "[1605]\ttraining's multi_logloss: 4.26337e-05\n",
            "[1606]\ttraining's multi_logloss: 4.25896e-05\n",
            "[1607]\ttraining's multi_logloss: 4.25527e-05\n",
            "[1608]\ttraining's multi_logloss: 4.25241e-05\n",
            "[1609]\ttraining's multi_logloss: 4.24842e-05\n",
            "[1610]\ttraining's multi_logloss: 4.24611e-05\n",
            "[1611]\ttraining's multi_logloss: 4.24194e-05\n",
            "[1612]\ttraining's multi_logloss: 4.23788e-05\n",
            "[1613]\ttraining's multi_logloss: 4.23347e-05\n",
            "[1614]\ttraining's multi_logloss: 4.2293e-05\n",
            "[1615]\ttraining's multi_logloss: 4.22445e-05\n",
            "[1616]\ttraining's multi_logloss: 4.21876e-05\n",
            "[1617]\ttraining's multi_logloss: 4.21355e-05\n",
            "[1618]\ttraining's multi_logloss: 4.20881e-05\n",
            "[1619]\ttraining's multi_logloss: 4.20213e-05\n",
            "[1620]\ttraining's multi_logloss: 4.19518e-05\n",
            "[1621]\ttraining's multi_logloss: 4.19085e-05\n",
            "[1622]\ttraining's multi_logloss: 4.18599e-05\n",
            "[1623]\ttraining's multi_logloss: 4.18077e-05\n",
            "[1624]\ttraining's multi_logloss: 4.17476e-05\n",
            "[1625]\ttraining's multi_logloss: 4.16798e-05\n",
            "[1626]\ttraining's multi_logloss: 4.16081e-05\n",
            "[1627]\ttraining's multi_logloss: 4.15397e-05\n",
            "[1628]\ttraining's multi_logloss: 4.14549e-05\n",
            "[1629]\ttraining's multi_logloss: 4.13942e-05\n",
            "[1630]\ttraining's multi_logloss: 4.13296e-05\n",
            "[1631]\ttraining's multi_logloss: 4.12715e-05\n",
            "[1632]\ttraining's multi_logloss: 4.12095e-05\n",
            "[1633]\ttraining's multi_logloss: 4.11647e-05\n",
            "[1634]\ttraining's multi_logloss: 4.11151e-05\n",
            "[1635]\ttraining's multi_logloss: 4.10776e-05\n",
            "[1636]\ttraining's multi_logloss: 4.10423e-05\n",
            "[1637]\ttraining's multi_logloss: 4.10196e-05\n",
            "[1638]\ttraining's multi_logloss: 4.09924e-05\n",
            "[1639]\ttraining's multi_logloss: 4.09644e-05\n",
            "[1640]\ttraining's multi_logloss: 4.09444e-05\n",
            "[1641]\ttraining's multi_logloss: 4.08751e-05\n",
            "[1642]\ttraining's multi_logloss: 4.07994e-05\n",
            "[1643]\ttraining's multi_logloss: 4.07393e-05\n",
            "[1644]\ttraining's multi_logloss: 4.06593e-05\n",
            "[1645]\ttraining's multi_logloss: 4.05849e-05\n",
            "[1646]\ttraining's multi_logloss: 4.05446e-05\n",
            "[1647]\ttraining's multi_logloss: 4.0518e-05\n",
            "[1648]\ttraining's multi_logloss: 4.04916e-05\n",
            "[1649]\ttraining's multi_logloss: 4.04692e-05\n",
            "[1650]\ttraining's multi_logloss: 4.04408e-05\n",
            "[1651]\ttraining's multi_logloss: 4.04041e-05\n",
            "[1652]\ttraining's multi_logloss: 4.0356e-05\n",
            "[1653]\ttraining's multi_logloss: 4.03161e-05\n",
            "[1654]\ttraining's multi_logloss: 4.02832e-05\n",
            "[1655]\ttraining's multi_logloss: 4.0249e-05\n",
            "[1656]\ttraining's multi_logloss: 4.02118e-05\n",
            "[1657]\ttraining's multi_logloss: 4.01783e-05\n",
            "[1658]\ttraining's multi_logloss: 4.01388e-05\n",
            "[1659]\ttraining's multi_logloss: 4.00941e-05\n",
            "[1660]\ttraining's multi_logloss: 4.00596e-05\n",
            "[1661]\ttraining's multi_logloss: 3.99958e-05\n",
            "[1662]\ttraining's multi_logloss: 3.99349e-05\n",
            "[1663]\ttraining's multi_logloss: 3.98642e-05\n",
            "[1664]\ttraining's multi_logloss: 3.9805e-05\n",
            "[1665]\ttraining's multi_logloss: 3.97404e-05\n",
            "[1666]\ttraining's multi_logloss: 3.97041e-05\n",
            "[1667]\ttraining's multi_logloss: 3.96538e-05\n",
            "[1668]\ttraining's multi_logloss: 3.96089e-05\n",
            "[1669]\ttraining's multi_logloss: 3.95844e-05\n",
            "[1670]\ttraining's multi_logloss: 3.95648e-05\n",
            "[1671]\ttraining's multi_logloss: 3.95219e-05\n",
            "[1672]\ttraining's multi_logloss: 3.94731e-05\n",
            "[1673]\ttraining's multi_logloss: 3.94062e-05\n",
            "[1674]\ttraining's multi_logloss: 3.93413e-05\n",
            "[1675]\ttraining's multi_logloss: 3.92417e-05\n",
            "[1676]\ttraining's multi_logloss: 3.92099e-05\n",
            "[1677]\ttraining's multi_logloss: 3.91806e-05\n",
            "[1678]\ttraining's multi_logloss: 3.91583e-05\n",
            "[1679]\ttraining's multi_logloss: 3.91439e-05\n",
            "[1680]\ttraining's multi_logloss: 3.91226e-05\n",
            "[1681]\ttraining's multi_logloss: 3.9065e-05\n",
            "[1682]\ttraining's multi_logloss: 3.90051e-05\n",
            "[1683]\ttraining's multi_logloss: 3.89629e-05\n",
            "[1684]\ttraining's multi_logloss: 3.89161e-05\n",
            "[1685]\ttraining's multi_logloss: 3.88505e-05\n",
            "[1686]\ttraining's multi_logloss: 3.88102e-05\n",
            "[1687]\ttraining's multi_logloss: 3.87772e-05\n",
            "[1688]\ttraining's multi_logloss: 3.87303e-05\n",
            "[1689]\ttraining's multi_logloss: 3.86919e-05\n",
            "[1690]\ttraining's multi_logloss: 3.86677e-05\n",
            "[1691]\ttraining's multi_logloss: 3.86391e-05\n",
            "[1692]\ttraining's multi_logloss: 3.86123e-05\n",
            "[1693]\ttraining's multi_logloss: 3.85739e-05\n",
            "[1694]\ttraining's multi_logloss: 3.85141e-05\n",
            "[1695]\ttraining's multi_logloss: 3.84938e-05\n",
            "[1696]\ttraining's multi_logloss: 3.84433e-05\n",
            "[1697]\ttraining's multi_logloss: 3.83856e-05\n",
            "[1698]\ttraining's multi_logloss: 3.83364e-05\n",
            "[1699]\ttraining's multi_logloss: 3.82787e-05\n",
            "[1700]\ttraining's multi_logloss: 3.82402e-05\n",
            "[1701]\ttraining's multi_logloss: 3.81791e-05\n",
            "[1702]\ttraining's multi_logloss: 3.81266e-05\n",
            "[1703]\ttraining's multi_logloss: 3.80821e-05\n",
            "[1704]\ttraining's multi_logloss: 3.80356e-05\n",
            "[1705]\ttraining's multi_logloss: 3.79916e-05\n",
            "[1706]\ttraining's multi_logloss: 3.79495e-05\n",
            "[1707]\ttraining's multi_logloss: 3.7915e-05\n",
            "[1708]\ttraining's multi_logloss: 3.78815e-05\n",
            "[1709]\ttraining's multi_logloss: 3.78437e-05\n",
            "[1710]\ttraining's multi_logloss: 3.78212e-05\n",
            "[1711]\ttraining's multi_logloss: 3.77631e-05\n",
            "[1712]\ttraining's multi_logloss: 3.77088e-05\n",
            "[1713]\ttraining's multi_logloss: 3.76416e-05\n",
            "[1714]\ttraining's multi_logloss: 3.75857e-05\n",
            "[1715]\ttraining's multi_logloss: 3.7541e-05\n",
            "[1716]\ttraining's multi_logloss: 3.75041e-05\n",
            "[1717]\ttraining's multi_logloss: 3.74751e-05\n",
            "[1718]\ttraining's multi_logloss: 3.74269e-05\n",
            "[1719]\ttraining's multi_logloss: 3.73824e-05\n",
            "[1720]\ttraining's multi_logloss: 3.73379e-05\n",
            "[1721]\ttraining's multi_logloss: 3.72995e-05\n",
            "[1722]\ttraining's multi_logloss: 3.7254e-05\n",
            "[1723]\ttraining's multi_logloss: 3.72044e-05\n",
            "[1724]\ttraining's multi_logloss: 3.71685e-05\n",
            "[1725]\ttraining's multi_logloss: 3.71258e-05\n",
            "[1726]\ttraining's multi_logloss: 3.70767e-05\n",
            "[1727]\ttraining's multi_logloss: 3.70277e-05\n",
            "[1728]\ttraining's multi_logloss: 3.6991e-05\n",
            "[1729]\ttraining's multi_logloss: 3.69632e-05\n",
            "[1730]\ttraining's multi_logloss: 3.69068e-05\n",
            "[1731]\ttraining's multi_logloss: 3.68773e-05\n",
            "[1732]\ttraining's multi_logloss: 3.68586e-05\n",
            "[1733]\ttraining's multi_logloss: 3.68225e-05\n",
            "[1734]\ttraining's multi_logloss: 3.67832e-05\n",
            "[1735]\ttraining's multi_logloss: 3.6761e-05\n",
            "[1736]\ttraining's multi_logloss: 3.67342e-05\n",
            "[1737]\ttraining's multi_logloss: 3.67123e-05\n",
            "[1738]\ttraining's multi_logloss: 3.66787e-05\n",
            "[1739]\ttraining's multi_logloss: 3.66591e-05\n",
            "[1740]\ttraining's multi_logloss: 3.66342e-05\n",
            "[1741]\ttraining's multi_logloss: 3.65695e-05\n",
            "[1742]\ttraining's multi_logloss: 3.65236e-05\n",
            "[1743]\ttraining's multi_logloss: 3.64811e-05\n",
            "[1744]\ttraining's multi_logloss: 3.6432e-05\n",
            "[1745]\ttraining's multi_logloss: 3.63782e-05\n",
            "[1746]\ttraining's multi_logloss: 3.6311e-05\n",
            "[1747]\ttraining's multi_logloss: 3.62617e-05\n",
            "[1748]\ttraining's multi_logloss: 3.62038e-05\n",
            "[1749]\ttraining's multi_logloss: 3.61734e-05\n",
            "[1750]\ttraining's multi_logloss: 3.61471e-05\n",
            "[1751]\ttraining's multi_logloss: 3.61011e-05\n",
            "[1752]\ttraining's multi_logloss: 3.60531e-05\n",
            "[1753]\ttraining's multi_logloss: 3.59986e-05\n",
            "[1754]\ttraining's multi_logloss: 3.59691e-05\n",
            "[1755]\ttraining's multi_logloss: 3.5931e-05\n",
            "[1756]\ttraining's multi_logloss: 3.5881e-05\n",
            "[1757]\ttraining's multi_logloss: 3.58386e-05\n",
            "[1758]\ttraining's multi_logloss: 3.57734e-05\n",
            "[1759]\ttraining's multi_logloss: 3.57299e-05\n",
            "[1760]\ttraining's multi_logloss: 3.56834e-05\n",
            "[1761]\ttraining's multi_logloss: 3.56446e-05\n",
            "[1762]\ttraining's multi_logloss: 3.56018e-05\n",
            "[1763]\ttraining's multi_logloss: 3.55592e-05\n",
            "[1764]\ttraining's multi_logloss: 3.55355e-05\n",
            "[1765]\ttraining's multi_logloss: 3.54899e-05\n",
            "[1766]\ttraining's multi_logloss: 3.54686e-05\n",
            "[1767]\ttraining's multi_logloss: 3.54385e-05\n",
            "[1768]\ttraining's multi_logloss: 3.53932e-05\n",
            "[1769]\ttraining's multi_logloss: 3.53598e-05\n",
            "[1770]\ttraining's multi_logloss: 3.5335e-05\n",
            "[1771]\ttraining's multi_logloss: 3.53009e-05\n",
            "[1772]\ttraining's multi_logloss: 3.52686e-05\n",
            "[1773]\ttraining's multi_logloss: 3.52383e-05\n",
            "[1774]\ttraining's multi_logloss: 3.52006e-05\n",
            "[1775]\ttraining's multi_logloss: 3.51702e-05\n",
            "[1776]\ttraining's multi_logloss: 3.51227e-05\n",
            "[1777]\ttraining's multi_logloss: 3.50852e-05\n",
            "[1778]\ttraining's multi_logloss: 3.50437e-05\n",
            "[1779]\ttraining's multi_logloss: 3.49959e-05\n",
            "[1780]\ttraining's multi_logloss: 3.49591e-05\n",
            "[1781]\ttraining's multi_logloss: 3.49355e-05\n",
            "[1782]\ttraining's multi_logloss: 3.49154e-05\n",
            "[1783]\ttraining's multi_logloss: 3.4889e-05\n",
            "[1784]\ttraining's multi_logloss: 3.48733e-05\n",
            "[1785]\ttraining's multi_logloss: 3.48501e-05\n",
            "[1786]\ttraining's multi_logloss: 3.48041e-05\n",
            "[1787]\ttraining's multi_logloss: 3.47649e-05\n",
            "[1788]\ttraining's multi_logloss: 3.47381e-05\n",
            "[1789]\ttraining's multi_logloss: 3.46945e-05\n",
            "[1790]\ttraining's multi_logloss: 3.46525e-05\n",
            "[1791]\ttraining's multi_logloss: 3.46099e-05\n",
            "[1792]\ttraining's multi_logloss: 3.45652e-05\n",
            "[1793]\ttraining's multi_logloss: 3.4508e-05\n",
            "[1794]\ttraining's multi_logloss: 3.44579e-05\n",
            "[1795]\ttraining's multi_logloss: 3.44111e-05\n",
            "[1796]\ttraining's multi_logloss: 3.43894e-05\n",
            "[1797]\ttraining's multi_logloss: 3.43714e-05\n",
            "[1798]\ttraining's multi_logloss: 3.43564e-05\n",
            "[1799]\ttraining's multi_logloss: 3.43276e-05\n",
            "[1800]\ttraining's multi_logloss: 3.43108e-05\n",
            "[1801]\ttraining's multi_logloss: 3.42791e-05\n",
            "[1802]\ttraining's multi_logloss: 3.42399e-05\n",
            "[1803]\ttraining's multi_logloss: 3.42118e-05\n",
            "[1804]\ttraining's multi_logloss: 3.41941e-05\n",
            "[1805]\ttraining's multi_logloss: 3.41559e-05\n",
            "[1806]\ttraining's multi_logloss: 3.41372e-05\n",
            "[1807]\ttraining's multi_logloss: 3.41061e-05\n",
            "[1808]\ttraining's multi_logloss: 3.40783e-05\n",
            "[1809]\ttraining's multi_logloss: 3.40525e-05\n",
            "[1810]\ttraining's multi_logloss: 3.40224e-05\n",
            "[1811]\ttraining's multi_logloss: 3.39951e-05\n",
            "[1812]\ttraining's multi_logloss: 3.39772e-05\n",
            "[1813]\ttraining's multi_logloss: 3.39653e-05\n",
            "[1814]\ttraining's multi_logloss: 3.39538e-05\n",
            "[1815]\ttraining's multi_logloss: 3.39337e-05\n",
            "[1816]\ttraining's multi_logloss: 3.39097e-05\n",
            "[1817]\ttraining's multi_logloss: 3.38871e-05\n",
            "[1818]\ttraining's multi_logloss: 3.38588e-05\n",
            "[1819]\ttraining's multi_logloss: 3.38456e-05\n",
            "[1820]\ttraining's multi_logloss: 3.38252e-05\n",
            "[1821]\ttraining's multi_logloss: 3.37965e-05\n",
            "[1822]\ttraining's multi_logloss: 3.37723e-05\n",
            "[1823]\ttraining's multi_logloss: 3.37382e-05\n",
            "[1824]\ttraining's multi_logloss: 3.37109e-05\n",
            "[1825]\ttraining's multi_logloss: 3.36876e-05\n",
            "[1826]\ttraining's multi_logloss: 3.36509e-05\n",
            "[1827]\ttraining's multi_logloss: 3.36195e-05\n",
            "[1828]\ttraining's multi_logloss: 3.35906e-05\n",
            "[1829]\ttraining's multi_logloss: 3.35677e-05\n",
            "[1830]\ttraining's multi_logloss: 3.35429e-05\n",
            "[1831]\ttraining's multi_logloss: 3.35136e-05\n",
            "[1832]\ttraining's multi_logloss: 3.34898e-05\n",
            "[1833]\ttraining's multi_logloss: 3.34701e-05\n",
            "[1834]\ttraining's multi_logloss: 3.34515e-05\n",
            "[1835]\ttraining's multi_logloss: 3.34243e-05\n",
            "[1836]\ttraining's multi_logloss: 3.34039e-05\n",
            "[1837]\ttraining's multi_logloss: 3.33849e-05\n",
            "[1838]\ttraining's multi_logloss: 3.33646e-05\n",
            "[1839]\ttraining's multi_logloss: 3.33526e-05\n",
            "[1840]\ttraining's multi_logloss: 3.33286e-05\n",
            "[1841]\ttraining's multi_logloss: 3.33103e-05\n",
            "[1842]\ttraining's multi_logloss: 3.32884e-05\n",
            "[1843]\ttraining's multi_logloss: 3.32613e-05\n",
            "[1844]\ttraining's multi_logloss: 3.32452e-05\n",
            "[1845]\ttraining's multi_logloss: 3.3241e-05\n",
            "[1846]\ttraining's multi_logloss: 3.3208e-05\n",
            "[1847]\ttraining's multi_logloss: 3.31781e-05\n",
            "[1848]\ttraining's multi_logloss: 3.31483e-05\n",
            "[1849]\ttraining's multi_logloss: 3.31336e-05\n",
            "[1850]\ttraining's multi_logloss: 3.31173e-05\n",
            "[1851]\ttraining's multi_logloss: 3.31007e-05\n",
            "[1852]\ttraining's multi_logloss: 3.30814e-05\n",
            "[1853]\ttraining's multi_logloss: 3.30685e-05\n",
            "[1854]\ttraining's multi_logloss: 3.30507e-05\n",
            "[1855]\ttraining's multi_logloss: 3.30253e-05\n",
            "[1856]\ttraining's multi_logloss: 3.2989e-05\n",
            "[1857]\ttraining's multi_logloss: 3.29497e-05\n",
            "[1858]\ttraining's multi_logloss: 3.29058e-05\n",
            "[1859]\ttraining's multi_logloss: 3.28793e-05\n",
            "[1860]\ttraining's multi_logloss: 3.28541e-05\n",
            "[1861]\ttraining's multi_logloss: 3.28167e-05\n",
            "[1862]\ttraining's multi_logloss: 3.28071e-05\n",
            "[1863]\ttraining's multi_logloss: 3.2778e-05\n",
            "[1864]\ttraining's multi_logloss: 3.27598e-05\n",
            "[1865]\ttraining's multi_logloss: 3.27335e-05\n",
            "[1866]\ttraining's multi_logloss: 3.27147e-05\n",
            "[1867]\ttraining's multi_logloss: 3.26997e-05\n",
            "[1868]\ttraining's multi_logloss: 3.26773e-05\n",
            "[1869]\ttraining's multi_logloss: 3.26586e-05\n",
            "[1870]\ttraining's multi_logloss: 3.26329e-05\n",
            "[1871]\ttraining's multi_logloss: 3.25943e-05\n",
            "[1872]\ttraining's multi_logloss: 3.25629e-05\n",
            "[1873]\ttraining's multi_logloss: 3.25362e-05\n",
            "[1874]\ttraining's multi_logloss: 3.25128e-05\n",
            "[1875]\ttraining's multi_logloss: 3.24896e-05\n",
            "[1876]\ttraining's multi_logloss: 3.24621e-05\n",
            "[1877]\ttraining's multi_logloss: 3.24396e-05\n",
            "[1878]\ttraining's multi_logloss: 3.24055e-05\n",
            "[1879]\ttraining's multi_logloss: 3.23764e-05\n",
            "[1880]\ttraining's multi_logloss: 3.23424e-05\n",
            "[1881]\ttraining's multi_logloss: 3.23087e-05\n",
            "[1882]\ttraining's multi_logloss: 3.22861e-05\n",
            "[1883]\ttraining's multi_logloss: 3.22581e-05\n",
            "[1884]\ttraining's multi_logloss: 3.22322e-05\n",
            "[1885]\ttraining's multi_logloss: 3.22088e-05\n",
            "[1886]\ttraining's multi_logloss: 3.2184e-05\n",
            "[1887]\ttraining's multi_logloss: 3.21621e-05\n",
            "[1888]\ttraining's multi_logloss: 3.21296e-05\n",
            "[1889]\ttraining's multi_logloss: 3.21096e-05\n",
            "[1890]\ttraining's multi_logloss: 3.20961e-05\n",
            "[1891]\ttraining's multi_logloss: 3.20758e-05\n",
            "[1892]\ttraining's multi_logloss: 3.20456e-05\n",
            "[1893]\ttraining's multi_logloss: 3.20372e-05\n",
            "[1894]\ttraining's multi_logloss: 3.20206e-05\n",
            "[1895]\ttraining's multi_logloss: 3.19868e-05\n",
            "[1896]\ttraining's multi_logloss: 3.19618e-05\n",
            "[1897]\ttraining's multi_logloss: 3.19218e-05\n",
            "[1898]\ttraining's multi_logloss: 3.18926e-05\n",
            "[1899]\ttraining's multi_logloss: 3.1868e-05\n",
            "[1900]\ttraining's multi_logloss: 3.18367e-05\n",
            "[1901]\ttraining's multi_logloss: 3.18096e-05\n",
            "[1902]\ttraining's multi_logloss: 3.17679e-05\n",
            "[1903]\ttraining's multi_logloss: 3.17439e-05\n",
            "[1904]\ttraining's multi_logloss: 3.17064e-05\n",
            "[1905]\ttraining's multi_logloss: 3.16771e-05\n",
            "[1906]\ttraining's multi_logloss: 3.16503e-05\n",
            "[1907]\ttraining's multi_logloss: 3.16154e-05\n",
            "[1908]\ttraining's multi_logloss: 3.1604e-05\n",
            "[1909]\ttraining's multi_logloss: 3.15839e-05\n",
            "[1910]\ttraining's multi_logloss: 3.15504e-05\n",
            "[1911]\ttraining's multi_logloss: 3.15351e-05\n",
            "[1912]\ttraining's multi_logloss: 3.15263e-05\n",
            "[1913]\ttraining's multi_logloss: 3.15149e-05\n",
            "[1914]\ttraining's multi_logloss: 3.15122e-05\n",
            "[1915]\ttraining's multi_logloss: 3.15079e-05\n",
            "[1916]\ttraining's multi_logloss: 3.14796e-05\n",
            "[1917]\ttraining's multi_logloss: 3.1449e-05\n",
            "[1918]\ttraining's multi_logloss: 3.14151e-05\n",
            "[1919]\ttraining's multi_logloss: 3.13964e-05\n",
            "[1920]\ttraining's multi_logloss: 3.13768e-05\n",
            "[1921]\ttraining's multi_logloss: 3.13519e-05\n",
            "[1922]\ttraining's multi_logloss: 3.13292e-05\n",
            "[1923]\ttraining's multi_logloss: 3.13175e-05\n",
            "[1924]\ttraining's multi_logloss: 3.13048e-05\n",
            "[1925]\ttraining's multi_logloss: 3.12783e-05\n",
            "[1926]\ttraining's multi_logloss: 3.12532e-05\n",
            "[1927]\ttraining's multi_logloss: 3.12251e-05\n",
            "[1928]\ttraining's multi_logloss: 3.11964e-05\n",
            "[1929]\ttraining's multi_logloss: 3.11749e-05\n",
            "[1930]\ttraining's multi_logloss: 3.11152e-05\n",
            "[1931]\ttraining's multi_logloss: 3.10898e-05\n",
            "[1932]\ttraining's multi_logloss: 3.10545e-05\n",
            "[1933]\ttraining's multi_logloss: 3.10247e-05\n",
            "[1934]\ttraining's multi_logloss: 3.09948e-05\n",
            "[1935]\ttraining's multi_logloss: 3.09772e-05\n",
            "[1936]\ttraining's multi_logloss: 3.09508e-05\n",
            "[1937]\ttraining's multi_logloss: 3.09382e-05\n",
            "[1938]\ttraining's multi_logloss: 3.09255e-05\n",
            "[1939]\ttraining's multi_logloss: 3.09164e-05\n",
            "[1940]\ttraining's multi_logloss: 3.09101e-05\n",
            "[1941]\ttraining's multi_logloss: 3.08792e-05\n",
            "[1942]\ttraining's multi_logloss: 3.08565e-05\n",
            "[1943]\ttraining's multi_logloss: 3.0842e-05\n",
            "[1944]\ttraining's multi_logloss: 3.08126e-05\n",
            "[1945]\ttraining's multi_logloss: 3.07861e-05\n",
            "[1946]\ttraining's multi_logloss: 3.07698e-05\n",
            "[1947]\ttraining's multi_logloss: 3.0739e-05\n",
            "[1948]\ttraining's multi_logloss: 3.07011e-05\n",
            "[1949]\ttraining's multi_logloss: 3.06683e-05\n",
            "[1950]\ttraining's multi_logloss: 3.06517e-05\n",
            "[1951]\ttraining's multi_logloss: 3.06144e-05\n",
            "[1952]\ttraining's multi_logloss: 3.05904e-05\n",
            "[1953]\ttraining's multi_logloss: 3.05556e-05\n",
            "[1954]\ttraining's multi_logloss: 3.05101e-05\n",
            "[1955]\ttraining's multi_logloss: 3.04739e-05\n",
            "[1956]\ttraining's multi_logloss: 3.04396e-05\n",
            "[1957]\ttraining's multi_logloss: 3.04258e-05\n",
            "[1958]\ttraining's multi_logloss: 3.04049e-05\n",
            "[1959]\ttraining's multi_logloss: 3.03678e-05\n",
            "[1960]\ttraining's multi_logloss: 3.03425e-05\n",
            "[1961]\ttraining's multi_logloss: 3.03261e-05\n",
            "[1962]\ttraining's multi_logloss: 3.02967e-05\n",
            "[1963]\ttraining's multi_logloss: 3.02827e-05\n",
            "[1964]\ttraining's multi_logloss: 3.02724e-05\n",
            "[1965]\ttraining's multi_logloss: 3.02556e-05\n",
            "[1966]\ttraining's multi_logloss: 3.02381e-05\n",
            "[1967]\ttraining's multi_logloss: 3.02242e-05\n",
            "[1968]\ttraining's multi_logloss: 3.02029e-05\n",
            "[1969]\ttraining's multi_logloss: 3.01805e-05\n",
            "[1970]\ttraining's multi_logloss: 3.01638e-05\n",
            "[1971]\ttraining's multi_logloss: 3.0136e-05\n",
            "[1972]\ttraining's multi_logloss: 3.01099e-05\n",
            "[1973]\ttraining's multi_logloss: 3.00838e-05\n",
            "[1974]\ttraining's multi_logloss: 3.00659e-05\n",
            "[1975]\ttraining's multi_logloss: 3.00331e-05\n",
            "[1976]\ttraining's multi_logloss: 3.00115e-05\n",
            "[1977]\ttraining's multi_logloss: 2.9998e-05\n",
            "[1978]\ttraining's multi_logloss: 2.99852e-05\n",
            "[1979]\ttraining's multi_logloss: 2.99781e-05\n",
            "[1980]\ttraining's multi_logloss: 2.99716e-05\n",
            "[1981]\ttraining's multi_logloss: 2.99568e-05\n",
            "[1982]\ttraining's multi_logloss: 2.99436e-05\n",
            "[1983]\ttraining's multi_logloss: 2.99144e-05\n",
            "[1984]\ttraining's multi_logloss: 2.99088e-05\n",
            "[1985]\ttraining's multi_logloss: 2.98938e-05\n",
            "[1986]\ttraining's multi_logloss: 2.98794e-05\n",
            "[1987]\ttraining's multi_logloss: 2.98731e-05\n",
            "[1988]\ttraining's multi_logloss: 2.98617e-05\n",
            "[1989]\ttraining's multi_logloss: 2.98465e-05\n",
            "[1990]\ttraining's multi_logloss: 2.98337e-05\n",
            "[1991]\ttraining's multi_logloss: 2.98042e-05\n",
            "[1992]\ttraining's multi_logloss: 2.97848e-05\n",
            "[1993]\ttraining's multi_logloss: 2.97593e-05\n",
            "[1994]\ttraining's multi_logloss: 2.97241e-05\n",
            "[1995]\ttraining's multi_logloss: 2.97018e-05\n",
            "[1996]\ttraining's multi_logloss: 2.96854e-05\n",
            "[1997]\ttraining's multi_logloss: 2.96612e-05\n",
            "[1998]\ttraining's multi_logloss: 2.96306e-05\n",
            "[1999]\ttraining's multi_logloss: 2.96058e-05\n",
            "[2000]\ttraining's multi_logloss: 2.95667e-05\n",
            "[2001]\ttraining's multi_logloss: 2.95562e-05\n",
            "[2002]\ttraining's multi_logloss: 2.95456e-05\n",
            "[2003]\ttraining's multi_logloss: 2.9533e-05\n",
            "[2004]\ttraining's multi_logloss: 2.95227e-05\n",
            "[2005]\ttraining's multi_logloss: 2.95175e-05\n",
            "[2006]\ttraining's multi_logloss: 2.94966e-05\n",
            "[2007]\ttraining's multi_logloss: 2.94778e-05\n",
            "[2008]\ttraining's multi_logloss: 2.94515e-05\n",
            "[2009]\ttraining's multi_logloss: 2.94387e-05\n",
            "[2010]\ttraining's multi_logloss: 2.94185e-05\n",
            "[2011]\ttraining's multi_logloss: 2.94025e-05\n",
            "[2012]\ttraining's multi_logloss: 2.93907e-05\n",
            "[2013]\ttraining's multi_logloss: 2.93739e-05\n",
            "[2014]\ttraining's multi_logloss: 2.93597e-05\n",
            "[2015]\ttraining's multi_logloss: 2.93335e-05\n",
            "[2016]\ttraining's multi_logloss: 2.93149e-05\n",
            "[2017]\ttraining's multi_logloss: 2.92933e-05\n",
            "[2018]\ttraining's multi_logloss: 2.9277e-05\n",
            "[2019]\ttraining's multi_logloss: 2.92635e-05\n",
            "[2020]\ttraining's multi_logloss: 2.92538e-05\n",
            "[2021]\ttraining's multi_logloss: 2.92211e-05\n",
            "[2022]\ttraining's multi_logloss: 2.92021e-05\n",
            "[2023]\ttraining's multi_logloss: 2.91821e-05\n",
            "[2024]\ttraining's multi_logloss: 2.91557e-05\n",
            "[2025]\ttraining's multi_logloss: 2.9144e-05\n",
            "[2026]\ttraining's multi_logloss: 2.9131e-05\n",
            "[2027]\ttraining's multi_logloss: 2.91185e-05\n",
            "[2028]\ttraining's multi_logloss: 2.91078e-05\n",
            "[2029]\ttraining's multi_logloss: 2.90992e-05\n",
            "[2030]\ttraining's multi_logloss: 2.90955e-05\n",
            "[2031]\ttraining's multi_logloss: 2.90722e-05\n",
            "[2032]\ttraining's multi_logloss: 2.90491e-05\n",
            "[2033]\ttraining's multi_logloss: 2.90307e-05\n",
            "[2034]\ttraining's multi_logloss: 2.9013e-05\n",
            "[2035]\ttraining's multi_logloss: 2.89847e-05\n",
            "[2036]\ttraining's multi_logloss: 2.89488e-05\n",
            "[2037]\ttraining's multi_logloss: 2.89334e-05\n",
            "[2038]\ttraining's multi_logloss: 2.89215e-05\n",
            "[2039]\ttraining's multi_logloss: 2.89121e-05\n",
            "[2040]\ttraining's multi_logloss: 2.89063e-05\n",
            "[2041]\ttraining's multi_logloss: 2.88839e-05\n",
            "[2042]\ttraining's multi_logloss: 2.88709e-05\n",
            "[2043]\ttraining's multi_logloss: 2.88544e-05\n",
            "[2044]\ttraining's multi_logloss: 2.88393e-05\n",
            "[2045]\ttraining's multi_logloss: 2.88292e-05\n",
            "[2046]\ttraining's multi_logloss: 2.88151e-05\n",
            "[2047]\ttraining's multi_logloss: 2.8802e-05\n",
            "[2048]\ttraining's multi_logloss: 2.87941e-05\n",
            "[2049]\ttraining's multi_logloss: 2.87887e-05\n",
            "[2050]\ttraining's multi_logloss: 2.87696e-05\n",
            "[2051]\ttraining's multi_logloss: 2.87608e-05\n",
            "[2052]\ttraining's multi_logloss: 2.87465e-05\n",
            "[2053]\ttraining's multi_logloss: 2.87425e-05\n",
            "[2054]\ttraining's multi_logloss: 2.8732e-05\n",
            "[2055]\ttraining's multi_logloss: 2.87311e-05\n",
            "[2056]\ttraining's multi_logloss: 2.87049e-05\n",
            "[2057]\ttraining's multi_logloss: 2.86882e-05\n",
            "[2058]\ttraining's multi_logloss: 2.86741e-05\n",
            "[2059]\ttraining's multi_logloss: 2.86506e-05\n",
            "[2060]\ttraining's multi_logloss: 2.86314e-05\n",
            "[2061]\ttraining's multi_logloss: 2.8604e-05\n",
            "[2062]\ttraining's multi_logloss: 2.85911e-05\n",
            "[2063]\ttraining's multi_logloss: 2.85716e-05\n",
            "[2064]\ttraining's multi_logloss: 2.85559e-05\n",
            "[2065]\ttraining's multi_logloss: 2.854e-05\n",
            "[2066]\ttraining's multi_logloss: 2.85183e-05\n",
            "[2067]\ttraining's multi_logloss: 2.84987e-05\n",
            "[2068]\ttraining's multi_logloss: 2.84802e-05\n",
            "[2069]\ttraining's multi_logloss: 2.84648e-05\n",
            "[2070]\ttraining's multi_logloss: 2.84581e-05\n",
            "[2071]\ttraining's multi_logloss: 2.84407e-05\n",
            "[2072]\ttraining's multi_logloss: 2.84171e-05\n",
            "[2073]\ttraining's multi_logloss: 2.8408e-05\n",
            "[2074]\ttraining's multi_logloss: 2.83985e-05\n",
            "[2075]\ttraining's multi_logloss: 2.83853e-05\n",
            "[2076]\ttraining's multi_logloss: 2.83644e-05\n",
            "[2077]\ttraining's multi_logloss: 2.83566e-05\n",
            "[2078]\ttraining's multi_logloss: 2.83424e-05\n",
            "[2079]\ttraining's multi_logloss: 2.83263e-05\n",
            "[2080]\ttraining's multi_logloss: 2.83263e-05\n",
            "[2081]\ttraining's multi_logloss: 2.83118e-05\n",
            "[2082]\ttraining's multi_logloss: 2.83005e-05\n",
            "[2083]\ttraining's multi_logloss: 2.82935e-05\n",
            "[2084]\ttraining's multi_logloss: 2.82788e-05\n",
            "[2085]\ttraining's multi_logloss: 2.82699e-05\n",
            "[2086]\ttraining's multi_logloss: 2.82502e-05\n",
            "[2087]\ttraining's multi_logloss: 2.82403e-05\n",
            "[2088]\ttraining's multi_logloss: 2.82243e-05\n",
            "[2089]\ttraining's multi_logloss: 2.82084e-05\n",
            "[2090]\ttraining's multi_logloss: 2.81885e-05\n",
            "[2091]\ttraining's multi_logloss: 2.81544e-05\n",
            "[2092]\ttraining's multi_logloss: 2.81272e-05\n",
            "[2093]\ttraining's multi_logloss: 2.80969e-05\n",
            "[2094]\ttraining's multi_logloss: 2.80756e-05\n",
            "[2095]\ttraining's multi_logloss: 2.80486e-05\n",
            "[2096]\ttraining's multi_logloss: 2.80362e-05\n",
            "[2097]\ttraining's multi_logloss: 2.80078e-05\n",
            "[2098]\ttraining's multi_logloss: 2.7993e-05\n",
            "[2099]\ttraining's multi_logloss: 2.79505e-05\n",
            "[2100]\ttraining's multi_logloss: 2.79222e-05\n",
            "[2101]\ttraining's multi_logloss: 2.79021e-05\n",
            "[2102]\ttraining's multi_logloss: 2.7873e-05\n",
            "[2103]\ttraining's multi_logloss: 2.78551e-05\n",
            "[2104]\ttraining's multi_logloss: 2.7838e-05\n",
            "[2105]\ttraining's multi_logloss: 2.78307e-05\n",
            "[2106]\ttraining's multi_logloss: 2.78153e-05\n",
            "[2107]\ttraining's multi_logloss: 2.77956e-05\n",
            "[2108]\ttraining's multi_logloss: 2.77903e-05\n",
            "[2109]\ttraining's multi_logloss: 2.77738e-05\n",
            "[2110]\ttraining's multi_logloss: 2.776e-05\n",
            "[2111]\ttraining's multi_logloss: 2.77328e-05\n",
            "[2112]\ttraining's multi_logloss: 2.77127e-05\n",
            "[2113]\ttraining's multi_logloss: 2.76868e-05\n",
            "[2114]\ttraining's multi_logloss: 2.76704e-05\n",
            "[2115]\ttraining's multi_logloss: 2.7658e-05\n",
            "[2116]\ttraining's multi_logloss: 2.76445e-05\n",
            "[2117]\ttraining's multi_logloss: 2.76143e-05\n",
            "[2118]\ttraining's multi_logloss: 2.75877e-05\n",
            "[2119]\ttraining's multi_logloss: 2.75554e-05\n",
            "[2120]\ttraining's multi_logloss: 2.75359e-05\n",
            "[2121]\ttraining's multi_logloss: 2.75195e-05\n",
            "[2122]\ttraining's multi_logloss: 2.75125e-05\n",
            "[2123]\ttraining's multi_logloss: 2.75069e-05\n",
            "[2124]\ttraining's multi_logloss: 2.75038e-05\n",
            "[2125]\ttraining's multi_logloss: 2.75007e-05\n",
            "[2126]\ttraining's multi_logloss: 2.74825e-05\n",
            "[2127]\ttraining's multi_logloss: 2.74618e-05\n",
            "[2128]\ttraining's multi_logloss: 2.74424e-05\n",
            "[2129]\ttraining's multi_logloss: 2.7426e-05\n",
            "[2130]\ttraining's multi_logloss: 2.74224e-05\n",
            "[2131]\ttraining's multi_logloss: 2.74123e-05\n",
            "[2132]\ttraining's multi_logloss: 2.74045e-05\n",
            "[2133]\ttraining's multi_logloss: 2.7399e-05\n",
            "[2134]\ttraining's multi_logloss: 2.73975e-05\n",
            "[2135]\ttraining's multi_logloss: 2.73955e-05\n",
            "[2136]\ttraining's multi_logloss: 2.73849e-05\n",
            "[2137]\ttraining's multi_logloss: 2.73757e-05\n",
            "[2138]\ttraining's multi_logloss: 2.73684e-05\n",
            "[2139]\ttraining's multi_logloss: 2.73498e-05\n",
            "[2140]\ttraining's multi_logloss: 2.7336e-05\n",
            "[2141]\ttraining's multi_logloss: 2.73265e-05\n",
            "[2142]\ttraining's multi_logloss: 2.73194e-05\n",
            "[2143]\ttraining's multi_logloss: 2.73159e-05\n",
            "[2144]\ttraining's multi_logloss: 2.73161e-05\n",
            "[2145]\ttraining's multi_logloss: 2.73174e-05\n",
            "[2146]\ttraining's multi_logloss: 2.73059e-05\n",
            "[2147]\ttraining's multi_logloss: 2.72974e-05\n",
            "[2148]\ttraining's multi_logloss: 2.72785e-05\n",
            "[2149]\ttraining's multi_logloss: 2.72577e-05\n",
            "[2150]\ttraining's multi_logloss: 2.72526e-05\n",
            "[2151]\ttraining's multi_logloss: 2.72296e-05\n",
            "[2152]\ttraining's multi_logloss: 2.72091e-05\n",
            "[2153]\ttraining's multi_logloss: 2.71832e-05\n",
            "[2154]\ttraining's multi_logloss: 2.71589e-05\n",
            "[2155]\ttraining's multi_logloss: 2.71429e-05\n",
            "[2156]\ttraining's multi_logloss: 2.71208e-05\n",
            "[2157]\ttraining's multi_logloss: 2.71031e-05\n",
            "[2158]\ttraining's multi_logloss: 2.70838e-05\n",
            "[2159]\ttraining's multi_logloss: 2.70418e-05\n",
            "[2160]\ttraining's multi_logloss: 2.70163e-05\n",
            "[2161]\ttraining's multi_logloss: 2.69982e-05\n",
            "[2162]\ttraining's multi_logloss: 2.69886e-05\n",
            "[2163]\ttraining's multi_logloss: 2.69816e-05\n",
            "[2164]\ttraining's multi_logloss: 2.69697e-05\n",
            "[2165]\ttraining's multi_logloss: 2.69656e-05\n",
            "[2166]\ttraining's multi_logloss: 2.69551e-05\n",
            "[2167]\ttraining's multi_logloss: 2.69486e-05\n",
            "[2168]\ttraining's multi_logloss: 2.69446e-05\n",
            "[2169]\ttraining's multi_logloss: 2.69354e-05\n",
            "[2170]\ttraining's multi_logloss: 2.69362e-05\n",
            "[2171]\ttraining's multi_logloss: 2.69186e-05\n",
            "[2172]\ttraining's multi_logloss: 2.68929e-05\n",
            "[2173]\ttraining's multi_logloss: 2.68692e-05\n",
            "[2174]\ttraining's multi_logloss: 2.68552e-05\n",
            "[2175]\ttraining's multi_logloss: 2.68503e-05\n",
            "[2176]\ttraining's multi_logloss: 2.68446e-05\n",
            "[2177]\ttraining's multi_logloss: 2.68404e-05\n",
            "[2178]\ttraining's multi_logloss: 2.68369e-05\n",
            "[2179]\ttraining's multi_logloss: 2.68243e-05\n",
            "[2180]\ttraining's multi_logloss: 2.68113e-05\n",
            "[2181]\ttraining's multi_logloss: 2.67924e-05\n",
            "[2182]\ttraining's multi_logloss: 2.67663e-05\n",
            "[2183]\ttraining's multi_logloss: 2.67443e-05\n",
            "[2184]\ttraining's multi_logloss: 2.67302e-05\n",
            "[2185]\ttraining's multi_logloss: 2.6721e-05\n",
            "[2186]\ttraining's multi_logloss: 2.67024e-05\n",
            "[2187]\ttraining's multi_logloss: 2.66901e-05\n",
            "[2188]\ttraining's multi_logloss: 2.66824e-05\n",
            "[2189]\ttraining's multi_logloss: 2.66591e-05\n",
            "[2190]\ttraining's multi_logloss: 2.66539e-05\n",
            "[2191]\ttraining's multi_logloss: 2.66405e-05\n",
            "[2192]\ttraining's multi_logloss: 2.66292e-05\n",
            "[2193]\ttraining's multi_logloss: 2.66235e-05\n",
            "[2194]\ttraining's multi_logloss: 2.66081e-05\n",
            "[2195]\ttraining's multi_logloss: 2.66044e-05\n",
            "[2196]\ttraining's multi_logloss: 2.6595e-05\n",
            "[2197]\ttraining's multi_logloss: 2.65753e-05\n",
            "[2198]\ttraining's multi_logloss: 2.65674e-05\n",
            "[2199]\ttraining's multi_logloss: 2.65618e-05\n",
            "[2200]\ttraining's multi_logloss: 2.65507e-05\n",
            "[2201]\ttraining's multi_logloss: 2.65247e-05\n",
            "[2202]\ttraining's multi_logloss: 2.64895e-05\n",
            "[2203]\ttraining's multi_logloss: 2.6455e-05\n",
            "[2204]\ttraining's multi_logloss: 2.64299e-05\n",
            "[2205]\ttraining's multi_logloss: 2.63931e-05\n",
            "[2206]\ttraining's multi_logloss: 2.63787e-05\n",
            "[2207]\ttraining's multi_logloss: 2.63647e-05\n",
            "[2208]\ttraining's multi_logloss: 2.63614e-05\n",
            "[2209]\ttraining's multi_logloss: 2.6361e-05\n",
            "[2210]\ttraining's multi_logloss: 2.63625e-05\n",
            "[2211]\ttraining's multi_logloss: 2.63497e-05\n",
            "[2212]\ttraining's multi_logloss: 2.63312e-05\n",
            "[2213]\ttraining's multi_logloss: 2.6324e-05\n",
            "[2214]\ttraining's multi_logloss: 2.63209e-05\n",
            "[2215]\ttraining's multi_logloss: 2.63212e-05\n",
            "[2216]\ttraining's multi_logloss: 2.63103e-05\n",
            "[2217]\ttraining's multi_logloss: 2.62899e-05\n",
            "[2218]\ttraining's multi_logloss: 2.62695e-05\n",
            "[2219]\ttraining's multi_logloss: 2.62457e-05\n",
            "[2220]\ttraining's multi_logloss: 2.62318e-05\n",
            "[2221]\ttraining's multi_logloss: 2.62206e-05\n",
            "[2222]\ttraining's multi_logloss: 2.62031e-05\n",
            "[2223]\ttraining's multi_logloss: 2.6199e-05\n",
            "[2224]\ttraining's multi_logloss: 2.61944e-05\n",
            "[2225]\ttraining's multi_logloss: 2.61827e-05\n",
            "[2226]\ttraining's multi_logloss: 2.61677e-05\n",
            "[2227]\ttraining's multi_logloss: 2.61551e-05\n",
            "[2228]\ttraining's multi_logloss: 2.61409e-05\n",
            "[2229]\ttraining's multi_logloss: 2.61287e-05\n",
            "[2230]\ttraining's multi_logloss: 2.61245e-05\n",
            "[2231]\ttraining's multi_logloss: 2.61126e-05\n",
            "[2232]\ttraining's multi_logloss: 2.61003e-05\n",
            "[2233]\ttraining's multi_logloss: 2.6089e-05\n",
            "[2234]\ttraining's multi_logloss: 2.60698e-05\n",
            "[2235]\ttraining's multi_logloss: 2.60605e-05\n",
            "[2236]\ttraining's multi_logloss: 2.60349e-05\n",
            "[2237]\ttraining's multi_logloss: 2.60081e-05\n",
            "[2238]\ttraining's multi_logloss: 2.5995e-05\n",
            "[2239]\ttraining's multi_logloss: 2.59757e-05\n",
            "[2240]\ttraining's multi_logloss: 2.59699e-05\n",
            "[2241]\ttraining's multi_logloss: 2.59316e-05\n",
            "[2242]\ttraining's multi_logloss: 2.59109e-05\n",
            "[2243]\ttraining's multi_logloss: 2.58829e-05\n",
            "[2244]\ttraining's multi_logloss: 2.58478e-05\n",
            "[2245]\ttraining's multi_logloss: 2.58244e-05\n",
            "[2246]\ttraining's multi_logloss: 2.58108e-05\n",
            "[2247]\ttraining's multi_logloss: 2.58012e-05\n",
            "[2248]\ttraining's multi_logloss: 2.57939e-05\n",
            "[2249]\ttraining's multi_logloss: 2.57904e-05\n",
            "[2250]\ttraining's multi_logloss: 2.57893e-05\n",
            "[2251]\ttraining's multi_logloss: 2.57811e-05\n",
            "[2252]\ttraining's multi_logloss: 2.57772e-05\n",
            "[2253]\ttraining's multi_logloss: 2.57757e-05\n",
            "[2254]\ttraining's multi_logloss: 2.57673e-05\n",
            "[2255]\ttraining's multi_logloss: 2.576e-05\n",
            "[2256]\ttraining's multi_logloss: 2.5746e-05\n",
            "[2257]\ttraining's multi_logloss: 2.57248e-05\n",
            "[2258]\ttraining's multi_logloss: 2.56966e-05\n",
            "[2259]\ttraining's multi_logloss: 2.5683e-05\n",
            "[2260]\ttraining's multi_logloss: 2.56705e-05\n",
            "[2261]\ttraining's multi_logloss: 2.56491e-05\n",
            "[2262]\ttraining's multi_logloss: 2.56222e-05\n",
            "[2263]\ttraining's multi_logloss: 2.55976e-05\n",
            "[2264]\ttraining's multi_logloss: 2.55784e-05\n",
            "[2265]\ttraining's multi_logloss: 2.55597e-05\n",
            "[2266]\ttraining's multi_logloss: 2.55401e-05\n",
            "[2267]\ttraining's multi_logloss: 2.55292e-05\n",
            "[2268]\ttraining's multi_logloss: 2.55212e-05\n",
            "[2269]\ttraining's multi_logloss: 2.5508e-05\n",
            "[2270]\ttraining's multi_logloss: 2.54859e-05\n",
            "[2271]\ttraining's multi_logloss: 2.54456e-05\n",
            "[2272]\ttraining's multi_logloss: 2.54267e-05\n",
            "[2273]\ttraining's multi_logloss: 2.54183e-05\n",
            "[2274]\ttraining's multi_logloss: 2.54049e-05\n",
            "[2275]\ttraining's multi_logloss: 2.53959e-05\n",
            "[2276]\ttraining's multi_logloss: 2.53842e-05\n",
            "[2277]\ttraining's multi_logloss: 2.53615e-05\n",
            "[2278]\ttraining's multi_logloss: 2.53551e-05\n",
            "[2279]\ttraining's multi_logloss: 2.53505e-05\n",
            "[2280]\ttraining's multi_logloss: 2.53486e-05\n",
            "[2281]\ttraining's multi_logloss: 2.5336e-05\n",
            "[2282]\ttraining's multi_logloss: 2.53267e-05\n",
            "[2283]\ttraining's multi_logloss: 2.53155e-05\n",
            "[2284]\ttraining's multi_logloss: 2.53113e-05\n",
            "[2285]\ttraining's multi_logloss: 2.53095e-05\n",
            "[2286]\ttraining's multi_logloss: 2.52996e-05\n",
            "[2287]\ttraining's multi_logloss: 2.52842e-05\n",
            "[2288]\ttraining's multi_logloss: 2.52723e-05\n",
            "[2289]\ttraining's multi_logloss: 2.52697e-05\n",
            "[2290]\ttraining's multi_logloss: 2.52538e-05\n",
            "[2291]\ttraining's multi_logloss: 2.52434e-05\n",
            "[2292]\ttraining's multi_logloss: 2.524e-05\n",
            "[2293]\ttraining's multi_logloss: 2.52292e-05\n",
            "[2294]\ttraining's multi_logloss: 2.52295e-05\n",
            "[2295]\ttraining's multi_logloss: 2.52343e-05\n",
            "[2296]\ttraining's multi_logloss: 2.52142e-05\n",
            "[2297]\ttraining's multi_logloss: 2.5193e-05\n",
            "[2298]\ttraining's multi_logloss: 2.51727e-05\n",
            "[2299]\ttraining's multi_logloss: 2.51685e-05\n",
            "[2300]\ttraining's multi_logloss: 2.51571e-05\n",
            "[2301]\ttraining's multi_logloss: 2.51338e-05\n",
            "[2302]\ttraining's multi_logloss: 2.51156e-05\n",
            "[2303]\ttraining's multi_logloss: 2.5089e-05\n",
            "[2304]\ttraining's multi_logloss: 2.50805e-05\n",
            "[2305]\ttraining's multi_logloss: 2.50803e-05\n",
            "[2306]\ttraining's multi_logloss: 2.50673e-05\n",
            "[2307]\ttraining's multi_logloss: 2.50581e-05\n",
            "[2308]\ttraining's multi_logloss: 2.50399e-05\n",
            "[2309]\ttraining's multi_logloss: 2.50174e-05\n",
            "[2310]\ttraining's multi_logloss: 2.50142e-05\n",
            "[2311]\ttraining's multi_logloss: 2.49889e-05\n",
            "[2312]\ttraining's multi_logloss: 2.49689e-05\n",
            "[2313]\ttraining's multi_logloss: 2.49651e-05\n",
            "[2314]\ttraining's multi_logloss: 2.49572e-05\n",
            "[2315]\ttraining's multi_logloss: 2.4948e-05\n",
            "[2316]\ttraining's multi_logloss: 2.49391e-05\n",
            "[2317]\ttraining's multi_logloss: 2.49341e-05\n",
            "[2318]\ttraining's multi_logloss: 2.49306e-05\n",
            "[2319]\ttraining's multi_logloss: 2.4929e-05\n",
            "[2320]\ttraining's multi_logloss: 2.49279e-05\n",
            "[2321]\ttraining's multi_logloss: 2.49196e-05\n",
            "[2322]\ttraining's multi_logloss: 2.4909e-05\n",
            "[2323]\ttraining's multi_logloss: 2.49064e-05\n",
            "[2324]\ttraining's multi_logloss: 2.48997e-05\n",
            "[2325]\ttraining's multi_logloss: 2.49005e-05\n",
            "[2326]\ttraining's multi_logloss: 2.48852e-05\n",
            "[2327]\ttraining's multi_logloss: 2.48752e-05\n",
            "[2328]\ttraining's multi_logloss: 2.48526e-05\n",
            "[2329]\ttraining's multi_logloss: 2.4838e-05\n",
            "[2330]\ttraining's multi_logloss: 2.48335e-05\n",
            "[2331]\ttraining's multi_logloss: 2.48136e-05\n",
            "[2332]\ttraining's multi_logloss: 2.47963e-05\n",
            "[2333]\ttraining's multi_logloss: 2.47903e-05\n",
            "[2334]\ttraining's multi_logloss: 2.47719e-05\n",
            "[2335]\ttraining's multi_logloss: 2.47558e-05\n",
            "[2336]\ttraining's multi_logloss: 2.473e-05\n",
            "[2337]\ttraining's multi_logloss: 2.47123e-05\n",
            "[2338]\ttraining's multi_logloss: 2.4697e-05\n",
            "[2339]\ttraining's multi_logloss: 2.46771e-05\n",
            "[2340]\ttraining's multi_logloss: 2.46696e-05\n",
            "[2341]\ttraining's multi_logloss: 2.46533e-05\n",
            "[2342]\ttraining's multi_logloss: 2.46385e-05\n",
            "[2343]\ttraining's multi_logloss: 2.46317e-05\n",
            "[2344]\ttraining's multi_logloss: 2.46223e-05\n",
            "[2345]\ttraining's multi_logloss: 2.46051e-05\n",
            "[2346]\ttraining's multi_logloss: 2.45945e-05\n",
            "[2347]\ttraining's multi_logloss: 2.45881e-05\n",
            "[2348]\ttraining's multi_logloss: 2.45776e-05\n",
            "[2349]\ttraining's multi_logloss: 2.45615e-05\n",
            "[2350]\ttraining's multi_logloss: 2.45601e-05\n",
            "[2351]\ttraining's multi_logloss: 2.45421e-05\n",
            "[2352]\ttraining's multi_logloss: 2.4527e-05\n",
            "[2353]\ttraining's multi_logloss: 2.45154e-05\n",
            "[2354]\ttraining's multi_logloss: 2.45083e-05\n",
            "[2355]\ttraining's multi_logloss: 2.4498e-05\n",
            "[2356]\ttraining's multi_logloss: 2.44893e-05\n",
            "[2357]\ttraining's multi_logloss: 2.44811e-05\n",
            "[2358]\ttraining's multi_logloss: 2.44763e-05\n",
            "[2359]\ttraining's multi_logloss: 2.4463e-05\n",
            "[2360]\ttraining's multi_logloss: 2.44465e-05\n",
            "[2361]\ttraining's multi_logloss: 2.44389e-05\n",
            "[2362]\ttraining's multi_logloss: 2.44127e-05\n",
            "[2363]\ttraining's multi_logloss: 2.43906e-05\n",
            "[2364]\ttraining's multi_logloss: 2.43894e-05\n",
            "[2365]\ttraining's multi_logloss: 2.43837e-05\n",
            "[2366]\ttraining's multi_logloss: 2.43762e-05\n",
            "[2367]\ttraining's multi_logloss: 2.43724e-05\n",
            "[2368]\ttraining's multi_logloss: 2.43715e-05\n",
            "[2369]\ttraining's multi_logloss: 2.43713e-05\n",
            "[2370]\ttraining's multi_logloss: 2.43736e-05\n",
            "[2371]\ttraining's multi_logloss: 2.43624e-05\n",
            "[2372]\ttraining's multi_logloss: 2.43476e-05\n",
            "[2373]\ttraining's multi_logloss: 2.43354e-05\n",
            "[2374]\ttraining's multi_logloss: 2.4325e-05\n",
            "[2375]\ttraining's multi_logloss: 2.43151e-05\n",
            "[2376]\ttraining's multi_logloss: 2.42964e-05\n",
            "[2377]\ttraining's multi_logloss: 2.42836e-05\n",
            "[2378]\ttraining's multi_logloss: 2.42682e-05\n",
            "[2379]\ttraining's multi_logloss: 2.42565e-05\n",
            "[2380]\ttraining's multi_logloss: 2.42298e-05\n",
            "[2381]\ttraining's multi_logloss: 2.42153e-05\n",
            "[2382]\ttraining's multi_logloss: 2.42089e-05\n",
            "[2383]\ttraining's multi_logloss: 2.42062e-05\n",
            "[2384]\ttraining's multi_logloss: 2.41996e-05\n",
            "[2385]\ttraining's multi_logloss: 2.42026e-05\n",
            "[2386]\ttraining's multi_logloss: 2.41915e-05\n",
            "[2387]\ttraining's multi_logloss: 2.41807e-05\n",
            "[2388]\ttraining's multi_logloss: 2.41773e-05\n",
            "[2389]\ttraining's multi_logloss: 2.4176e-05\n",
            "[2390]\ttraining's multi_logloss: 2.41776e-05\n",
            "[2391]\ttraining's multi_logloss: 2.41642e-05\n",
            "[2392]\ttraining's multi_logloss: 2.41522e-05\n",
            "[2393]\ttraining's multi_logloss: 2.4136e-05\n",
            "[2394]\ttraining's multi_logloss: 2.41244e-05\n",
            "[2395]\ttraining's multi_logloss: 2.41196e-05\n",
            "[2396]\ttraining's multi_logloss: 2.41058e-05\n",
            "[2397]\ttraining's multi_logloss: 2.40874e-05\n",
            "[2398]\ttraining's multi_logloss: 2.40768e-05\n",
            "[2399]\ttraining's multi_logloss: 2.40682e-05\n",
            "[2400]\ttraining's multi_logloss: 2.40626e-05\n",
            "[2401]\ttraining's multi_logloss: 2.40542e-05\n",
            "[2402]\ttraining's multi_logloss: 2.40492e-05\n",
            "[2403]\ttraining's multi_logloss: 2.40477e-05\n",
            "[2404]\ttraining's multi_logloss: 2.40312e-05\n",
            "[2405]\ttraining's multi_logloss: 2.40247e-05\n",
            "[2406]\ttraining's multi_logloss: 2.40122e-05\n",
            "[2407]\ttraining's multi_logloss: 2.40022e-05\n",
            "[2408]\ttraining's multi_logloss: 2.39927e-05\n",
            "[2409]\ttraining's multi_logloss: 2.39789e-05\n",
            "[2410]\ttraining's multi_logloss: 2.39677e-05\n",
            "[2411]\ttraining's multi_logloss: 2.39504e-05\n",
            "[2412]\ttraining's multi_logloss: 2.39425e-05\n",
            "[2413]\ttraining's multi_logloss: 2.39365e-05\n",
            "[2414]\ttraining's multi_logloss: 2.39197e-05\n",
            "[2415]\ttraining's multi_logloss: 2.39186e-05\n",
            "[2416]\ttraining's multi_logloss: 2.39125e-05\n",
            "[2417]\ttraining's multi_logloss: 2.39087e-05\n",
            "[2418]\ttraining's multi_logloss: 2.38956e-05\n",
            "[2419]\ttraining's multi_logloss: 2.38957e-05\n",
            "[2420]\ttraining's multi_logloss: 2.38996e-05\n",
            "[2421]\ttraining's multi_logloss: 2.38856e-05\n",
            "[2422]\ttraining's multi_logloss: 2.38706e-05\n",
            "[2423]\ttraining's multi_logloss: 2.38675e-05\n",
            "[2424]\ttraining's multi_logloss: 2.38552e-05\n",
            "[2425]\ttraining's multi_logloss: 2.38522e-05\n",
            "[2426]\ttraining's multi_logloss: 2.38289e-05\n",
            "[2427]\ttraining's multi_logloss: 2.38087e-05\n",
            "[2428]\ttraining's multi_logloss: 2.37721e-05\n",
            "[2429]\ttraining's multi_logloss: 2.37568e-05\n",
            "[2430]\ttraining's multi_logloss: 2.37508e-05\n",
            "[2431]\ttraining's multi_logloss: 2.37399e-05\n",
            "[2432]\ttraining's multi_logloss: 2.37332e-05\n",
            "[2433]\ttraining's multi_logloss: 2.37275e-05\n",
            "[2434]\ttraining's multi_logloss: 2.37248e-05\n",
            "[2435]\ttraining's multi_logloss: 2.37176e-05\n",
            "[2436]\ttraining's multi_logloss: 2.37073e-05\n",
            "[2437]\ttraining's multi_logloss: 2.37004e-05\n",
            "[2438]\ttraining's multi_logloss: 2.37002e-05\n",
            "[2439]\ttraining's multi_logloss: 2.36969e-05\n",
            "[2440]\ttraining's multi_logloss: 2.37016e-05\n",
            "[2441]\ttraining's multi_logloss: 2.36901e-05\n",
            "[2442]\ttraining's multi_logloss: 2.36825e-05\n",
            "[2443]\ttraining's multi_logloss: 2.36721e-05\n",
            "[2444]\ttraining's multi_logloss: 2.36558e-05\n",
            "[2445]\ttraining's multi_logloss: 2.365e-05\n",
            "[2446]\ttraining's multi_logloss: 2.36349e-05\n",
            "[2447]\ttraining's multi_logloss: 2.36296e-05\n",
            "[2448]\ttraining's multi_logloss: 2.36166e-05\n",
            "[2449]\ttraining's multi_logloss: 2.36066e-05\n",
            "[2450]\ttraining's multi_logloss: 2.36074e-05\n",
            "[2451]\ttraining's multi_logloss: 2.35987e-05\n",
            "[2452]\ttraining's multi_logloss: 2.35932e-05\n",
            "[2453]\ttraining's multi_logloss: 2.35696e-05\n",
            "[2454]\ttraining's multi_logloss: 2.35583e-05\n",
            "[2455]\ttraining's multi_logloss: 2.35372e-05\n",
            "[2456]\ttraining's multi_logloss: 2.35123e-05\n",
            "[2457]\ttraining's multi_logloss: 2.34921e-05\n",
            "[2458]\ttraining's multi_logloss: 2.34735e-05\n",
            "[2459]\ttraining's multi_logloss: 2.34587e-05\n",
            "[2460]\ttraining's multi_logloss: 2.34406e-05\n",
            "[2461]\ttraining's multi_logloss: 2.34348e-05\n",
            "[2462]\ttraining's multi_logloss: 2.34286e-05\n",
            "[2463]\ttraining's multi_logloss: 2.34149e-05\n",
            "[2464]\ttraining's multi_logloss: 2.3399e-05\n",
            "[2465]\ttraining's multi_logloss: 2.33946e-05\n",
            "[2466]\ttraining's multi_logloss: 2.33902e-05\n",
            "[2467]\ttraining's multi_logloss: 2.33865e-05\n",
            "[2468]\ttraining's multi_logloss: 2.33849e-05\n",
            "[2469]\ttraining's multi_logloss: 2.3384e-05\n",
            "[2470]\ttraining's multi_logloss: 2.33858e-05\n",
            "[2471]\ttraining's multi_logloss: 2.33719e-05\n",
            "[2472]\ttraining's multi_logloss: 2.33672e-05\n",
            "[2473]\ttraining's multi_logloss: 2.33653e-05\n",
            "[2474]\ttraining's multi_logloss: 2.33574e-05\n",
            "[2475]\ttraining's multi_logloss: 2.33593e-05\n",
            "[2476]\ttraining's multi_logloss: 2.33418e-05\n",
            "[2477]\ttraining's multi_logloss: 2.33266e-05\n",
            "[2478]\ttraining's multi_logloss: 2.33141e-05\n",
            "[2479]\ttraining's multi_logloss: 2.33049e-05\n",
            "[2480]\ttraining's multi_logloss: 2.32886e-05\n",
            "[2481]\ttraining's multi_logloss: 2.32742e-05\n",
            "[2482]\ttraining's multi_logloss: 2.32707e-05\n",
            "[2483]\ttraining's multi_logloss: 2.32703e-05\n",
            "[2484]\ttraining's multi_logloss: 2.32704e-05\n",
            "[2485]\ttraining's multi_logloss: 2.32734e-05\n",
            "[2486]\ttraining's multi_logloss: 2.32631e-05\n",
            "[2487]\ttraining's multi_logloss: 2.32601e-05\n",
            "[2488]\ttraining's multi_logloss: 2.32607e-05\n",
            "[2489]\ttraining's multi_logloss: 2.32482e-05\n",
            "[2490]\ttraining's multi_logloss: 2.32373e-05\n",
            "[2491]\ttraining's multi_logloss: 2.32271e-05\n",
            "[2492]\ttraining's multi_logloss: 2.32187e-05\n",
            "[2493]\ttraining's multi_logloss: 2.3213e-05\n",
            "[2494]\ttraining's multi_logloss: 2.32054e-05\n",
            "[2495]\ttraining's multi_logloss: 2.32037e-05\n",
            "[2496]\ttraining's multi_logloss: 2.3196e-05\n",
            "[2497]\ttraining's multi_logloss: 2.31906e-05\n",
            "[2498]\ttraining's multi_logloss: 2.31886e-05\n",
            "[2499]\ttraining's multi_logloss: 2.3188e-05\n",
            "[2500]\ttraining's multi_logloss: 2.31867e-05\n",
            "[2501]\ttraining's multi_logloss: 2.31723e-05\n",
            "[2502]\ttraining's multi_logloss: 2.31492e-05\n",
            "[2503]\ttraining's multi_logloss: 2.31372e-05\n",
            "[2504]\ttraining's multi_logloss: 2.31276e-05\n",
            "[2505]\ttraining's multi_logloss: 2.312e-05\n",
            "[2506]\ttraining's multi_logloss: 2.30995e-05\n",
            "[2507]\ttraining's multi_logloss: 2.3076e-05\n",
            "[2508]\ttraining's multi_logloss: 2.306e-05\n",
            "[2509]\ttraining's multi_logloss: 2.30563e-05\n",
            "[2510]\ttraining's multi_logloss: 2.30435e-05\n",
            "[2511]\ttraining's multi_logloss: 2.30334e-05\n",
            "[2512]\ttraining's multi_logloss: 2.30228e-05\n",
            "[2513]\ttraining's multi_logloss: 2.30016e-05\n",
            "[2514]\ttraining's multi_logloss: 2.29971e-05\n",
            "[2515]\ttraining's multi_logloss: 2.29844e-05\n",
            "[2516]\ttraining's multi_logloss: 2.29794e-05\n",
            "[2517]\ttraining's multi_logloss: 2.29757e-05\n",
            "[2518]\ttraining's multi_logloss: 2.29735e-05\n",
            "[2519]\ttraining's multi_logloss: 2.29602e-05\n",
            "[2520]\ttraining's multi_logloss: 2.29623e-05\n",
            "[2521]\ttraining's multi_logloss: 2.29534e-05\n",
            "[2522]\ttraining's multi_logloss: 2.29426e-05\n",
            "[2523]\ttraining's multi_logloss: 2.29374e-05\n",
            "[2524]\ttraining's multi_logloss: 2.29234e-05\n",
            "[2525]\ttraining's multi_logloss: 2.29087e-05\n",
            "[2526]\ttraining's multi_logloss: 2.28868e-05\n",
            "[2527]\ttraining's multi_logloss: 2.28711e-05\n",
            "[2528]\ttraining's multi_logloss: 2.2856e-05\n",
            "[2529]\ttraining's multi_logloss: 2.28483e-05\n",
            "[2530]\ttraining's multi_logloss: 2.28273e-05\n",
            "[2531]\ttraining's multi_logloss: 2.28214e-05\n",
            "[2532]\ttraining's multi_logloss: 2.28155e-05\n",
            "[2533]\ttraining's multi_logloss: 2.28115e-05\n",
            "[2534]\ttraining's multi_logloss: 2.28026e-05\n",
            "[2535]\ttraining's multi_logloss: 2.27909e-05\n",
            "[2536]\ttraining's multi_logloss: 2.27754e-05\n",
            "[2537]\ttraining's multi_logloss: 2.27603e-05\n",
            "[2538]\ttraining's multi_logloss: 2.27436e-05\n",
            "[2539]\ttraining's multi_logloss: 2.27165e-05\n",
            "[2540]\ttraining's multi_logloss: 2.27002e-05\n",
            "[2541]\ttraining's multi_logloss: 2.2683e-05\n",
            "[2542]\ttraining's multi_logloss: 2.26692e-05\n",
            "[2543]\ttraining's multi_logloss: 2.26587e-05\n",
            "[2544]\ttraining's multi_logloss: 2.26515e-05\n",
            "[2545]\ttraining's multi_logloss: 2.26277e-05\n",
            "[2546]\ttraining's multi_logloss: 2.26144e-05\n",
            "[2547]\ttraining's multi_logloss: 2.26093e-05\n",
            "[2548]\ttraining's multi_logloss: 2.25945e-05\n",
            "[2549]\ttraining's multi_logloss: 2.25854e-05\n",
            "[2550]\ttraining's multi_logloss: 2.25777e-05\n",
            "[2551]\ttraining's multi_logloss: 2.25718e-05\n",
            "[2552]\ttraining's multi_logloss: 2.25643e-05\n",
            "[2553]\ttraining's multi_logloss: 2.25651e-05\n",
            "[2554]\ttraining's multi_logloss: 2.25683e-05\n",
            "[2555]\ttraining's multi_logloss: 2.25732e-05\n",
            "[2556]\ttraining's multi_logloss: 2.25646e-05\n",
            "[2557]\ttraining's multi_logloss: 2.25584e-05\n",
            "[2558]\ttraining's multi_logloss: 2.25541e-05\n",
            "[2559]\ttraining's multi_logloss: 2.25532e-05\n",
            "[2560]\ttraining's multi_logloss: 2.25433e-05\n",
            "[2561]\ttraining's multi_logloss: 2.2533e-05\n",
            "[2562]\ttraining's multi_logloss: 2.25255e-05\n",
            "[2563]\ttraining's multi_logloss: 2.25223e-05\n",
            "[2564]\ttraining's multi_logloss: 2.25188e-05\n",
            "[2565]\ttraining's multi_logloss: 2.25078e-05\n",
            "[2566]\ttraining's multi_logloss: 2.24932e-05\n",
            "[2567]\ttraining's multi_logloss: 2.24842e-05\n",
            "[2568]\ttraining's multi_logloss: 2.24768e-05\n",
            "[2569]\ttraining's multi_logloss: 2.24723e-05\n",
            "[2570]\ttraining's multi_logloss: 2.24697e-05\n",
            "[2571]\ttraining's multi_logloss: 2.24539e-05\n",
            "[2572]\ttraining's multi_logloss: 2.24478e-05\n",
            "[2573]\ttraining's multi_logloss: 2.24357e-05\n",
            "[2574]\ttraining's multi_logloss: 2.2427e-05\n",
            "[2575]\ttraining's multi_logloss: 2.24111e-05\n",
            "[2576]\ttraining's multi_logloss: 2.2405e-05\n",
            "[2577]\ttraining's multi_logloss: 2.23963e-05\n",
            "[2578]\ttraining's multi_logloss: 2.23918e-05\n",
            "[2579]\ttraining's multi_logloss: 2.23915e-05\n",
            "[2580]\ttraining's multi_logloss: 2.23952e-05\n",
            "[2581]\ttraining's multi_logloss: 2.23887e-05\n",
            "[2582]\ttraining's multi_logloss: 2.23847e-05\n",
            "[2583]\ttraining's multi_logloss: 2.23838e-05\n",
            "[2584]\ttraining's multi_logloss: 2.23839e-05\n",
            "[2585]\ttraining's multi_logloss: 2.23862e-05\n",
            "[2586]\ttraining's multi_logloss: 2.23703e-05\n",
            "[2587]\ttraining's multi_logloss: 2.23575e-05\n",
            "[2588]\ttraining's multi_logloss: 2.23462e-05\n",
            "[2589]\ttraining's multi_logloss: 2.23379e-05\n",
            "[2590]\ttraining's multi_logloss: 2.233e-05\n",
            "[2591]\ttraining's multi_logloss: 2.23171e-05\n",
            "[2592]\ttraining's multi_logloss: 2.23098e-05\n",
            "[2593]\ttraining's multi_logloss: 2.22974e-05\n",
            "[2594]\ttraining's multi_logloss: 2.2288e-05\n",
            "[2595]\ttraining's multi_logloss: 2.22801e-05\n",
            "[2596]\ttraining's multi_logloss: 2.22752e-05\n",
            "[2597]\ttraining's multi_logloss: 2.22744e-05\n",
            "[2598]\ttraining's multi_logloss: 2.22738e-05\n",
            "[2599]\ttraining's multi_logloss: 2.22669e-05\n",
            "[2600]\ttraining's multi_logloss: 2.22702e-05\n",
            "[2601]\ttraining's multi_logloss: 2.22584e-05\n",
            "[2602]\ttraining's multi_logloss: 2.22496e-05\n",
            "[2603]\ttraining's multi_logloss: 2.22437e-05\n",
            "[2604]\ttraining's multi_logloss: 2.224e-05\n",
            "[2605]\ttraining's multi_logloss: 2.22382e-05\n",
            "[2606]\ttraining's multi_logloss: 2.22234e-05\n",
            "[2607]\ttraining's multi_logloss: 2.2218e-05\n",
            "[2608]\ttraining's multi_logloss: 2.22136e-05\n",
            "[2609]\ttraining's multi_logloss: 2.22017e-05\n",
            "[2610]\ttraining's multi_logloss: 2.22021e-05\n",
            "[2611]\ttraining's multi_logloss: 2.21971e-05\n",
            "[2612]\ttraining's multi_logloss: 2.21938e-05\n",
            "[2613]\ttraining's multi_logloss: 2.21925e-05\n",
            "[2614]\ttraining's multi_logloss: 2.21855e-05\n",
            "[2615]\ttraining's multi_logloss: 2.21658e-05\n",
            "[2616]\ttraining's multi_logloss: 2.21493e-05\n",
            "[2617]\ttraining's multi_logloss: 2.2145e-05\n",
            "[2618]\ttraining's multi_logloss: 2.2144e-05\n",
            "[2619]\ttraining's multi_logloss: 2.21444e-05\n",
            "[2620]\ttraining's multi_logloss: 2.21431e-05\n",
            "[2621]\ttraining's multi_logloss: 2.21322e-05\n",
            "[2622]\ttraining's multi_logloss: 2.21166e-05\n",
            "[2623]\ttraining's multi_logloss: 2.21113e-05\n",
            "[2624]\ttraining's multi_logloss: 2.21082e-05\n",
            "[2625]\ttraining's multi_logloss: 2.21008e-05\n",
            "[2626]\ttraining's multi_logloss: 2.20894e-05\n",
            "[2627]\ttraining's multi_logloss: 2.20879e-05\n",
            "[2628]\ttraining's multi_logloss: 2.20892e-05\n",
            "[2629]\ttraining's multi_logloss: 2.20932e-05\n",
            "[2630]\ttraining's multi_logloss: 2.20864e-05\n",
            "[2631]\ttraining's multi_logloss: 2.20748e-05\n",
            "[2632]\ttraining's multi_logloss: 2.20662e-05\n",
            "[2633]\ttraining's multi_logloss: 2.20595e-05\n",
            "[2634]\ttraining's multi_logloss: 2.20557e-05\n",
            "[2635]\ttraining's multi_logloss: 2.20448e-05\n",
            "[2636]\ttraining's multi_logloss: 2.20384e-05\n",
            "[2637]\ttraining's multi_logloss: 2.20322e-05\n",
            "[2638]\ttraining's multi_logloss: 2.20277e-05\n",
            "[2639]\ttraining's multi_logloss: 2.20259e-05\n",
            "[2640]\ttraining's multi_logloss: 2.20197e-05\n",
            "[2641]\ttraining's multi_logloss: 2.20173e-05\n",
            "[2642]\ttraining's multi_logloss: 2.20099e-05\n",
            "[2643]\ttraining's multi_logloss: 2.20038e-05\n",
            "[2644]\ttraining's multi_logloss: 2.19985e-05\n",
            "[2645]\ttraining's multi_logloss: 2.19964e-05\n",
            "[2646]\ttraining's multi_logloss: 2.19846e-05\n",
            "[2647]\ttraining's multi_logloss: 2.19765e-05\n",
            "[2648]\ttraining's multi_logloss: 2.19717e-05\n",
            "[2649]\ttraining's multi_logloss: 2.19692e-05\n",
            "[2650]\ttraining's multi_logloss: 2.19681e-05\n",
            "[2651]\ttraining's multi_logloss: 2.19526e-05\n",
            "[2652]\ttraining's multi_logloss: 2.19418e-05\n",
            "[2653]\ttraining's multi_logloss: 2.19326e-05\n",
            "[2654]\ttraining's multi_logloss: 2.19203e-05\n",
            "[2655]\ttraining's multi_logloss: 2.19127e-05\n",
            "[2656]\ttraining's multi_logloss: 2.19054e-05\n",
            "[2657]\ttraining's multi_logloss: 2.19005e-05\n",
            "[2658]\ttraining's multi_logloss: 2.1889e-05\n",
            "[2659]\ttraining's multi_logloss: 2.18815e-05\n",
            "[2660]\ttraining's multi_logloss: 2.18709e-05\n",
            "[2661]\ttraining's multi_logloss: 2.18585e-05\n",
            "[2662]\ttraining's multi_logloss: 2.18538e-05\n",
            "[2663]\ttraining's multi_logloss: 2.18404e-05\n",
            "[2664]\ttraining's multi_logloss: 2.18236e-05\n",
            "[2665]\ttraining's multi_logloss: 2.18221e-05\n",
            "[2666]\ttraining's multi_logloss: 2.1802e-05\n",
            "[2667]\ttraining's multi_logloss: 2.17955e-05\n",
            "[2668]\ttraining's multi_logloss: 2.17913e-05\n",
            "[2669]\ttraining's multi_logloss: 2.17889e-05\n",
            "[2670]\ttraining's multi_logloss: 2.17892e-05\n",
            "[2671]\ttraining's multi_logloss: 2.17849e-05\n",
            "[2672]\ttraining's multi_logloss: 2.17824e-05\n",
            "[2673]\ttraining's multi_logloss: 2.17822e-05\n",
            "[2674]\ttraining's multi_logloss: 2.17748e-05\n",
            "[2675]\ttraining's multi_logloss: 2.17786e-05\n",
            "[2676]\ttraining's multi_logloss: 2.1766e-05\n",
            "[2677]\ttraining's multi_logloss: 2.17587e-05\n",
            "[2678]\ttraining's multi_logloss: 2.17563e-05\n",
            "[2679]\ttraining's multi_logloss: 2.17565e-05\n",
            "[2680]\ttraining's multi_logloss: 2.17529e-05\n",
            "[2681]\ttraining's multi_logloss: 2.17362e-05\n",
            "[2682]\ttraining's multi_logloss: 2.17218e-05\n",
            "[2683]\ttraining's multi_logloss: 2.17185e-05\n",
            "[2684]\ttraining's multi_logloss: 2.17059e-05\n",
            "[2685]\ttraining's multi_logloss: 2.17039e-05\n",
            "[2686]\ttraining's multi_logloss: 2.16888e-05\n",
            "[2687]\ttraining's multi_logloss: 2.16734e-05\n",
            "[2688]\ttraining's multi_logloss: 2.16539e-05\n",
            "[2689]\ttraining's multi_logloss: 2.16341e-05\n",
            "[2690]\ttraining's multi_logloss: 2.16183e-05\n",
            "[2691]\ttraining's multi_logloss: 2.16118e-05\n",
            "[2692]\ttraining's multi_logloss: 2.16011e-05\n",
            "[2693]\ttraining's multi_logloss: 2.15998e-05\n",
            "[2694]\ttraining's multi_logloss: 2.15917e-05\n",
            "[2695]\ttraining's multi_logloss: 2.15846e-05\n",
            "[2696]\ttraining's multi_logloss: 2.15744e-05\n",
            "[2697]\ttraining's multi_logloss: 2.15673e-05\n",
            "[2698]\ttraining's multi_logloss: 2.15527e-05\n",
            "[2699]\ttraining's multi_logloss: 2.15516e-05\n",
            "[2700]\ttraining's multi_logloss: 2.15477e-05\n",
            "[2701]\ttraining's multi_logloss: 2.15412e-05\n",
            "[2702]\ttraining's multi_logloss: 2.15366e-05\n",
            "[2703]\ttraining's multi_logloss: 2.15275e-05\n",
            "[2704]\ttraining's multi_logloss: 2.15176e-05\n",
            "[2705]\ttraining's multi_logloss: 2.15149e-05\n",
            "[2706]\ttraining's multi_logloss: 2.1501e-05\n",
            "[2707]\ttraining's multi_logloss: 2.14895e-05\n",
            "[2708]\ttraining's multi_logloss: 2.1479e-05\n",
            "[2709]\ttraining's multi_logloss: 2.14698e-05\n",
            "[2710]\ttraining's multi_logloss: 2.14634e-05\n",
            "[2711]\ttraining's multi_logloss: 2.14569e-05\n",
            "[2712]\ttraining's multi_logloss: 2.14548e-05\n",
            "[2713]\ttraining's multi_logloss: 2.14535e-05\n",
            "[2714]\ttraining's multi_logloss: 2.14551e-05\n",
            "[2715]\ttraining's multi_logloss: 2.14485e-05\n",
            "[2716]\ttraining's multi_logloss: 2.14354e-05\n",
            "[2717]\ttraining's multi_logloss: 2.14249e-05\n",
            "[2718]\ttraining's multi_logloss: 2.14227e-05\n",
            "[2719]\ttraining's multi_logloss: 2.14145e-05\n",
            "[2720]\ttraining's multi_logloss: 2.14074e-05\n",
            "[2721]\ttraining's multi_logloss: 2.14011e-05\n",
            "[2722]\ttraining's multi_logloss: 2.13971e-05\n",
            "[2723]\ttraining's multi_logloss: 2.13965e-05\n",
            "[2724]\ttraining's multi_logloss: 2.13979e-05\n",
            "[2725]\ttraining's multi_logloss: 2.14015e-05\n",
            "[2726]\ttraining's multi_logloss: 2.13948e-05\n",
            "[2727]\ttraining's multi_logloss: 2.13891e-05\n",
            "[2728]\ttraining's multi_logloss: 2.1388e-05\n",
            "[2729]\ttraining's multi_logloss: 2.13885e-05\n",
            "[2730]\ttraining's multi_logloss: 2.13912e-05\n",
            "[2731]\ttraining's multi_logloss: 2.13843e-05\n",
            "[2732]\ttraining's multi_logloss: 2.13772e-05\n",
            "[2733]\ttraining's multi_logloss: 2.13753e-05\n",
            "[2734]\ttraining's multi_logloss: 2.13753e-05\n",
            "[2735]\ttraining's multi_logloss: 2.13766e-05\n",
            "[2736]\ttraining's multi_logloss: 2.13699e-05\n",
            "[2737]\ttraining's multi_logloss: 2.13653e-05\n",
            "[2738]\ttraining's multi_logloss: 2.13464e-05\n",
            "[2739]\ttraining's multi_logloss: 2.13265e-05\n",
            "[2740]\ttraining's multi_logloss: 2.13245e-05\n",
            "[2741]\ttraining's multi_logloss: 2.13165e-05\n",
            "[2742]\ttraining's multi_logloss: 2.13077e-05\n",
            "[2743]\ttraining's multi_logloss: 2.12999e-05\n",
            "[2744]\ttraining's multi_logloss: 2.12786e-05\n",
            "[2745]\ttraining's multi_logloss: 2.127e-05\n",
            "[2746]\ttraining's multi_logloss: 2.12651e-05\n",
            "[2747]\ttraining's multi_logloss: 2.12634e-05\n",
            "[2748]\ttraining's multi_logloss: 2.12567e-05\n",
            "[2749]\ttraining's multi_logloss: 2.12579e-05\n",
            "[2750]\ttraining's multi_logloss: 2.12407e-05\n",
            "[2751]\ttraining's multi_logloss: 2.12342e-05\n",
            "[2752]\ttraining's multi_logloss: 2.12175e-05\n",
            "[2753]\ttraining's multi_logloss: 2.1203e-05\n",
            "[2754]\ttraining's multi_logloss: 2.12033e-05\n",
            "[2755]\ttraining's multi_logloss: 2.1205e-05\n",
            "[2756]\ttraining's multi_logloss: 2.11998e-05\n",
            "[2757]\ttraining's multi_logloss: 2.11945e-05\n",
            "[2758]\ttraining's multi_logloss: 2.11937e-05\n",
            "[2759]\ttraining's multi_logloss: 2.11943e-05\n",
            "[2760]\ttraining's multi_logloss: 2.11974e-05\n",
            "[2761]\ttraining's multi_logloss: 2.11883e-05\n",
            "[2762]\ttraining's multi_logloss: 2.11838e-05\n",
            "[2763]\ttraining's multi_logloss: 2.11815e-05\n",
            "[2764]\ttraining's multi_logloss: 2.11811e-05\n",
            "[2765]\ttraining's multi_logloss: 2.11822e-05\n",
            "[2766]\ttraining's multi_logloss: 2.11733e-05\n",
            "[2767]\ttraining's multi_logloss: 2.1162e-05\n",
            "[2768]\ttraining's multi_logloss: 2.11587e-05\n",
            "[2769]\ttraining's multi_logloss: 2.11522e-05\n",
            "[2770]\ttraining's multi_logloss: 2.1153e-05\n",
            "[2771]\ttraining's multi_logloss: 2.11441e-05\n",
            "[2772]\ttraining's multi_logloss: 2.11393e-05\n",
            "[2773]\ttraining's multi_logloss: 2.11356e-05\n",
            "[2774]\ttraining's multi_logloss: 2.11338e-05\n",
            "[2775]\ttraining's multi_logloss: 2.11344e-05\n",
            "[2776]\ttraining's multi_logloss: 2.11264e-05\n",
            "[2777]\ttraining's multi_logloss: 2.1115e-05\n",
            "[2778]\ttraining's multi_logloss: 2.11127e-05\n",
            "[2779]\ttraining's multi_logloss: 2.11124e-05\n",
            "[2780]\ttraining's multi_logloss: 2.11135e-05\n",
            "[2781]\ttraining's multi_logloss: 2.11067e-05\n",
            "[2782]\ttraining's multi_logloss: 2.1103e-05\n",
            "[2783]\ttraining's multi_logloss: 2.11013e-05\n",
            "[2784]\ttraining's multi_logloss: 2.11017e-05\n",
            "[2785]\ttraining's multi_logloss: 2.11017e-05\n",
            "[2786]\ttraining's multi_logloss: 2.10941e-05\n",
            "[2787]\ttraining's multi_logloss: 2.10894e-05\n",
            "[2788]\ttraining's multi_logloss: 2.10885e-05\n",
            "[2789]\ttraining's multi_logloss: 2.10897e-05\n",
            "[2790]\ttraining's multi_logloss: 2.10935e-05\n",
            "[2791]\ttraining's multi_logloss: 2.10649e-05\n",
            "[2792]\ttraining's multi_logloss: 2.10506e-05\n",
            "[2793]\ttraining's multi_logloss: 2.10486e-05\n",
            "[2794]\ttraining's multi_logloss: 2.1032e-05\n",
            "[2795]\ttraining's multi_logloss: 2.10186e-05\n",
            "[2796]\ttraining's multi_logloss: 2.10125e-05\n",
            "[2797]\ttraining's multi_logloss: 2.10097e-05\n",
            "[2798]\ttraining's multi_logloss: 2.10095e-05\n",
            "[2799]\ttraining's multi_logloss: 2.10123e-05\n",
            "[2800]\ttraining's multi_logloss: 2.10083e-05\n",
            "[2801]\ttraining's multi_logloss: 2.10022e-05\n",
            "[2802]\ttraining's multi_logloss: 2.0995e-05\n",
            "[2803]\ttraining's multi_logloss: 2.09891e-05\n",
            "[2804]\ttraining's multi_logloss: 2.09858e-05\n",
            "[2805]\ttraining's multi_logloss: 2.09812e-05\n",
            "[2806]\ttraining's multi_logloss: 2.09663e-05\n",
            "[2807]\ttraining's multi_logloss: 2.09618e-05\n",
            "[2808]\ttraining's multi_logloss: 2.09566e-05\n",
            "[2809]\ttraining's multi_logloss: 2.09535e-05\n",
            "[2810]\ttraining's multi_logloss: 2.09458e-05\n",
            "[2811]\ttraining's multi_logloss: 2.09406e-05\n",
            "[2812]\ttraining's multi_logloss: 2.09374e-05\n",
            "[2813]\ttraining's multi_logloss: 2.09367e-05\n",
            "[2814]\ttraining's multi_logloss: 2.09367e-05\n",
            "[2815]\ttraining's multi_logloss: 2.09389e-05\n",
            "[2816]\ttraining's multi_logloss: 2.09266e-05\n",
            "[2817]\ttraining's multi_logloss: 2.09229e-05\n",
            "[2818]\ttraining's multi_logloss: 2.09173e-05\n",
            "[2819]\ttraining's multi_logloss: 2.09163e-05\n",
            "[2820]\ttraining's multi_logloss: 2.09026e-05\n",
            "[2821]\ttraining's multi_logloss: 2.08964e-05\n",
            "[2822]\ttraining's multi_logloss: 2.08907e-05\n",
            "[2823]\ttraining's multi_logloss: 2.08817e-05\n",
            "[2824]\ttraining's multi_logloss: 2.08738e-05\n",
            "[2825]\ttraining's multi_logloss: 2.08742e-05\n",
            "[2826]\ttraining's multi_logloss: 2.08694e-05\n",
            "[2827]\ttraining's multi_logloss: 2.08527e-05\n",
            "[2828]\ttraining's multi_logloss: 2.08505e-05\n",
            "[2829]\ttraining's multi_logloss: 2.08493e-05\n",
            "[2830]\ttraining's multi_logloss: 2.08497e-05\n",
            "[2831]\ttraining's multi_logloss: 2.08414e-05\n",
            "[2832]\ttraining's multi_logloss: 2.08373e-05\n",
            "[2833]\ttraining's multi_logloss: 2.08354e-05\n",
            "[2834]\ttraining's multi_logloss: 2.08312e-05\n",
            "[2835]\ttraining's multi_logloss: 2.08277e-05\n",
            "[2836]\ttraining's multi_logloss: 2.082e-05\n",
            "[2837]\ttraining's multi_logloss: 2.08147e-05\n",
            "[2838]\ttraining's multi_logloss: 2.08115e-05\n",
            "[2839]\ttraining's multi_logloss: 2.0809e-05\n",
            "[2840]\ttraining's multi_logloss: 2.08096e-05\n",
            "[2841]\ttraining's multi_logloss: 2.08053e-05\n",
            "[2842]\ttraining's multi_logloss: 2.07965e-05\n",
            "[2843]\ttraining's multi_logloss: 2.07931e-05\n",
            "[2844]\ttraining's multi_logloss: 2.07878e-05\n",
            "[2845]\ttraining's multi_logloss: 2.07806e-05\n",
            "[2846]\ttraining's multi_logloss: 2.07711e-05\n",
            "[2847]\ttraining's multi_logloss: 2.07654e-05\n",
            "[2848]\ttraining's multi_logloss: 2.07603e-05\n",
            "[2849]\ttraining's multi_logloss: 2.07577e-05\n",
            "[2850]\ttraining's multi_logloss: 2.07585e-05\n",
            "[2851]\ttraining's multi_logloss: 2.07446e-05\n",
            "[2852]\ttraining's multi_logloss: 2.07416e-05\n",
            "[2853]\ttraining's multi_logloss: 2.07408e-05\n",
            "[2854]\ttraining's multi_logloss: 2.07382e-05\n",
            "[2855]\ttraining's multi_logloss: 2.07358e-05\n",
            "[2856]\ttraining's multi_logloss: 2.07298e-05\n",
            "[2857]\ttraining's multi_logloss: 2.0727e-05\n",
            "[2858]\ttraining's multi_logloss: 2.07167e-05\n",
            "[2859]\ttraining's multi_logloss: 2.07083e-05\n",
            "[2860]\ttraining's multi_logloss: 2.07029e-05\n",
            "[2861]\ttraining's multi_logloss: 2.0696e-05\n",
            "[2862]\ttraining's multi_logloss: 2.06924e-05\n",
            "[2863]\ttraining's multi_logloss: 2.069e-05\n",
            "[2864]\ttraining's multi_logloss: 2.06863e-05\n",
            "[2865]\ttraining's multi_logloss: 2.06896e-05\n",
            "[2866]\ttraining's multi_logloss: 2.06769e-05\n",
            "[2867]\ttraining's multi_logloss: 2.06692e-05\n",
            "[2868]\ttraining's multi_logloss: 2.06607e-05\n",
            "[2869]\ttraining's multi_logloss: 2.06583e-05\n",
            "[2870]\ttraining's multi_logloss: 2.0645e-05\n",
            "[2871]\ttraining's multi_logloss: 2.06264e-05\n",
            "[2872]\ttraining's multi_logloss: 2.06229e-05\n",
            "[2873]\ttraining's multi_logloss: 2.06226e-05\n",
            "[2874]\ttraining's multi_logloss: 2.06154e-05\n",
            "[2875]\ttraining's multi_logloss: 2.06079e-05\n",
            "[2876]\ttraining's multi_logloss: 2.05922e-05\n",
            "[2877]\ttraining's multi_logloss: 2.0588e-05\n",
            "[2878]\ttraining's multi_logloss: 2.05861e-05\n",
            "[2879]\ttraining's multi_logloss: 2.05847e-05\n",
            "[2880]\ttraining's multi_logloss: 2.05748e-05\n",
            "[2881]\ttraining's multi_logloss: 2.05667e-05\n",
            "[2882]\ttraining's multi_logloss: 2.05605e-05\n",
            "[2883]\ttraining's multi_logloss: 2.0558e-05\n",
            "[2884]\ttraining's multi_logloss: 2.05566e-05\n",
            "[2885]\ttraining's multi_logloss: 2.05582e-05\n",
            "[2886]\ttraining's multi_logloss: 2.05512e-05\n",
            "[2887]\ttraining's multi_logloss: 2.05413e-05\n",
            "[2888]\ttraining's multi_logloss: 2.05297e-05\n",
            "[2889]\ttraining's multi_logloss: 2.05225e-05\n",
            "[2890]\ttraining's multi_logloss: 2.05233e-05\n",
            "[2891]\ttraining's multi_logloss: 2.05055e-05\n",
            "[2892]\ttraining's multi_logloss: 2.04997e-05\n",
            "[2893]\ttraining's multi_logloss: 2.04916e-05\n",
            "[2894]\ttraining's multi_logloss: 2.04885e-05\n",
            "[2895]\ttraining's multi_logloss: 2.04832e-05\n",
            "[2896]\ttraining's multi_logloss: 2.04774e-05\n",
            "[2897]\ttraining's multi_logloss: 2.04607e-05\n",
            "[2898]\ttraining's multi_logloss: 2.04357e-05\n",
            "[2899]\ttraining's multi_logloss: 2.04346e-05\n",
            "[2900]\ttraining's multi_logloss: 2.04353e-05\n",
            "[2901]\ttraining's multi_logloss: 2.04308e-05\n",
            "[2902]\ttraining's multi_logloss: 2.04234e-05\n",
            "[2903]\ttraining's multi_logloss: 2.04232e-05\n",
            "[2904]\ttraining's multi_logloss: 2.04244e-05\n",
            "[2905]\ttraining's multi_logloss: 2.04177e-05\n",
            "[2906]\ttraining's multi_logloss: 2.04119e-05\n",
            "[2907]\ttraining's multi_logloss: 2.04092e-05\n",
            "[2908]\ttraining's multi_logloss: 2.04076e-05\n",
            "[2909]\ttraining's multi_logloss: 2.04083e-05\n",
            "[2910]\ttraining's multi_logloss: 2.04097e-05\n",
            "[2911]\ttraining's multi_logloss: 2.04045e-05\n",
            "[2912]\ttraining's multi_logloss: 2.04022e-05\n",
            "[2913]\ttraining's multi_logloss: 2.04032e-05\n",
            "[2914]\ttraining's multi_logloss: 2.04066e-05\n",
            "[2915]\ttraining's multi_logloss: 2.04134e-05\n",
            "[2916]\ttraining's multi_logloss: 2.04034e-05\n",
            "[2917]\ttraining's multi_logloss: 2.03995e-05\n",
            "[2918]\ttraining's multi_logloss: 2.03996e-05\n",
            "[2919]\ttraining's multi_logloss: 2.04017e-05\n",
            "[2920]\ttraining's multi_logloss: 2.03984e-05\n",
            "[2921]\ttraining's multi_logloss: 2.0391e-05\n",
            "[2922]\ttraining's multi_logloss: 2.03862e-05\n",
            "[2923]\ttraining's multi_logloss: 2.03824e-05\n",
            "[2924]\ttraining's multi_logloss: 2.03812e-05\n",
            "[2925]\ttraining's multi_logloss: 2.03815e-05\n",
            "[2926]\ttraining's multi_logloss: 2.03728e-05\n",
            "[2927]\ttraining's multi_logloss: 2.03606e-05\n",
            "[2928]\ttraining's multi_logloss: 2.0353e-05\n",
            "[2929]\ttraining's multi_logloss: 2.03428e-05\n",
            "[2930]\ttraining's multi_logloss: 2.03334e-05\n",
            "[2931]\ttraining's multi_logloss: 2.03276e-05\n",
            "[2932]\ttraining's multi_logloss: 2.03222e-05\n",
            "[2933]\ttraining's multi_logloss: 2.03164e-05\n",
            "[2934]\ttraining's multi_logloss: 2.031e-05\n",
            "[2935]\ttraining's multi_logloss: 2.0312e-05\n",
            "[2936]\ttraining's multi_logloss: 2.0305e-05\n",
            "[2937]\ttraining's multi_logloss: 2.03009e-05\n",
            "[2938]\ttraining's multi_logloss: 2.02905e-05\n",
            "[2939]\ttraining's multi_logloss: 2.02891e-05\n",
            "[2940]\ttraining's multi_logloss: 2.02896e-05\n",
            "[2941]\ttraining's multi_logloss: 2.02769e-05\n",
            "[2942]\ttraining's multi_logloss: 2.02737e-05\n",
            "[2943]\ttraining's multi_logloss: 2.0273e-05\n",
            "[2944]\ttraining's multi_logloss: 2.02738e-05\n",
            "[2945]\ttraining's multi_logloss: 2.02771e-05\n",
            "[2946]\ttraining's multi_logloss: 2.02701e-05\n",
            "[2947]\ttraining's multi_logloss: 2.02633e-05\n",
            "[2948]\ttraining's multi_logloss: 2.02615e-05\n",
            "[2949]\ttraining's multi_logloss: 2.02589e-05\n",
            "[2950]\ttraining's multi_logloss: 2.02607e-05\n",
            "[2951]\ttraining's multi_logloss: 2.02546e-05\n",
            "[2952]\ttraining's multi_logloss: 2.02503e-05\n",
            "[2953]\ttraining's multi_logloss: 2.0246e-05\n",
            "[2954]\ttraining's multi_logloss: 2.0244e-05\n",
            "[2955]\ttraining's multi_logloss: 2.02435e-05\n",
            "[2956]\ttraining's multi_logloss: 2.02402e-05\n",
            "[2957]\ttraining's multi_logloss: 2.0239e-05\n",
            "[2958]\ttraining's multi_logloss: 2.02405e-05\n",
            "[2959]\ttraining's multi_logloss: 2.02433e-05\n",
            "[2960]\ttraining's multi_logloss: 2.02488e-05\n",
            "[2961]\ttraining's multi_logloss: 2.02365e-05\n",
            "[2962]\ttraining's multi_logloss: 2.02262e-05\n",
            "[2963]\ttraining's multi_logloss: 2.02067e-05\n",
            "[2964]\ttraining's multi_logloss: 2.02027e-05\n",
            "[2965]\ttraining's multi_logloss: 2.0203e-05\n",
            "[2966]\ttraining's multi_logloss: 2.01941e-05\n",
            "[2967]\ttraining's multi_logloss: 2.01905e-05\n",
            "[2968]\ttraining's multi_logloss: 2.01893e-05\n",
            "[2969]\ttraining's multi_logloss: 2.01866e-05\n",
            "[2970]\ttraining's multi_logloss: 2.01903e-05\n",
            "[2971]\ttraining's multi_logloss: 2.01835e-05\n",
            "[2972]\ttraining's multi_logloss: 2.0179e-05\n",
            "[2973]\ttraining's multi_logloss: 2.01774e-05\n",
            "[2974]\ttraining's multi_logloss: 2.01777e-05\n",
            "[2975]\ttraining's multi_logloss: 2.01799e-05\n",
            "[2976]\ttraining's multi_logloss: 2.01734e-05\n",
            "[2977]\ttraining's multi_logloss: 2.01687e-05\n",
            "[2978]\ttraining's multi_logloss: 2.01664e-05\n",
            "[2979]\ttraining's multi_logloss: 2.01616e-05\n",
            "[2980]\ttraining's multi_logloss: 2.01624e-05\n",
            "[2981]\ttraining's multi_logloss: 2.01575e-05\n",
            "[2982]\ttraining's multi_logloss: 2.01551e-05\n",
            "[2983]\ttraining's multi_logloss: 2.01547e-05\n",
            "[2984]\ttraining's multi_logloss: 2.01558e-05\n",
            "[2985]\ttraining's multi_logloss: 2.01596e-05\n",
            "[2986]\ttraining's multi_logloss: 2.01543e-05\n",
            "[2987]\ttraining's multi_logloss: 2.01502e-05\n",
            "[2988]\ttraining's multi_logloss: 2.01482e-05\n",
            "[2989]\ttraining's multi_logloss: 2.0148e-05\n",
            "[2990]\ttraining's multi_logloss: 2.01497e-05\n",
            "[2991]\ttraining's multi_logloss: 2.01428e-05\n",
            "[2992]\ttraining's multi_logloss: 2.01378e-05\n",
            "[2993]\ttraining's multi_logloss: 2.01275e-05\n",
            "[2994]\ttraining's multi_logloss: 2.01274e-05\n",
            "[2995]\ttraining's multi_logloss: 2.01308e-05\n",
            "[2996]\ttraining's multi_logloss: 2.01264e-05\n",
            "[2997]\ttraining's multi_logloss: 2.01246e-05\n",
            "[2998]\ttraining's multi_logloss: 2.01107e-05\n",
            "[2999]\ttraining's multi_logloss: 2.01075e-05\n",
            "[3000]\ttraining's multi_logloss: 2.01011e-05\n",
            "[3001]\ttraining's multi_logloss: 2.00959e-05\n",
            "[3002]\ttraining's multi_logloss: 2.00932e-05\n",
            "[3003]\ttraining's multi_logloss: 2.0092e-05\n",
            "[3004]\ttraining's multi_logloss: 2.00924e-05\n",
            "[3005]\ttraining's multi_logloss: 2.00945e-05\n",
            "[3006]\ttraining's multi_logloss: 2.00871e-05\n",
            "[3007]\ttraining's multi_logloss: 2.00814e-05\n",
            "[3008]\ttraining's multi_logloss: 2.00626e-05\n",
            "[3009]\ttraining's multi_logloss: 2.00603e-05\n",
            "[3010]\ttraining's multi_logloss: 2.00605e-05\n",
            "[3011]\ttraining's multi_logloss: 2.00546e-05\n",
            "[3012]\ttraining's multi_logloss: 2.00466e-05\n",
            "[3013]\ttraining's multi_logloss: 2.00215e-05\n",
            "[3014]\ttraining's multi_logloss: 2.00203e-05\n",
            "[3015]\ttraining's multi_logloss: 2.0015e-05\n",
            "[3016]\ttraining's multi_logloss: 1.99945e-05\n",
            "[3017]\ttraining's multi_logloss: 1.99757e-05\n",
            "[3018]\ttraining's multi_logloss: 1.99588e-05\n",
            "[3019]\ttraining's multi_logloss: 1.99426e-05\n",
            "[3020]\ttraining's multi_logloss: 1.9927e-05\n",
            "[3021]\ttraining's multi_logloss: 1.99205e-05\n",
            "[3022]\ttraining's multi_logloss: 1.99039e-05\n",
            "[3023]\ttraining's multi_logloss: 1.98919e-05\n",
            "[3024]\ttraining's multi_logloss: 1.98756e-05\n",
            "[3025]\ttraining's multi_logloss: 1.98754e-05\n",
            "[3026]\ttraining's multi_logloss: 1.98708e-05\n",
            "[3027]\ttraining's multi_logloss: 1.98676e-05\n",
            "[3028]\ttraining's multi_logloss: 1.98576e-05\n",
            "[3029]\ttraining's multi_logloss: 1.98559e-05\n",
            "[3030]\ttraining's multi_logloss: 1.98522e-05\n",
            "[3031]\ttraining's multi_logloss: 1.98464e-05\n",
            "[3032]\ttraining's multi_logloss: 1.98423e-05\n",
            "[3033]\ttraining's multi_logloss: 1.98411e-05\n",
            "[3034]\ttraining's multi_logloss: 1.9835e-05\n",
            "[3035]\ttraining's multi_logloss: 1.98324e-05\n",
            "[3036]\ttraining's multi_logloss: 1.98263e-05\n",
            "[3037]\ttraining's multi_logloss: 1.98217e-05\n",
            "[3038]\ttraining's multi_logloss: 1.98117e-05\n",
            "[3039]\ttraining's multi_logloss: 1.97976e-05\n",
            "[3040]\ttraining's multi_logloss: 1.97796e-05\n",
            "[3041]\ttraining's multi_logloss: 1.97739e-05\n",
            "[3042]\ttraining's multi_logloss: 1.97682e-05\n",
            "[3043]\ttraining's multi_logloss: 1.97671e-05\n",
            "[3044]\ttraining's multi_logloss: 1.97671e-05\n",
            "[3045]\ttraining's multi_logloss: 1.976e-05\n",
            "[3046]\ttraining's multi_logloss: 1.9757e-05\n",
            "[3047]\ttraining's multi_logloss: 1.97533e-05\n",
            "[3048]\ttraining's multi_logloss: 1.97515e-05\n",
            "[3049]\ttraining's multi_logloss: 1.97518e-05\n",
            "[3050]\ttraining's multi_logloss: 1.97531e-05\n",
            "[3051]\ttraining's multi_logloss: 1.97472e-05\n",
            "[3052]\ttraining's multi_logloss: 1.97441e-05\n",
            "[3053]\ttraining's multi_logloss: 1.97332e-05\n",
            "[3054]\ttraining's multi_logloss: 1.97314e-05\n",
            "[3055]\ttraining's multi_logloss: 1.97249e-05\n",
            "[3056]\ttraining's multi_logloss: 1.97178e-05\n",
            "[3057]\ttraining's multi_logloss: 1.97132e-05\n",
            "[3058]\ttraining's multi_logloss: 1.97103e-05\n",
            "[3059]\ttraining's multi_logloss: 1.97098e-05\n",
            "[3060]\ttraining's multi_logloss: 1.97039e-05\n",
            "[3061]\ttraining's multi_logloss: 1.97005e-05\n",
            "[3062]\ttraining's multi_logloss: 1.96768e-05\n",
            "[3063]\ttraining's multi_logloss: 1.96769e-05\n",
            "[3064]\ttraining's multi_logloss: 1.96786e-05\n",
            "[3065]\ttraining's multi_logloss: 1.96744e-05\n",
            "[3066]\ttraining's multi_logloss: 1.9669e-05\n",
            "[3067]\ttraining's multi_logloss: 1.96648e-05\n",
            "[3068]\ttraining's multi_logloss: 1.9662e-05\n",
            "[3069]\ttraining's multi_logloss: 1.96552e-05\n",
            "[3070]\ttraining's multi_logloss: 1.96503e-05\n",
            "[3071]\ttraining's multi_logloss: 1.96438e-05\n",
            "[3072]\ttraining's multi_logloss: 1.96401e-05\n",
            "[3073]\ttraining's multi_logloss: 1.96366e-05\n",
            "[3074]\ttraining's multi_logloss: 1.96359e-05\n",
            "[3075]\ttraining's multi_logloss: 1.96369e-05\n",
            "[3076]\ttraining's multi_logloss: 1.96238e-05\n",
            "[3077]\ttraining's multi_logloss: 1.96192e-05\n",
            "[3078]\ttraining's multi_logloss: 1.9617e-05\n",
            "[3079]\ttraining's multi_logloss: 1.96165e-05\n",
            "[3080]\ttraining's multi_logloss: 1.96026e-05\n",
            "[3081]\ttraining's multi_logloss: 1.95969e-05\n",
            "[3082]\ttraining's multi_logloss: 1.95886e-05\n",
            "[3083]\ttraining's multi_logloss: 1.95789e-05\n",
            "[3084]\ttraining's multi_logloss: 1.95707e-05\n",
            "[3085]\ttraining's multi_logloss: 1.95725e-05\n",
            "[3086]\ttraining's multi_logloss: 1.95642e-05\n",
            "[3087]\ttraining's multi_logloss: 1.95592e-05\n",
            "[3088]\ttraining's multi_logloss: 1.95568e-05\n",
            "[3089]\ttraining's multi_logloss: 1.95514e-05\n",
            "[3090]\ttraining's multi_logloss: 1.95536e-05\n",
            "[3091]\ttraining's multi_logloss: 1.95415e-05\n",
            "[3092]\ttraining's multi_logloss: 1.95392e-05\n",
            "[3093]\ttraining's multi_logloss: 1.95277e-05\n",
            "[3094]\ttraining's multi_logloss: 1.95184e-05\n",
            "[3095]\ttraining's multi_logloss: 1.95115e-05\n",
            "[3096]\ttraining's multi_logloss: 1.95064e-05\n",
            "[3097]\ttraining's multi_logloss: 1.94975e-05\n",
            "[3098]\ttraining's multi_logloss: 1.94968e-05\n",
            "[3099]\ttraining's multi_logloss: 1.94914e-05\n",
            "[3100]\ttraining's multi_logloss: 1.94947e-05\n",
            "[3101]\ttraining's multi_logloss: 1.94883e-05\n",
            "[3102]\ttraining's multi_logloss: 1.94871e-05\n",
            "[3103]\ttraining's multi_logloss: 1.94879e-05\n",
            "[3104]\ttraining's multi_logloss: 1.94883e-05\n",
            "[3105]\ttraining's multi_logloss: 1.94937e-05\n",
            "[3106]\ttraining's multi_logloss: 1.94893e-05\n",
            "[3107]\ttraining's multi_logloss: 1.94873e-05\n",
            "[3108]\ttraining's multi_logloss: 1.94831e-05\n",
            "[3109]\ttraining's multi_logloss: 1.94854e-05\n",
            "[3110]\ttraining's multi_logloss: 1.94848e-05\n",
            "[3111]\ttraining's multi_logloss: 1.94745e-05\n",
            "[3112]\ttraining's multi_logloss: 1.94714e-05\n",
            "[3113]\ttraining's multi_logloss: 1.94693e-05\n",
            "[3114]\ttraining's multi_logloss: 1.94692e-05\n",
            "[3115]\ttraining's multi_logloss: 1.94647e-05\n",
            "[3116]\ttraining's multi_logloss: 1.94622e-05\n",
            "[3117]\ttraining's multi_logloss: 1.94605e-05\n",
            "[3118]\ttraining's multi_logloss: 1.94621e-05\n",
            "[3119]\ttraining's multi_logloss: 1.94654e-05\n",
            "[3120]\ttraining's multi_logloss: 1.94708e-05\n",
            "[3121]\ttraining's multi_logloss: 1.9463e-05\n",
            "[3122]\ttraining's multi_logloss: 1.94577e-05\n",
            "[3123]\ttraining's multi_logloss: 1.94542e-05\n",
            "[3124]\ttraining's multi_logloss: 1.94527e-05\n",
            "[3125]\ttraining's multi_logloss: 1.94515e-05\n",
            "[3126]\ttraining's multi_logloss: 1.94453e-05\n",
            "[3127]\ttraining's multi_logloss: 1.94409e-05\n",
            "[3128]\ttraining's multi_logloss: 1.94388e-05\n",
            "[3129]\ttraining's multi_logloss: 1.94372e-05\n",
            "[3130]\ttraining's multi_logloss: 1.94279e-05\n",
            "[3131]\ttraining's multi_logloss: 1.94252e-05\n",
            "[3132]\ttraining's multi_logloss: 1.94251e-05\n",
            "[3133]\ttraining's multi_logloss: 1.94269e-05\n",
            "[3134]\ttraining's multi_logloss: 1.94312e-05\n",
            "[3135]\ttraining's multi_logloss: 1.94365e-05\n",
            "[3136]\ttraining's multi_logloss: 1.94273e-05\n",
            "[3137]\ttraining's multi_logloss: 1.94182e-05\n",
            "[3138]\ttraining's multi_logloss: 1.94128e-05\n",
            "[3139]\ttraining's multi_logloss: 1.94106e-05\n",
            "[3140]\ttraining's multi_logloss: 1.94103e-05\n",
            "[3141]\ttraining's multi_logloss: 1.94037e-05\n",
            "[3142]\ttraining's multi_logloss: 1.93994e-05\n",
            "[3143]\ttraining's multi_logloss: 1.93924e-05\n",
            "[3144]\ttraining's multi_logloss: 1.93929e-05\n",
            "[3145]\ttraining's multi_logloss: 1.93894e-05\n",
            "[3146]\ttraining's multi_logloss: 1.9379e-05\n",
            "[3147]\ttraining's multi_logloss: 1.93676e-05\n",
            "[3148]\ttraining's multi_logloss: 1.93646e-05\n",
            "[3149]\ttraining's multi_logloss: 1.93638e-05\n",
            "[3150]\ttraining's multi_logloss: 1.93646e-05\n",
            "[3151]\ttraining's multi_logloss: 1.93582e-05\n",
            "[3152]\ttraining's multi_logloss: 1.9355e-05\n",
            "[3153]\ttraining's multi_logloss: 1.93526e-05\n",
            "[3154]\ttraining's multi_logloss: 1.93527e-05\n",
            "[3155]\ttraining's multi_logloss: 1.9355e-05\n",
            "[3156]\ttraining's multi_logloss: 1.93507e-05\n",
            "[3157]\ttraining's multi_logloss: 1.93372e-05\n",
            "[3158]\ttraining's multi_logloss: 1.93345e-05\n",
            "[3159]\ttraining's multi_logloss: 1.93333e-05\n",
            "[3160]\ttraining's multi_logloss: 1.93328e-05\n",
            "[3161]\ttraining's multi_logloss: 1.93273e-05\n",
            "[3162]\ttraining's multi_logloss: 1.93247e-05\n",
            "[3163]\ttraining's multi_logloss: 1.93186e-05\n",
            "[3164]\ttraining's multi_logloss: 1.93207e-05\n",
            "[3165]\ttraining's multi_logloss: 1.93196e-05\n",
            "[3166]\ttraining's multi_logloss: 1.93081e-05\n",
            "[3167]\ttraining's multi_logloss: 1.92974e-05\n",
            "[3168]\ttraining's multi_logloss: 1.92803e-05\n",
            "[3169]\ttraining's multi_logloss: 1.92718e-05\n",
            "[3170]\ttraining's multi_logloss: 1.9265e-05\n",
            "[3171]\ttraining's multi_logloss: 1.92576e-05\n",
            "[3172]\ttraining's multi_logloss: 1.92553e-05\n",
            "[3173]\ttraining's multi_logloss: 1.92551e-05\n",
            "[3174]\ttraining's multi_logloss: 1.92568e-05\n",
            "[3175]\ttraining's multi_logloss: 1.92558e-05\n",
            "[3176]\ttraining's multi_logloss: 1.92435e-05\n",
            "[3177]\ttraining's multi_logloss: 1.92388e-05\n",
            "[3178]\ttraining's multi_logloss: 1.92347e-05\n",
            "[3179]\ttraining's multi_logloss: 1.92318e-05\n",
            "[3180]\ttraining's multi_logloss: 1.92307e-05\n",
            "[3181]\ttraining's multi_logloss: 1.92262e-05\n",
            "[3182]\ttraining's multi_logloss: 1.92186e-05\n",
            "[3183]\ttraining's multi_logloss: 1.92191e-05\n",
            "[3184]\ttraining's multi_logloss: 1.92215e-05\n",
            "[3185]\ttraining's multi_logloss: 1.92264e-05\n",
            "[3186]\ttraining's multi_logloss: 1.92211e-05\n",
            "[3187]\ttraining's multi_logloss: 1.92151e-05\n",
            "[3188]\ttraining's multi_logloss: 1.92151e-05\n",
            "[3189]\ttraining's multi_logloss: 1.92124e-05\n",
            "[3190]\ttraining's multi_logloss: 1.9212e-05\n",
            "[3191]\ttraining's multi_logloss: 1.92031e-05\n",
            "[3192]\ttraining's multi_logloss: 1.91989e-05\n",
            "[3193]\ttraining's multi_logloss: 1.91965e-05\n",
            "[3194]\ttraining's multi_logloss: 1.9195e-05\n",
            "[3195]\ttraining's multi_logloss: 1.91956e-05\n",
            "[3196]\ttraining's multi_logloss: 1.9185e-05\n",
            "[3197]\ttraining's multi_logloss: 1.91777e-05\n",
            "[3198]\ttraining's multi_logloss: 1.91763e-05\n",
            "[3199]\ttraining's multi_logloss: 1.9168e-05\n",
            "[3200]\ttraining's multi_logloss: 1.91656e-05\n",
            "[3201]\ttraining's multi_logloss: 1.91611e-05\n",
            "[3202]\ttraining's multi_logloss: 1.91581e-05\n",
            "[3203]\ttraining's multi_logloss: 1.91568e-05\n",
            "[3204]\ttraining's multi_logloss: 1.91572e-05\n",
            "[3205]\ttraining's multi_logloss: 1.91545e-05\n",
            "[3206]\ttraining's multi_logloss: 1.91488e-05\n",
            "[3207]\ttraining's multi_logloss: 1.91403e-05\n",
            "[3208]\ttraining's multi_logloss: 1.91387e-05\n",
            "[3209]\ttraining's multi_logloss: 1.9134e-05\n",
            "[3210]\ttraining's multi_logloss: 1.91351e-05\n",
            "[3211]\ttraining's multi_logloss: 1.91293e-05\n",
            "[3212]\ttraining's multi_logloss: 1.91267e-05\n",
            "[3213]\ttraining's multi_logloss: 1.91262e-05\n",
            "[3214]\ttraining's multi_logloss: 1.91276e-05\n",
            "[3215]\ttraining's multi_logloss: 1.9122e-05\n",
            "[3216]\ttraining's multi_logloss: 1.91179e-05\n",
            "[3217]\ttraining's multi_logloss: 1.91145e-05\n",
            "[3218]\ttraining's multi_logloss: 1.91004e-05\n",
            "[3219]\ttraining's multi_logloss: 1.91013e-05\n",
            "[3220]\ttraining's multi_logloss: 1.90971e-05\n",
            "[3221]\ttraining's multi_logloss: 1.9092e-05\n",
            "[3222]\ttraining's multi_logloss: 1.90883e-05\n",
            "[3223]\ttraining's multi_logloss: 1.90799e-05\n",
            "[3224]\ttraining's multi_logloss: 1.90676e-05\n",
            "[3225]\ttraining's multi_logloss: 1.90572e-05\n",
            "[3226]\ttraining's multi_logloss: 1.90543e-05\n",
            "[3227]\ttraining's multi_logloss: 1.90527e-05\n",
            "[3228]\ttraining's multi_logloss: 1.90532e-05\n",
            "[3229]\ttraining's multi_logloss: 1.9055e-05\n",
            "[3230]\ttraining's multi_logloss: 1.90545e-05\n",
            "[3231]\ttraining's multi_logloss: 1.905e-05\n",
            "[3232]\ttraining's multi_logloss: 1.90483e-05\n",
            "[3233]\ttraining's multi_logloss: 1.90485e-05\n",
            "[3234]\ttraining's multi_logloss: 1.90499e-05\n",
            "[3235]\ttraining's multi_logloss: 1.90531e-05\n",
            "[3236]\ttraining's multi_logloss: 1.9048e-05\n",
            "[3237]\ttraining's multi_logloss: 1.90451e-05\n",
            "[3238]\ttraining's multi_logloss: 1.90389e-05\n",
            "[3239]\ttraining's multi_logloss: 1.90399e-05\n",
            "[3240]\ttraining's multi_logloss: 1.90431e-05\n",
            "[3241]\ttraining's multi_logloss: 1.90369e-05\n",
            "[3242]\ttraining's multi_logloss: 1.90336e-05\n",
            "[3243]\ttraining's multi_logloss: 1.90324e-05\n",
            "[3244]\ttraining's multi_logloss: 1.90326e-05\n",
            "[3245]\ttraining's multi_logloss: 1.90305e-05\n",
            "[3246]\ttraining's multi_logloss: 1.90261e-05\n",
            "[3247]\ttraining's multi_logloss: 1.90233e-05\n",
            "[3248]\ttraining's multi_logloss: 1.90224e-05\n",
            "[3249]\ttraining's multi_logloss: 1.90232e-05\n",
            "[3250]\ttraining's multi_logloss: 1.90255e-05\n",
            "[3251]\ttraining's multi_logloss: 1.90166e-05\n",
            "[3252]\ttraining's multi_logloss: 1.90119e-05\n",
            "[3253]\ttraining's multi_logloss: 1.90091e-05\n",
            "[3254]\ttraining's multi_logloss: 1.90005e-05\n",
            "[3255]\ttraining's multi_logloss: 1.89971e-05\n",
            "[3256]\ttraining's multi_logloss: 1.89936e-05\n",
            "[3257]\ttraining's multi_logloss: 1.89929e-05\n",
            "[3258]\ttraining's multi_logloss: 1.8985e-05\n",
            "[3259]\ttraining's multi_logloss: 1.89841e-05\n",
            "[3260]\ttraining's multi_logloss: 1.89772e-05\n",
            "[3261]\ttraining's multi_logloss: 1.89728e-05\n",
            "[3262]\ttraining's multi_logloss: 1.89703e-05\n",
            "[3263]\ttraining's multi_logloss: 1.89702e-05\n",
            "[3264]\ttraining's multi_logloss: 1.89667e-05\n",
            "[3265]\ttraining's multi_logloss: 1.89658e-05\n",
            "[3266]\ttraining's multi_logloss: 1.89594e-05\n",
            "[3267]\ttraining's multi_logloss: 1.89542e-05\n",
            "[3268]\ttraining's multi_logloss: 1.89513e-05\n",
            "[3269]\ttraining's multi_logloss: 1.89507e-05\n",
            "[3270]\ttraining's multi_logloss: 1.89449e-05\n",
            "[3271]\ttraining's multi_logloss: 1.89258e-05\n",
            "[3272]\ttraining's multi_logloss: 1.89071e-05\n",
            "[3273]\ttraining's multi_logloss: 1.88903e-05\n",
            "[3274]\ttraining's multi_logloss: 1.88656e-05\n",
            "[3275]\ttraining's multi_logloss: 1.88531e-05\n",
            "[3276]\ttraining's multi_logloss: 1.88468e-05\n",
            "[3277]\ttraining's multi_logloss: 1.88429e-05\n",
            "[3278]\ttraining's multi_logloss: 1.88402e-05\n",
            "[3279]\ttraining's multi_logloss: 1.88401e-05\n",
            "[3280]\ttraining's multi_logloss: 1.88389e-05\n",
            "[3281]\ttraining's multi_logloss: 1.88329e-05\n",
            "[3282]\ttraining's multi_logloss: 1.88287e-05\n",
            "[3283]\ttraining's multi_logloss: 1.88258e-05\n",
            "[3284]\ttraining's multi_logloss: 1.88158e-05\n",
            "[3285]\ttraining's multi_logloss: 1.88168e-05\n",
            "[3286]\ttraining's multi_logloss: 1.88093e-05\n",
            "[3287]\ttraining's multi_logloss: 1.88043e-05\n",
            "[3288]\ttraining's multi_logloss: 1.88009e-05\n",
            "[3289]\ttraining's multi_logloss: 1.87986e-05\n",
            "[3290]\ttraining's multi_logloss: 1.87981e-05\n",
            "[3291]\ttraining's multi_logloss: 1.87928e-05\n",
            "[3292]\ttraining's multi_logloss: 1.87896e-05\n",
            "[3293]\ttraining's multi_logloss: 1.87838e-05\n",
            "[3294]\ttraining's multi_logloss: 1.87852e-05\n",
            "[3295]\ttraining's multi_logloss: 1.87897e-05\n",
            "[3296]\ttraining's multi_logloss: 1.87836e-05\n",
            "[3297]\ttraining's multi_logloss: 1.87804e-05\n",
            "[3298]\ttraining's multi_logloss: 1.87776e-05\n",
            "[3299]\ttraining's multi_logloss: 1.87731e-05\n",
            "[3300]\ttraining's multi_logloss: 1.87729e-05\n",
            "[3301]\ttraining's multi_logloss: 1.87679e-05\n",
            "[3302]\ttraining's multi_logloss: 1.87642e-05\n",
            "[3303]\ttraining's multi_logloss: 1.87555e-05\n",
            "[3304]\ttraining's multi_logloss: 1.8755e-05\n",
            "[3305]\ttraining's multi_logloss: 1.87554e-05\n",
            "[3306]\ttraining's multi_logloss: 1.87513e-05\n",
            "[3307]\ttraining's multi_logloss: 1.87485e-05\n",
            "[3308]\ttraining's multi_logloss: 1.87483e-05\n",
            "[3309]\ttraining's multi_logloss: 1.87499e-05\n",
            "[3310]\ttraining's multi_logloss: 1.87524e-05\n",
            "[3311]\ttraining's multi_logloss: 1.87473e-05\n",
            "[3312]\ttraining's multi_logloss: 1.87356e-05\n",
            "[3313]\ttraining's multi_logloss: 1.87257e-05\n",
            "[3314]\ttraining's multi_logloss: 1.87196e-05\n",
            "[3315]\ttraining's multi_logloss: 1.87123e-05\n",
            "[3316]\ttraining's multi_logloss: 1.87062e-05\n",
            "[3317]\ttraining's multi_logloss: 1.86992e-05\n",
            "[3318]\ttraining's multi_logloss: 1.86961e-05\n",
            "[3319]\ttraining's multi_logloss: 1.86954e-05\n",
            "[3320]\ttraining's multi_logloss: 1.8696e-05\n",
            "[3321]\ttraining's multi_logloss: 1.86854e-05\n",
            "[3322]\ttraining's multi_logloss: 1.86766e-05\n",
            "[3323]\ttraining's multi_logloss: 1.86722e-05\n",
            "[3324]\ttraining's multi_logloss: 1.86666e-05\n",
            "[3325]\ttraining's multi_logloss: 1.86631e-05\n",
            "[3326]\ttraining's multi_logloss: 1.86566e-05\n",
            "[3327]\ttraining's multi_logloss: 1.86515e-05\n",
            "[3328]\ttraining's multi_logloss: 1.86488e-05\n",
            "[3329]\ttraining's multi_logloss: 1.8642e-05\n",
            "[3330]\ttraining's multi_logloss: 1.86412e-05\n",
            "[3331]\ttraining's multi_logloss: 1.86358e-05\n",
            "[3332]\ttraining's multi_logloss: 1.86329e-05\n",
            "[3333]\ttraining's multi_logloss: 1.86321e-05\n",
            "[3334]\ttraining's multi_logloss: 1.8634e-05\n",
            "[3335]\ttraining's multi_logloss: 1.86371e-05\n",
            "[3336]\ttraining's multi_logloss: 1.86315e-05\n",
            "[3337]\ttraining's multi_logloss: 1.86219e-05\n",
            "[3338]\ttraining's multi_logloss: 1.86137e-05\n",
            "[3339]\ttraining's multi_logloss: 1.86132e-05\n",
            "[3340]\ttraining's multi_logloss: 1.86151e-05\n",
            "[3341]\ttraining's multi_logloss: 1.86094e-05\n",
            "[3342]\ttraining's multi_logloss: 1.86059e-05\n",
            "[3343]\ttraining's multi_logloss: 1.86042e-05\n",
            "[3344]\ttraining's multi_logloss: 1.86044e-05\n",
            "[3345]\ttraining's multi_logloss: 1.85979e-05\n",
            "[3346]\ttraining's multi_logloss: 1.85937e-05\n",
            "[3347]\ttraining's multi_logloss: 1.85917e-05\n",
            "[3348]\ttraining's multi_logloss: 1.85861e-05\n",
            "[3349]\ttraining's multi_logloss: 1.85869e-05\n",
            "[3350]\ttraining's multi_logloss: 1.85892e-05\n",
            "[3351]\ttraining's multi_logloss: 1.85828e-05\n",
            "[3352]\ttraining's multi_logloss: 1.85816e-05\n",
            "[3353]\ttraining's multi_logloss: 1.85828e-05\n",
            "[3354]\ttraining's multi_logloss: 1.85849e-05\n",
            "[3355]\ttraining's multi_logloss: 1.85888e-05\n",
            "[3356]\ttraining's multi_logloss: 1.85862e-05\n",
            "[3357]\ttraining's multi_logloss: 1.85856e-05\n",
            "[3358]\ttraining's multi_logloss: 1.85858e-05\n",
            "[3359]\ttraining's multi_logloss: 1.85884e-05\n",
            "[3360]\ttraining's multi_logloss: 1.85921e-05\n",
            "[3361]\ttraining's multi_logloss: 1.85905e-05\n",
            "[3362]\ttraining's multi_logloss: 1.85906e-05\n",
            "Early stopping, best iteration is:\n",
            "[3352]\ttraining's multi_logloss: 1.85816e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUQKYVS_bx8A",
        "colab_type": "text"
      },
      "source": [
        "And now let's "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFYk6LUSVVIY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "0bd83660-d647-476c-ba7e-83ea1b7e0569"
      },
      "source": [
        "print('Saving model...')\n",
        "# save model to file\n",
        "gbm.save_model('model.txt')\n",
        "\n",
        "print('Starting predicting...')\n",
        "# predict\n",
        "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model...\n",
            "Starting predicting...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOenLKe0bzsE",
        "colab_type": "text"
      },
      "source": [
        "Convert predictions to our required format:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTB2h1GBVZa_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = [list(o).index(max(o)) for o in y_pred]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hpxfZg9cJ_g",
        "colab_type": "text"
      },
      "source": [
        "And let's run the test:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQSCp6rmZp0M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8566591a-2c28-4465-90ce-3e8eacb94365"
      },
      "source": [
        "print('test', metrics.f1_score(list(y_test), y_pred, average='macro'))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test 0.8787403280193746\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0Wb4g5_b5WU",
        "colab_type": "text"
      },
      "source": [
        "This is better than `baseline 3: 0.8122 word2vec cbow embedding + baseline 2 + svm`, so we should get **8 points** for the model and **9 points** in total."
      ]
    }
  ]
}